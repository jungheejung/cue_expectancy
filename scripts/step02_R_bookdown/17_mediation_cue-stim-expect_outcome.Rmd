# [beh] Mediation outcome ~ cue * stim * expectrating * n-1outcomerating  {#ch17_mediation}


helpful resources
https://nmmichalak.github.io/nicholas_michalak/blog_entries/2018/nrg01/nrg01.html
## What is the purpose of this notebook? {.unlisted .unnumbered}
Here, I model the outcome ratings as a function of cue, stimulus intensity, expectation ratings, N-1 outcome rating. 
* As opposed to notebook 15, I want to check if the demeaning process should be for runs as opposed to subjects. 
* In other words, calculate the average within run and subtract ratings 
* Main model: `lmer(outcome_rating ~ cue * stim * expectation rating + N-1 outcomerating)` 
* Main question: What constitutes a reported outcome rating? 
* Sub questions:
  - If there is a linear relationship between expectation rating and outcome rating, does this differ as a function of cue?
  - How does a N-1 outcome rating affect current expectation ratings? 
  - Later, is this effect different across tasks or are they similar?

* IV: 
  stim (high / med / low)
  cue (high / low)
  expectation rating (continuous)
  N-1 outcome rating (continuous)
* DV: outcome rating

### Some thoughts, TODOs {.unlisted .unnumbered}

* Standardized coefficients
* Slope difference? Intercept difference? ( cue and expectantion rating)
* Correct for the range (within participant)
hypothesis:
1. Larger expectation leads to prediction error
2. Individual differences in ratings
3. Outcome experience, based on behavioral experience
What are the brain maps associated with each component.  


```{r load_libraries_17, message=FALSE, warning=FALSE, include=FALSE, paged.print=TRUE}
library(psych)
library(car)
# library(lmSupport)
library(lme4)
library(lmerTest)
library(dplyr)
library(plyr)
library(tidyr)
library(stringr)
library(ggplot2)
library(png)
library(knitr)
library(ggpubr)
library(gridExtra)
library(merTools)
library(sjstats) #to get ICC
library(tidyverse)
library(GGally)
library(lme4)
library(gghalves)
library(effectsize)
library(devtools)
library(visibly) # 
library(plotly) #plot
library(scico) # plot
library(emmeans) # v. 1.7.0
library(magrittr) # v. 2.0.1
source('http://psych.colorado.edu/~jclab/R/mcSummaryLm.R')
source("/Users/h/Documents/projects_local/RainCloudPlots/tutorial_R/R_rainclouds.R")
source("/Users/h/Documents/projects_local/RainCloudPlots/tutorial_R/summarySE.R")
source("/Users/h/Documents/projects_local/RainCloudPlots/tutorial_R/simulateData.R")
# source("https://gist.github.com/benmarwick/2a1bb0133ff568cbe28d/geom_flat_violin.R")

library(r2mlm)
file.sources = list.files(c("/Users/h/Dropbox/projects_dropbox/social_influence_analysis/scripts/step02_R/utils"),
                          pattern="*.R", 
                          full.names=TRUE, 
                          ignore.case=TRUE)
sapply(file.sources,source,.GlobalEnv)
```

load data and combine participant data

```{r load_data_and_exclude_m1, echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
main_dir = dirname(dirname(getwd()))
datadir = file.path(main_dir, 'data', 'beh', 'beh02_preproc')
# parameters _____________________________________ # nolint
subject_varkey <- "src_subject_id"
iv <- "param_cue_type"
dv <- "event03_RT"
dv_keyword <- "RT"
xlab <- ""
taskname <- "pain"

ylab <- "ratings (degree)"
subject <- "subject"
exclude <- "sub-0999|sub-0001|sub-0002|sub-0003|sub-0004|sub-0005|sub-0006|sub-0007|sub-0008|sub-0009|sub-0010|sub-0011"

# load data _____________________________________
data <- load_task_social_df(datadir, taskname = taskname, subject_varkey = subject_varkey, iv = iv, exclude = exclude)
data$event03_RT <- data$event03_stimulusC_reseponseonset - data$event03_stimulus_displayonset
# data['event03_RT'], data.event03_RT - pandas
analysis_dir <- file.path(main_dir, "analysis", "mixedeffect", "model15_iv-cue-stim-N1outcome-expect_dv-outcome", as.character(Sys.Date()))
dir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)
```

```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
summary(data[, c("event02_expect_RT", "event04_actual_RT", "event02_expect_angle", "event04_actual_angle")])
```



### Covariance matrix: ratings and RT {.unlisted .unnumbered}
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
# data(data, package = 'visibly')

myvars <- names(data) %in% 
  c( "event02_expect_angle", "event02_expect_RT", "event04_actual_angle", "event04_actual_RT", "event01_cue_onset")
newdata <- data[myvars]
# numdata  <- unlist(lapply(data, is.numeric), use.names = FALSE) 
data_naomit <- na.omit(newdata)
cor_matrix = cor(data_naomit)
corr_heat(cor_matrix)
```

### Covariance matrix: fixation durations (e.g. ISIs) {.unlisted .unnumbered}
```{r echo=FALSE, message=FALSE, warning=FALSE, paged.print=FALSE}
ISIvars <- names(data) %in% 
  c( "ISI01_duration", "ISI02_duration", "ISI03_duration")
ISIdata <- data[ISIvars]
# numdata  <- unlist(lapply(data, is.numeric), use.names = FALSE) 
ISIdata_naomit <- na.omit(ISIdata)
ISIcor_matrix = cor(ISIdata_naomit)
corr_heat(ISIcor_matrix)
```

```{r function::simple_contrasts_beh, message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
simple_contrasts_beh <- function(df) {
# [ CONTRASTS ]  ________________________________________________________________________________ # nolint
# contrast code ________________________________________
df$stim_factor <- factor(df$param_stimulus_type)

# contrast code 1 linear
df$stim_con_linear[df$param_stimulus_type == "low_stim"] <-  -0.5
df$stim_con_linear[df$param_stimulus_type == "med_stim"] <-  0
df$stim_con_linear[df$param_stimulus_type == "high_stim"] <-  0.5

# contrast code 2 quadratic
df$stim_con_quad[df$param_stimulus_type == "low_stim"] <-  -0.33
df$stim_con_quad[df$param_stimulus_type == "med_stim"] <-  0.66
df$stim_con_quad[df$param_stimulus_type == "high_stim"] <-  -0.33

# cue contrast
df$CUE_high_gt_low[df$param_cue_type == "low_cue"] <-  -0.5 # social influence task
df$CUE_high_gt_low[df$param_cue_type == "high_cue"] <-  0.5 # no influence task

df$stim_ordered <- factor(
        df$param_stimulus_type,
        levels = c("low_stim", "med_stim", "high_stim")
    )

df$cue_name[df$param_cue_type == "low_cue"] <- "low"
df$cue_name[df$param_cue_type == "high_cue"] <- "high"

df$cue_ordered <- factor(
        df$cue_name,
        levels = c("low", "high")
    )
return(df)
}
```

```{r message=FALSE, warning=FALSE, include=FALSE, paged.print=FALSE}
data_p2= data %>%
  arrange(src_subject_id ) %>%
  group_by(src_subject_id) %>%
  mutate(trial_index = row_number())
data_a3 <- data_p2 %>% 
  group_by(src_subject_id, session_id, param_run_num) %>% 
  mutate(trial_index = row_number(param_run_num))

data_a3lag <- 
    data_a3 %>%
    group_by(src_subject_id, session_id, param_run_num) %>%
    mutate(lag.04outcomeangle = dplyr::lag(event04_actual_angle, n = 1, default = NA))
data_a3lag_omit <- data_a3lag[complete.cases(data_a3lag$lag.04outcomeangle),]

df <- data_a3lag_omit
pvc <- simple_contrasts_beh(df)
```

## mediation

```{r}
psych::mediate(event04_actual_angle ~ CUE_high_gt_low*stim_con_linear+ event02_expect_angle + lag.04outcomeangle, data = pvc, n.iter = 1000) %>% print(short = FALSE) 
```
## mediation 2
```{r}
mod1 <- "# a path
         #thirst ~ a * room_temp
         event02_expect_angle ~ a * CUE_high_gt_low

         # b path
         #consume ~ b * thirst
         event04_actual_angle ~ b* event02_expect_angle
         
         # c prime path 
         #consume ~ cp * room_temp
         event04_actual_angle ~ cp * CUE_high_gt_low
         
         # indirect and total effects
         ab := a * b
         total := cp + ab"
```

```{r}
library(lavaan)
fsem1 <- sem(mod1, data = pvc, se = "bootstrap", bootstrap = 1000)
summary(fsem1, standardized = TRUE)
parameterestimates(fsem1, boot.ci.type = "bca.simple", standardized = TRUE) %>% 
  kable()

```
```{r eval=FALSE, warning=TRUE, include=FALSE}
with(pvc, MBESS::mediation.effect.plot(x = CUE_high_gt_low, 
                                mediator = event02_expect_angle, 
                                dv = event04_actual_angle, 
                                ylab = "outcome rating", xlab = "expectation rating"))
```


## mediation 3: Test same model using mediation() from MBESS
```{r echo=FALSE, message=FALSE, warning=TRUE, paged.print=FALSE}
library(mediation)
library(brms)
library(MBESS)
library(bayestestR)
with(pvc, MBESS::mediation(x = CUE_high_gt_low, 
                    mediator = event02_expect_angle, 
                    dv = event04_actual_angle, bootstrap = TRUE, which.boot = "BCa", B = 100))
```

## mediation 4: Test library mediation
```{r eval=FALSE, include=FALSE}
library(mediation)
library(brms)
library(MBESS)
library(bayestestR)
model.0 <- lm(event04_actual_angle ~ CUE_high_gt_low, pvc)
model.M <- lm(event02_expect_angle ~ CUE_high_gt_low, pvc)
model.Y <- lm(event04_actual_angle ~ CUE_high_gt_low + event02_expect_angle, pvc)
results <- mediation::mediate(
    model.M,
    model.Y,
    treat = 'CUE_high_gt_low',
    mediator = 'event02_expect_angle',
    boot = TRUE,
    sims = 500
)
summary(results)
```


