[{"path":"index.html","id":"about","chapter":"1 About","heading":"1 About","text":"analysis book written Markdown. purpose keep track analyses summarize findings, decluttering result vs. code.","code":""},{"path":"index.html","id":"usage","chapter":"1 About","heading":"1.1 Usage","text":"bookdown chapter .Rmd file. .Rmd migrated git repository cue-expectancy cue-expectancy specifically folder step02_R. .Rmd file developed standalone analysis pipeline. validated, identical .Rmd migrated bookdown folder edited bookdown compiling.","code":""},{"path":"index.html","id":"order","chapter":"1 About","heading":"1.2 Order","text":"Behavioral analysisReinforcement learning simulationsfMRI analysis (signatures)fMRI FIR time series analysis","code":""},{"path":"index.html","id":"todo","chapter":"1 About","heading":"1.3 TODO","text":"create behavioral file - tedious reproducible compile dataframe everytimecreate script converting column names","code":""},{"path":"beh-intro.html","id":"beh-intro","chapter":"Behavioral Rating analysis","heading":"Behavioral Rating analysis","text":"following chapters analyze behavioral ratings – expectation outcome ratings – function experimental variables. first build analyses factor: cue stimulus intensity. , include analysis shifting trials analyzing impact previous trial ratings current ratingChapter 2 details cue effect expectation ratings.Chapter 2 details cue effect expectation ratings.Chapter 3 examines cue effect outcome ratingsChapter 3 examines cue effect outcome ratingsChapter 5 examines interaction cue stimulus intensity outcome ratings.Chapter 5 examines interaction cue stimulus intensity outcome ratings.Chapter 10 examines outcome rating function cue, stimulus intensity, expectation ratings, N-1 outcome rating.Chapter 10 examines outcome rating function cue, stimulus intensity, expectation ratings, N-1 outcome rating.","code":""},{"path":"beh-intro.html","id":"beh-sub","chapter":"Behavioral Rating analysis","heading":"Check if this one produces a line","text":"Let’s begin working workflow developing apps.text. Let’s see wraps aroundthis lead lineInclude actual content . thoughtsconvert ratingszscore ratingscalculate relationship","code":"\n# and let me check my code"},{"path":"beh-expect-cue.html","id":"beh-expect-cue","chapter":"2 beh :: expectation ~ cue","heading":"2 beh :: expectation ~ cue","text":"","code":""},{"path":"beh-expect-cue.html","id":"what-is-the-purpose-of-this-notebook","chapter":"2 beh :: expectation ~ cue","heading":"What is the purpose of this notebook?","text":", plot expectation ratings function cue.Main model: lmer(expect_rating ~ cue)Main question: expectations ratings differ function cue type?main effect cue expectation ratings, cue effect differ depending task type?IV: cue (high / low)DV: expectation ratingAlso, larger IQRs expectation ratings also show greater cue effects?\nSteps:\ncalculate cue effects per pariticpant (high vs. low cue average)\ncalculate IQR per participant\ncheck correlation","code":"\nfor (taskname in c(\"pain\", \"vicarious\", \"cognitive\")) {\n    dv_keyword <- \"expect\"\n    model_savefname <- file.path(\n        analysis_dir,\n        paste(\"lmer_task-\", taskname,\n            \"_rating-\", dv_keyword,\n            \"_\", as.character(Sys.Date()), \".txt\",\n            sep = \"\"\n        )\n    )\n    iv <- \"param_stimulus_type\"\n    dv <- \"event02_expect_angle\"\n    subject_varkey <- \"src_subject_id\"\n\n    print_lmer_output = TRUE\n    exclude <- \"sub-0001|sub-0999\"\n    # load data, run model, and exclude outliers\n    data <- df_load_beh(datadir, taskname, subject_varkey, iv, dv, exclude)\n    ############################################################################\n    # TODO: substitue with cueR::simple_contrast_beh(data)  right before iv <-\"stim_ordered\"\n    data$subject = factor(data$src_subject_id)\n    data$stim_name[data$param_stimulus_type == \"high_stim\"] <- \"high\"\n    data$stim_name[data$param_stimulus_type == \"med_stim\"] <- \"med\"\n    data$stim_name[data$param_stimulus_type == \"low_stim\"] <- \"low\"\n\n    data$stimlin[data$param_stimulus_type == \"high_stim\"] <- 0.5\n    data$stimlin[data$param_stimulus_type == \"med_stim\"] <- 0\n    data$stimlin[data$param_stimulus_type == \"low_stim\"] <- -0.5\n\n    data$stimquad[data$param_stimulus_type == \"high_stim\"] <- -0.34\n    data$stimquad[data$param_stimulus_type == \"med_stim\"] <- 0.66\n    data$stimquad[data$param_stimulus_type == \"low_stim\"] <- -0.34\n\n        data$cue_name[data$param_cue_type == \"high_cue\"] <- \"high\"\n    data$cue_name[data$param_cue_type == \"low_cue\"] <- \"low\"\n\n            data$cue_con[data$param_cue_type == \"high_cue\"] <- 0.5\n    data$cue_con[data$param_cue_type == \"low_cue\"] <- -0.5\n    # DATA$levels_ordered <- factor(DATA$param_stimulus_type, levels=c(\"low\", \"med\", \"high\"))\n\n    data$stim_ordered <- factor(\n        data$stim_name,\n        levels = c(\"low\", \"med\", \"high\")\n    )\n    ############################################################################\n    iv <- \"stim_ordered\"\n    dv <- \"event02_expect_angle\"\n    print(taskname)\n    model <- lmer(event02_expect_angle ~ cue_con + (1|src_subject_id), data = data)\n    print(summary(model))\n}## [1] \"pain\"\n## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: event02_expect_angle ~ cue_con + (1 | src_subject_id)\n##    Data: data\n## \n## REML criterion at convergence: 56012.8\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.1273 -0.6288 -0.0305  0.6197  4.8504 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept) 831.9    28.84   \n##  Residual                   529.5    23.01   \n## Number of obs: 6095, groups:  src_subject_id, 114\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   60.9943     2.7230  113.0814   22.40   <2e-16 ***\n## cue_con       34.4542     0.5899 5981.2865   58.41   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##         (Intr)\n## cue_con 0.000 \n## [1] \"vicarious\"\n## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: event02_expect_angle ~ cue_con + (1 | src_subject_id)\n##    Data: data\n## \n## REML criterion at convergence: 57065.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.3554 -0.6080 -0.0778  0.5620  6.2802 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept) 116.5    10.79   \n##  Residual                   293.8    17.14   \n## Number of obs: 6656, groups:  src_subject_id, 114\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   31.1604     1.0368  112.8038   30.05   <2e-16 ***\n## cue_con       33.7887     0.4205 6542.0225   80.36   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##         (Intr)\n## cue_con 0.002 \n## [1] \"cognitive\"\n## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: event02_expect_angle ~ cue_con + (1 | src_subject_id)\n##    Data: data\n## \n## REML criterion at convergence: 58008\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.3780 -0.6120 -0.0800  0.5341  9.3354 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept) 167.4    12.94   \n##  Residual                   303.3    17.41   \n## Number of obs: 6737, groups:  src_subject_id, 114\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   33.8866     1.2332  112.1041   27.48   <2e-16 ***\n## cue_con       31.7535     0.4246 6622.2852   74.78   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##         (Intr)\n## cue_con 0.000\n# parameters _____________________________________ # nolint\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"; iv_keyword <- \"cue\"; dv <- \"event02_expect_angle\"; dv_keyword <- \"expect\"\nxlab <- \"\"; ylim = c(0,180); ylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001|sub-0003|sub-0004|sub-0005|sub-0025|sub-0999\"\nsubjectwise_mean <- \"mean_per_sub\"; group_mean <- \"mean_per_sub_norm_mean\"; se <- \"se\"\ncolor_scheme <-     if (any(startsWith(dv_keyword, c(\"expect\", \"Expect\")))) {\n        color_scheme <- c(\"#1B9E77\", \"#D95F02\")\n    } else {\n        color_scheme <- c(\"#4575B4\", \"#D73027\")\n    }\nprint_lmer_output <- FALSE\nggtitle_phrase <- \" - Expectation Rating (degree)\"\nanalysis_dir <- file.path(main_dir, \"analysis\", \"mixedeffect\", \"model01_iv-cue_dv-expect\", as.character(Sys.Date()))\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)"},{"path":"beh-expect-cue.html","id":"pain","chapter":"2 beh :: expectation ~ cue","heading":"2.1 Pain","text":"","code":""},{"path":"beh-expect-cue.html","id":"for-the-pain-task-what-is-the-effect-of-cue-on-expectation-ratings","chapter":"2 beh :: expectation ~ cue","heading":"For the pain task, what is the effect of cue on expectation ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-expect-cue.html","id":"vicarious","chapter":"2 beh :: expectation ~ cue","heading":"2.2 Vicarious","text":"","code":""},{"path":"beh-expect-cue.html","id":"for-the-vicarious-task-what-is-the-effect-of-cue-on-expectation-ratings","chapter":"2 beh :: expectation ~ cue","heading":"For the vicarious task, what is the effect of cue on expectation ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-expect-cue.html","id":"cognitive","chapter":"2 beh :: expectation ~ cue","heading":"2.3 Cognitive","text":"","code":""},{"path":"beh-expect-cue.html","id":"for-the-cognitive-task-what-is-the-effect-of-cue-on-expectation-ratings","chapter":"2 beh :: expectation ~ cue","heading":"For the cognitive task, what is the effect of cue on expectation ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-expect-cue.html","id":"individual-difference-analysis","chapter":"2 beh :: expectation ~ cue","heading":"2.4 Individual difference analysis","text":"","code":""},{"path":"beh-expect-cue.html","id":"are-cue-effects-on-expectation-ratings-similar-across-tasks","chapter":"2 beh :: expectation ~ cue","heading":"Are cue effects (on expectation ratings) similar across tasks?","text":"Using random slopes cue effects, plot side side\nthree tasks pain, cognitive, vicarious. can see, \nhigh correlation across random effects cue across\npain-cognitive, pain-vicarious, cognitive-vicarious. plots\nsuggest universal mechansim cue-expectancy effect, although\nmay critic cues identical across tasks, thereby \ncue effects identical due stimuli , necessarily \ndomain-general expectation process.","code":"## Warning: Removed 3 rows containing non-finite values (`stat_cor()`).## Warning: Removed 3 rows containing missing values (`geom_point()`).## Warning: Removed 1 rows containing non-finite values (`stat_cor()`).## Warning: Removed 1 rows containing missing values (`geom_point()`).## Warning: Removed 3 rows containing non-finite values (`stat_cor()`).## Warning: Removed 3 rows containing missing values (`geom_point()`)."},{"path":"beh-outcome-cue.html","id":"beh-outcome-cue","chapter":"3 beh :: outcome ~ cue","heading":"3 beh :: outcome ~ cue","text":"","code":""},{"path":"beh-outcome-cue.html","id":"what-is-the-purpose-of-this-notebook-1","chapter":"3 beh :: outcome ~ cue","heading":"What is the purpose of this notebook?","text":", plot outcome ratings function cue.Main model: lmer(outcome_rating ~ cue)Main question: outcome ratings differ function cue type?main effect cue outcome ratings, cue effect differ depending task type?IV: cue (high / low)DV: outcome ratingFIX: plot statistics random effect plot - broken?","code":"\n# parameters _____________________________________ # nolint\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"; iv_keyword <- \"cue\"; dv <- \"event04_actual_angle\"; dv_keyword <- \"outcome\"\nxlab <- \"\"; ylim = c(0,180); ylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001|sub-0003|sub-0004|sub-0005|sub-0025|sub-0999\"\nsubjectwise_mean <- \"mean_per_sub\"; group_mean <- \"mean_per_sub_norm_mean\"; se <- \"se\"\ncolor_scheme <-     if (any(startsWith(dv_keyword, c(\"expect\", \"Expect\")))) {\n        color_scheme <- c(\"#1B9E77\", \"#D95F02\")\n    } else {\n        color_scheme <- c(\"#4575B4\", \"#D73027\")\n    }\nprint_lmer_output <- FALSE\nggtitle_phrase <- \" - Outcome Rating (degree)\"\nanalysis_dir <- file.path(main_dir, \"analysis\", \"mixedeffect\", \"model03_iv-cue_dv-outcome\", as.character(Sys.Date()))\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)"},{"path":"beh-outcome-cue.html","id":"pain-1","chapter":"3 beh :: outcome ~ cue","heading":"3.1 Pain","text":"","code":""},{"path":"beh-outcome-cue.html","id":"for-the-vicarious-task-what-is-the-effect-of-cue-on-outcome-ratings","chapter":"3 beh :: outcome ~ cue","heading":"For the vicarious task, what is the effect of cue on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-outcome-cue.html","id":"vicarious-1","chapter":"3 beh :: outcome ~ cue","heading":"3.2 Vicarious","text":"","code":""},{"path":"beh-outcome-cue.html","id":"for-the-vicarious-task-what-is-the-effect-of-cue-on-outcome-ratings-1","chapter":"3 beh :: outcome ~ cue","heading":"For the vicarious task, what is the effect of cue on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-outcome-cue.html","id":"cognitive-1","chapter":"3 beh :: outcome ~ cue","heading":"3.3 Cognitive","text":"","code":""},{"path":"beh-outcome-cue.html","id":"for-the-cognitive-task-what-is-the-effect-of-cue-on-outcome-ratings","chapter":"3 beh :: outcome ~ cue","heading":"For the cognitive task, what is the effect of cue on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-outcome-cue.html","id":"individual-differences-analysis-random-cue-effects","chapter":"3 beh :: outcome ~ cue","heading":"3.4 Individual differences analysis: random cue effects","text":"Using random effects mixed effects model, ’m plotting random effect cue types per task.[ INSERT DESCRIPTION ]Note:Pain: Warning: Removed 2 rows containing non-finite values (stat_cor()).Vicarious: Warning: Removed 1 rows containing non-finite values (stat_cor()).Cognitive: Warning: Removed 2 rows containing non-finite values (stat_cor()).","code":""},{"path":"beh-outcome-cue.html","id":"individual-differences-analysis-2-random-intercept-random-slopes-of-cue-effect","chapter":"3 beh :: outcome ~ cue","heading":"3.5 Individual differences analysis 2: random intercept + random slopes of cue effect","text":"based Tor’s suggestion, plotting random efects random intercepts well. just cue effectsNote:Pain: Warning: Removed 49 rows containing non-finite values (stat_cor()).Vicarious: Removed 8 rows containing non-finite values (stat_cor()).Cognitive: Removed 52 rows containing non-finite values (stat_cor()).","code":""},{"path":"beh-outcome-stim.html","id":"beh-outcome-stim","chapter":"4 beh :: outcome ~ stim","heading":"4 beh :: outcome ~ stim","text":"","code":""},{"path":"beh-outcome-stim.html","id":"what-is-the-purpose-of-this-notebook-2","chapter":"4 beh :: outcome ~ stim","heading":"What is the purpose of this notebook?","text":", plot outcome ratings function stimulus intensityMain model: lmer(outcome_rating ~ stim)Main question: outcome ratings differ function stimulus intensity? expect see linear effect stimulus intensity.main effect cue expectation ratings, cue effect differ depending task type?IV: stim (high / med / low)DV: outcome ratingFIX: plot statistics random effect plot - broken?","code":"\n# parameters _____________________________________ # nolint\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_stimulus_type\"; iv_keyword <- \"stim\"; dv <- \"event04_actual_angle\"; dv_keyword <- \"outcome\"\nxlab <- \"\"; ylim = c(0,180); ylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001|sub-0003|sub-0004|sub-0005|sub-0025|sub-0999\"\nsubjectwise_mean <- \"mean_per_sub\"; group_mean <- \"mean_per_sub_norm_mean\"; se <- \"se\"\ncolor_scheme <-     if (any(startsWith(dv_keyword, c(\"expect\", \"Expect\")))) {\n        color_scheme <- c(\"#1B9E77\", \"#D95F02\")\n    } else {\n        color_scheme <- c(\"#4575B4\", \"#D73027\")\n    }\nprint_lmer_output <- FALSE\nggtitle_phrase <- \" - Outcome Rating (degree)\"\nanalysis_dir <- file.path(main_dir, \"analysis\", \"mixedeffect\", paste0(\"model04_iv-\",iv_keyword,\"_dv-\",dv_keyword), as.character(Sys.Date()))\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)"},{"path":"beh-outcome-stim.html","id":"pain-2","chapter":"4 beh :: outcome ~ stim","heading":"4.1 Pain","text":"","code":""},{"path":"beh-outcome-stim.html","id":"for-the-pain-task-what-is-the-effect-of-stimulus-intensity-on-outcome-ratings","chapter":"4 beh :: outcome ~ stim","heading":"For the pain task, what is the effect of stimulus intensity on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":"## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated."},{"path":"beh-outcome-stim.html","id":"vicarious-2","chapter":"4 beh :: outcome ~ stim","heading":"4.2 Vicarious","text":"","code":""},{"path":"beh-outcome-stim.html","id":"for-the-vicarious-task-what-is-the-effect-of-stimulus-intensity-on-outcome-ratings","chapter":"4 beh :: outcome ~ stim","heading":"For the vicarious task, what is the effect of stimulus intensity on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":"## Warning: Model failed to converge with 1 negative eigenvalue: -8.5e+01## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill"},{"path":"beh-outcome-stim.html","id":"cognitive-2","chapter":"4 beh :: outcome ~ stim","heading":"4.3 Cognitive","text":"","code":""},{"path":"beh-outcome-stim.html","id":"for-the-cognitive-task-what-is-the-effect-of-stimulus-intensity-on-outcome-ratings","chapter":"4 beh :: outcome ~ stim","heading":"For the cognitive task, what is the effect of stimulus intensity on outcome ratings?","text":"[ INSERT DESCRIPTION ]","code":"## Warning: Model failed to converge with 1 negative eigenvalue: -1.1e+02## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill"},{"path":"beh-outcome-stim.html","id":"for-loop","chapter":"4 beh :: outcome ~ stim","heading":"4.4 for loop","text":"","code":"## boundary (singular) fit: see help('isSingular')## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 52938.5\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5365 -0.5608 -0.0002  0.5695  4.6143 \n## \n## Random effects:\n##  Groups         Name                        Variance Std.Dev. Corr       \n##  src_subject_id (Intercept)                 952.46   30.862              \n##                 param_stimulus_typelow_stim 127.22   11.279   -0.47      \n##                 param_stimulus_typemed_stim  29.79    5.458   -0.24  0.97\n##  Residual                                   448.14   21.169              \n## Number of obs: 5851, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)                  80.3242     2.9886 109.1411   26.88   <2e-16 ***\n## param_stimulus_typelow_stim -29.2521     1.2974 107.5783  -22.55   <2e-16 ***\n## param_stimulus_typemed_stim -13.7621     0.8652 148.5592  -15.90   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                 (Intr) prm_stmls_typl_\n## prm_stmls_typl_ -0.455                \n## prm_stmls_typm_ -0.236  0.718         \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Coordinate system already present. Adding new coordinate system, which will\n## replace the existing one.\n## boundary (singular) fit: see help('isSingular')## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 56882.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.5482 -0.5779 -0.1812  0.4475  6.1884 \n## \n## Random effects:\n##  Groups         Name                        Variance Std.Dev. Corr       \n##  src_subject_id (Intercept)                 283.44   16.836              \n##                 param_stimulus_typelow_stim 172.13   13.120   -0.88      \n##                 param_stimulus_typemed_stim  98.63    9.931   -0.85  1.00\n##  Residual                                   448.25   21.172              \n## Number of obs: 6313, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)                   40.822      1.681 108.598   24.29   <2e-16 ***\n## param_stimulus_typelow_stim  -24.936      1.426 109.210  -17.49   <2e-16 ***\n## param_stimulus_typemed_stim  -17.614      1.162 114.541  -15.15   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                 (Intr) prm_stmls_typl_\n## prm_stmls_typl_ -0.837                \n## prm_stmls_typm_ -0.784  0.862         \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Coordinate system already present. Adding new coordinate system, which will\n## replace the existing one.## boundary (singular) fit: see help('isSingular')## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 54866.8\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.7173 -0.6283 -0.1660  0.4545  7.0548 \n## \n## Random effects:\n##  Groups         Name                        Variance Std.Dev. Corr       \n##  src_subject_id (Intercept)                 176.9233 13.3013             \n##                 param_stimulus_typelow_stim   8.2230  2.8676  -0.75      \n##                 param_stimulus_typemed_stim   0.4181  0.6466   0.37  0.33\n##  Residual                                   374.7596 19.3587             \n## Number of obs: 6220, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)                  31.4642     1.3417 109.5625  23.451   <2e-16 ***\n## param_stimulus_typelow_stim  -8.1551     0.6623 106.7910 -12.313   <2e-16 ***\n## param_stimulus_typemed_stim  -1.0096     0.6056 718.4229  -1.667   0.0959 .  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                 (Intr) prm_stmls_typl_\n## prm_stmls_typl_ -0.500                \n## prm_stmls_typm_ -0.186  0.465         \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Coordinate system already present. Adding new coordinate system, which will\n## replace the existing one."},{"path":"beh-outcome-stim.html","id":"lineplot","chapter":"4 beh :: outcome ~ stim","heading":"4.5 Lineplot","text":"","code":"\nlibrary(ggpubr)\nDATA = as.data.frame(combined_se_calc_cooksd)\ncolor = c( \"#4575B4\", \"#D73027\")\nLINEIV1 = \"stim_ordered\"\nLINEIV2 = \"cue_ordered\"\nMEAN = \"mean_per_sub_norm_mean\"\nERROR = \"se\"\ndv_keyword = \"actual\"\np1 = plot_lineplot_onefactor(DATA, 'pain',\n               LINEIV1, MEAN, ERROR, color, xlab = \"Stimulus intensity\" , ylab= \"Outcome rating\", ggtitle = 'pain' )\np2 = plot_lineplot_onefactor(DATA,'vicarious',\n               LINEIV1, MEAN, ERROR, color,xlab = \"Stimulus intensity\" , ylab= \"Outcome rating\",ggtitle = 'vicarious')\np3 = plot_lineplot_onefactor(DATA, 'cognitive',\n               LINEIV1, MEAN, ERROR, color,xlab = \"Stimulus intensity\" , ylab= \"Outcome rating\",ggtitle = 'cognitive')\n#grid.arrange(p1, p2, p3, ncol=3 , common.legend = TRUE)\nggpubr::ggarrange(p1,p2,p3,ncol = 3, nrow = 1, common.legend = TRUE,legend = \"bottom\")\nplot_filename = file.path(analysis_dir,\n                          paste('lineplot_task-all_rating-',dv_keyword,'.png', sep = \"\"))\nggsave(plot_filename, width = 15, height = 6)"},{"path":"beh-outcome-stim.html","id":"individual-differences-in-outcome-rating-cue-effect","chapter":"4 beh :: outcome ~ stim","heading":"4.6 individual differences in outcome rating cue effect","text":"[ INSERT DESCRIPTION ]","code":""},{"path":"beh-outcome-cueXstim.html","id":"beh-outcome-cueXstim","chapter":"5 beh :: outcome ~ cue * stim","heading":"5 beh :: outcome ~ cue * stim","text":"","code":""},{"path":"beh-outcome-cueXstim.html","id":"what-is-the-purpose-of-this-notebook-3","chapter":"5 beh :: outcome ~ cue * stim","heading":"What is the purpose of this notebook?","text":", plot outcome ratings function cue stimulus intensity.Main model: lmer(outcome_rating ~ cue * stim)Main question: outcome ratings differ function cue type stimulus intensity?main effect cue outcome ratings, cue effect differ depending task type?interaction two factors?IV:\ncue (high / low)\nstim (high / med / low)\ncue (high / low)stim (high / med / low)DV: outcome rating","code":""},{"path":"beh-outcome-cueXstim.html","id":"cue-contrasts","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.1 Cue contrasts","text":"lmer(Outcome ~ Cue_contrast)IV: Stim X Cue_contrastDV: Outcome rating","code":""},{"path":"beh-outcome-cueXstim.html","id":"todo-model-03-3-2.-individual-differences","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.2 TODO: model 03 3-2. individual differences","text":"","code":""},{"path":"beh-outcome-cueXstim.html","id":"delete-after-sandbox","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.2.1 DELETE AFTER SANDBOX","text":"","code":""},{"path":"beh-outcome-cueXstim.html","id":"cue-x-stim-raincloud-plots","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.3 Cue X Stim Raincloud plots","text":"IV: Cue x stimDV: Outcome rating","code":"## TableGrob (1 x 2) \"arrange\": 2 grobs\n##   z     cells    name              grob\n## 1 1 (1-1,1-1) arrange    gtable[layout]\n## 2 2 (1-1,2-2) arrange gtable[guide-box]## TableGrob (1 x 2) \"arrange\": 2 grobs\n##   z     cells    name              grob\n## 1 1 (1-1,1-1) arrange    gtable[layout]\n## 2 2 (1-1,2-2) arrange gtable[guide-box]## TableGrob (1 x 2) \"arrange\": 2 grobs\n##   z     cells    name              grob\n## 1 1 (1-1,1-1) arrange    gtable[layout]\n## 2 2 (1-1,2-2) arrange gtable[guide-box]"},{"path":"beh-outcome-cueXstim.html","id":"cue-x-stim-linear-model","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.3.1 Cue X Stim linear model","text":"\nMultilevel-modeling:\nlmer(OUTCOME ~ CUE * STIM + (CUE * STIM | sub), data = pvc)\n","code":"\n    # stim_con1 <- \"STIM_linear\"\n    # stim_con2 <- \"STIM_quadratic\"\n    # iv1 <- \"CUE_high_gt_low\"\n    # dv <- \"OUTCOME\"\n\n\nlibrary(Matrix)\nlibrary(glmmTMB)## Warning in checkDepPackageVersion(dep_pkg = \"TMB\"): Package version inconsistency detected.\n## glmmTMB was built with TMB version 1.9.6\n## Current TMB version is 1.9.10\n## Please re-install glmmTMB from source or restore original 'TMB' package (see '?reinstalling' for more information)\nlibrary(TMB)\nlibrary(RcppEigen)\n\ndf <- data[!is.na(data$OUTCOME), ]\n\nfullmodel <-\n  lmer(\n    OUTCOME ~ CUE_high_gt_low * STIM_linear + (\n      CUE_high_gt_low * STIM_linear  |\n        subject\n    ),\n    data = df\n\n  )## boundary (singular) fit: see help('isSingular')\n# TODO:: troubleshoot\n# m <- glmmTMB(OUTCOME ~ CUE_high_gt_low * STIM_linear + ( CUE_high_gt_low * STIM_linear  | subject),\n#              data = df,\n#              control = glmmTMBControl(rank_check = \"adjust\"))\n#              #start = start_values,\n#\n# summary(m)\n\nsjPlot::tab_model(fullmodel,\n                  title = \"Multilevel-modeling: \\nlmer(OUTCOME ~ CUE * STIM + (CUE * STIM | sub), data = pvc)\",\n                  CSS = list(css.table = '+font-size: 12;'))"},{"path":"beh-outcome-cueXstim.html","id":"individual-differences-in-cue-effects","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.4 Individual differences in cue effects","text":"","code":""},{"path":"beh-outcome-cueXstim.html","id":"cue-x-stim-lineplot","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.5 Cue X Stim Lineplot","text":"Instead rain cloud plots, , plot lines confidence interval\ncue x stim combination. Plotted per task.","code":""},{"path":"beh-outcome-cueXstim.html","id":"clinical-trials","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.6 Clinical trials","text":"","code":""},{"path":"beh-outcome-cueXstim.html","id":"cue-contrast-average-across-intensity","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.7 cue contrast average across intensity","text":"","code":"## [1] \"pain\"\n## [1] 8.203947\n## [1] 0.8871599\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"61.6884121864272\" \"2.860880140792\"  \n## [1] \"high\"             \"70.2234946843967\" \"2.85365310068339\"\n## [1] \"vicarious\"\n## [1] 7.69279\n## [1] 0.6584873\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"22.7808026788692\" \"1.0440409512757\" \n## [1] \"high\"             \"30.636407755966\"  \"1.20480098494488\"\n## [1] \"cognitive\"\n## [1] 8.019356\n## [1] 0.7038933\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"24.308987672219\"  \"1.19373008209444\"\n## [1] \"high\"             \"32.34623546235\"   \"1.37653031156445\""},{"path":"beh-outcome-cueXstim.html","id":"cue-contrast-average-across-expectation","chapter":"5 beh :: outcome ~ cue * stim","heading":"5.8 cue contrast average across expectation","text":"https://stackoverflow.com/questions/29402528/append-data-frames-together----loop/29419402","code":"## [1] \"pain\"\n## [1] 35.05694\n## [1] 1.989724\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"44.6580941421071\" \"3.02430373086043\"\n## [1] \"high\"             \"79.4644108331637\" \"2.85584321656255\"\n## [1] \"vicarious\"\n## [1] 33.25123\n## [1] 1.503149\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"14.9314711535258\" \"1.00860750130232\"\n## [1] \"high\"             \"48.146271174259\"  \"1.54236667339445\"\n## [1] \"cognitive\"\n## [1] 30.7638\n## [1] 1.53046\n## [1] \"high vs. low cue\"\n## [1] \"low\"              \"18.5956241315907\" \"1.20836045474955\"\n## [1] \"high\"             \"49.3940294143433\" \"1.73640570707356\""},{"path":"jepma.html","id":"jepma","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6 beh :: expect-outcome ~ cue * trial","text":"","code":""},{"path":"jepma.html","id":"overview","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.1 Overview","text":"purpose markdown benchmark plots Jepma et al. (2018).\n, plot expectancy ratings actual ratings, high low cues – one panel.","code":""},{"path":"jepma.html","id":"some-thoughts-todos","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"Some thoughts, TODOs","text":"plot 2. runs repeated omitted subjects 72 trials. need identify list work behavioral data.need check whether counterbalancing done correctly.load data combine participant data","code":"\nmain_dir = dirname(dirname(getwd()))\ndatadir = file.path(main_dir, 'data', 'beh', 'beh02_preproc')\n# parameters _____________________________________ # nolint\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"\ndv <- \"event03_RT\"\ndv_keyword <- \"RT\"\nxlab <- \"\"\ntaskname <- \"pain\"\n\nylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001|sub-0003|sub-0004|sub-0005|sub-0025|sub-0999\" #/ \"sub-0999|sub-0001|sub-0002|sub-0003|sub-0004|sub-0005|sub-0006|sub-0007|sub-0008|sub-0009|sub-0010|sub-0011\"\n\n# load data _____________________________________\ndata <- df_load_beh(datadir, taskname = taskname, subject_varkey = subject_varkey, iv = iv, exclude = exclude)\ndata$event03_RT <- data$event03_stimulusC_reseponseonset - data$event03_stimulus_displayonset\n# data['event03_RT'], data.event03_RT - pandas\nanalysis_dir <- file.path(main_dir, \"analysis\", \"mixedeffect\", \"model06_iv-cue-trial_dv-expect-actual\", as.character(Sys.Date()))\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)\nsummary(data)##  src_subject_id     session_id    param_task_name    param_run_num   \n##  Min.   :  2.00   Min.   :1.000   Length:6492        Min.   :-2.000  \n##  1st Qu.: 37.00   1st Qu.:1.000   Class :character   1st Qu.: 2.000  \n##  Median : 73.00   Median :3.000   Mode  :character   Median : 3.000  \n##  Mean   : 69.86   Mean   :2.595                      Mean   : 3.462  \n##  3rd Qu.:101.00   3rd Qu.:4.000                      3rd Qu.: 5.000  \n##  Max.   :133.00   Max.   :4.000                      Max.   : 6.000  \n##                                                                      \n##  param_counterbalance_ver param_counterbalance_block_num param_cue_type    \n##  Min.   :1.000            Min.   :1.000                  Length:6492       \n##  1st Qu.:2.000            1st Qu.:1.000                  Class :character  \n##  Median :3.000            Median :2.000                  Mode  :character  \n##  Mean   :3.157            Mean   :1.503                                    \n##  3rd Qu.:4.000            3rd Qu.:2.000                                    \n##  Max.   :5.000            Max.   :2.000                                    \n##                                                                            \n##  param_stimulus_type param_cond_type param_trigger_onset param_start_biopac \n##  Length:6492         Min.   :1.0     Min.   :1.615e+09   Min.   :1.615e+09  \n##  Class :character    1st Qu.:2.0     1st Qu.:1.627e+09   1st Qu.:1.627e+09  \n##  Mode  :character    Median :3.5     Median :1.632e+09   Median :1.632e+09  \n##                      Mean   :3.5     Mean   :1.634e+09   Mean   :1.634e+09  \n##                      3rd Qu.:5.0     3rd Qu.:1.644e+09   3rd Qu.:1.644e+09  \n##                      Max.   :6.0     Max.   :1.657e+09   Max.   :1.657e+09  \n##                                                                             \n##    ITI_onset           ITI_biopac         ITI_duration      event01_cue_onset  \n##  Min.   :1.615e+09   Min.   :1.615e+09   Min.   : 0.00281   Min.   :1.615e+09  \n##  1st Qu.:1.627e+09   1st Qu.:1.627e+09   1st Qu.: 1.56340   1st Qu.:1.627e+09  \n##  Median :1.632e+09   Median :1.632e+09   Median : 3.26975   Median :1.632e+09  \n##  Mean   :1.634e+09   Mean   :1.634e+09   Mean   : 4.44243   Mean   :1.634e+09  \n##  3rd Qu.:1.644e+09   3rd Qu.:1.644e+09   3rd Qu.: 6.65337   3rd Qu.:1.644e+09  \n##  Max.   :1.657e+09   Max.   :1.657e+09   Max.   :17.07488   Max.   :1.657e+09  \n##                                                                                \n##  event01_cue_biopac  event01_cue_type   event01_cue_filename\n##  Min.   :1.615e+09   Length:6492        Length:6492         \n##  1st Qu.:1.627e+09   Class :character   Class :character    \n##  Median :1.632e+09   Mode  :character   Mode  :character    \n##  Mean   :1.634e+09                                          \n##  3rd Qu.:1.644e+09                                          \n##  Max.   :1.657e+09                                          \n##                                                             \n##   ISI01_onset         ISI01_biopac       ISI01_duration   \n##  Min.   :1.615e+09   Min.   :1.615e+09   Min.   :0.00396  \n##  1st Qu.:1.627e+09   1st Qu.:1.627e+09   1st Qu.:0.99133  \n##  Median :1.632e+09   Median :1.632e+09   Median :1.39215  \n##  Mean   :1.634e+09   Mean   :1.634e+09   Mean   :1.47844  \n##  3rd Qu.:1.644e+09   3rd Qu.:1.644e+09   3rd Qu.:1.98314  \n##  Max.   :1.657e+09   Max.   :1.657e+09   Max.   :2.89685  \n##                                                           \n##  event02_expect_displayonset event02_expect_biopac event02_expect_responseonset\n##  Min.   :1.615e+09           Min.   :1.615e+09     Min.   :1.615e+09           \n##  1st Qu.:1.627e+09           1st Qu.:1.627e+09     1st Qu.:1.627e+09           \n##  Median :1.632e+09           Median :1.632e+09     Median :1.632e+09           \n##  Mean   :1.634e+09           Mean   :1.634e+09     Mean   :1.634e+09           \n##  3rd Qu.:1.644e+09           3rd Qu.:1.644e+09     3rd Qu.:1.643e+09           \n##  Max.   :1.657e+09           Max.   :1.657e+09     Max.   :1.657e+09           \n##                                                    NA's   :661                 \n##  event02_expect_RT event02_expect_angle event02_expect_angle_label\n##  Min.   :0.6504    Min.   :  0.00       Length:6492               \n##  1st Qu.:1.6341    1st Qu.: 30.18       Class :character          \n##  Median :2.0517    Median : 58.56       Mode  :character          \n##  Mean   :2.1397    Mean   : 62.94                                 \n##  3rd Qu.:2.5678    3rd Qu.: 90.00                                 \n##  Max.   :3.9912    Max.   :180.00                                 \n##  NA's   :661       NA's   :661                                    \n##   ISI02_onset         ISI02_biopac       ISI02_duration   \n##  Min.   :1.615e+09   Min.   :1.615e+09   Min.   : 0.1422  \n##  1st Qu.:1.627e+09   1st Qu.:1.627e+09   1st Qu.: 1.8599  \n##  Median :1.632e+09   Median :1.632e+09   Median : 4.3664  \n##  Mean   :1.634e+09   Mean   :1.634e+09   Mean   : 4.4542  \n##  3rd Qu.:1.644e+09   3rd Qu.:1.644e+09   3rd Qu.: 6.2697  \n##  Max.   :1.657e+09   Max.   :1.657e+09   Max.   :20.0723  \n##                                                           \n##  event03_stimulus_type event03_stimulus_displayonset event03_stimulus_biopac\n##  Length:6492           Min.   :1.615e+09             Min.   :1.615e+09      \n##  Class :character      1st Qu.:1.627e+09             1st Qu.:1.627e+09      \n##  Mode  :character      Median :1.632e+09             Median :1.632e+09      \n##                        Mean   :1.634e+09             Mean   :1.634e+09      \n##                        3rd Qu.:1.644e+09             3rd Qu.:1.644e+09      \n##                        Max.   :1.657e+09             Max.   :1.657e+09      \n##                                                                             \n##  event03_stimulus_C_stim_match event03_stimulusC_response\n##  Mode:logical                  Min.   :0                 \n##  NA's:6492                     1st Qu.:0                 \n##                                Median :0                 \n##                                Mean   :0                 \n##                                3rd Qu.:0                 \n##                                Max.   :0                 \n##                                                          \n##  event03_stimulusC_responsekeyname event03_stimulusC_reseponseonset\n##  Mode:logical                      Min.   :0                       \n##  NA's:6492                         1st Qu.:0                       \n##                                    Median :0                       \n##                                    Mean   :0                       \n##                                    3rd Qu.:0                       \n##                                    Max.   :0                       \n##                                                                    \n##  event03_stimulusC_RT  ISI03_onset         ISI03_biopac       ISI03_duration   \n##  Min.   :0            Min.   :1.615e+09   Min.   :1.615e+09   Min.   : 0.4788  \n##  1st Qu.:0            1st Qu.:1.627e+09   1st Qu.:1.627e+09   1st Qu.: 2.3846  \n##  Median :0            Median :1.632e+09   Median :1.632e+09   Median : 4.0370  \n##  Mean   :0            Mean   :1.634e+09   Mean   :1.634e+09   Mean   : 4.4870  \n##  3rd Qu.:0            3rd Qu.:1.644e+09   3rd Qu.:1.644e+09   3rd Qu.: 5.8864  \n##  Max.   :0            Max.   :1.657e+09   Max.   :1.657e+09   Max.   :17.6951  \n##                                                                                \n##  event04_actual_displayonset event04_actual_biopac event04_actual_responseonset\n##  Min.   :1.615e+09           Min.   :1.615e+09     Min.   :1.615e+09           \n##  1st Qu.:1.627e+09           1st Qu.:1.627e+09     1st Qu.:1.627e+09           \n##  Median :1.632e+09           Median :1.632e+09     Median :1.631e+09           \n##  Mean   :1.634e+09           Mean   :1.634e+09     Mean   :1.634e+09           \n##  3rd Qu.:1.644e+09           3rd Qu.:1.644e+09     3rd Qu.:1.643e+09           \n##  Max.   :1.657e+09           Max.   :1.657e+09     Max.   :1.657e+09           \n##                                                    NA's   :638                 \n##  event04_actual_RT event04_actual_angle event04_actual_angle_label\n##  Min.   :0.0168    Min.   :  0.00       Length:6492               \n##  1st Qu.:1.9197    1st Qu.: 38.80       Class :character          \n##  Median :2.3510    Median : 60.77       Mode  :character          \n##  Mean   :2.4005    Mean   : 66.33                                 \n##  3rd Qu.:2.8512    3rd Qu.: 88.38                                 \n##  Max.   :3.9930    Max.   :180.00                                 \n##  NA's   :638       NA's   :641                                    \n##  param_end_instruct_onset param_end_biopac    param_experiment_duration\n##  Min.   :1.615e+09        Min.   :1.615e+09   Min.   :398.1            \n##  1st Qu.:1.627e+09        1st Qu.:1.627e+09   1st Qu.:398.6            \n##  Median :1.632e+09        Median :1.632e+09   Median :398.8            \n##  Mean   :1.634e+09        Mean   :1.634e+09   Mean   :398.8            \n##  3rd Qu.:1.644e+09        3rd Qu.:1.644e+09   3rd Qu.:399.0            \n##  Max.   :1.657e+09        Max.   :1.657e+09   Max.   :399.5            \n##                                                                        \n##  event03_stimulus_P_trigger event03_stimulus_P_delay_between_medoc\n##  Length:6492                Min.   :0                             \n##  Class :character           1st Qu.:0                             \n##  Mode  :character           Median :0                             \n##                             Mean   :0                             \n##                             3rd Qu.:0                             \n##                             Max.   :0                             \n##                                                                   \n##  event03_stimulus_V_patientid event03_stimulus_V_filename\n##  Mode:logical                 Mode:logical               \n##  NA's:6492                    NA's:6492                  \n##                                                          \n##                                                          \n##                                                          \n##                                                          \n##                                                          \n##  event03_stimulus_C_stim_num event03_stimulus_C_stim_filename\n##  Min.   :0                   Mode:logical                    \n##  1st Qu.:0                   NA's:6492                       \n##  Median :0                                                   \n##  Mean   :0                                                   \n##  3rd Qu.:0                                                   \n##  Max.   :0                                                   \n##                                                              \n##  delay_between_medoc    subject       event03_RT        \n##  Min.   :0.01409     98     :  96   Min.   :-1.657e+09  \n##  1st Qu.:0.03728     6      :  72   1st Qu.:-1.644e+09  \n##  Median :0.04537     9      :  72   Median :-1.632e+09  \n##  Mean   :0.04818     10     :  72   Mean   :-1.634e+09  \n##  3rd Qu.:0.05712     18     :  72   3rd Qu.:-1.627e+09  \n##  Max.   :2.03502     29     :  72   Max.   :-1.615e+09  \n##                      (Other):6036\n# data(data, package = 'visibly')\n\nmyvars <- names(data) %in%\n  c( \"event02_expect_angle\", \"event02_expect_RT\", \"event04_actual_angle\", \"event04_actual_RT\", \"event01_cue_onset\")\nnewdata <- data[myvars]\n# numdata  <- unlist(lapply(data, is.numeric), use.names = FALSE)\ndata_naomit <- na.omit(newdata)\ncor_matrix = cor(data_naomit)\ncorr_heat(cor_matrix)## No FA options specified, using psych package defaults.## Warning in fac(r = r, nfactors = nfactors, n.obs = n.obs, rotate = rotate, : I\n## am sorry, to do these rotations requires the GPArotation package to be\n## installed\nISIvars <- names(data) %in%\n  c( \"ISI01_duration\", \"ISI02_duration\", \"ISI03_duration\")\nISIdata <- data[ISIvars]\n# numdata  <- unlist(lapply(data, is.numeric), use.names = FALSE)\nISIdata_naomit <- na.omit(ISIdata)\nISIcor_matrix = cor(ISIdata_naomit)\ncorr_heat(ISIcor_matrix)## No FA options specified, using psych package defaults.\ncar::vif(lm(event04_actual_angle ~  event02_expect_angle + event02_expect_RT + event04_actual_RT, dat = data_naomit))## event02_expect_angle    event02_expect_RT    event04_actual_RT \n##             1.019462             1.084419             1.099422"},{"path":"jepma.html","id":"plot-1---one-run-average-across-participants","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.2 plot 1 - one run, average across participants","text":"ggplot","code":"\n# subject # run # param_cue # param_stim # rating_type # rating_value\n\ndata_trial= data %>%\n  arrange(src_subject_id, session_id, param_run_num) %>%\n  group_by(src_subject_id) %>%\n  mutate(trial_index = rep_len(1:12, length.out = n()))\ndata_long = data_trial %>%\n  pivot_longer(cols = c('event02_expect_angle', 'event04_actual_angle'),\n               names_to = \"rating_type\",\n               values_to = \"rating_value\")\n# # PLOT\n    data_long$cue_name[data_long$param_cue_type == \"high_cue\"] <- \"high cue\"## Warning: Unknown or uninitialised column: `cue_name`.\n    data_long$cue_name[data_long$param_cue_type == \"low_cue\"] <- \"low cue\"\n\n    data_long$stim_name[data_long$param_stimulus_type == \"high_stim\"] <- \"high\"## Warning: Unknown or uninitialised column: `stim_name`.\n    data_long$stim_name[data_long$param_stimulus_type == \"med_stim\"] <- \"med\"\n    data_long$stim_name[data_long$param_stimulus_type == \"low_stim\"] <- \"low\"\n\n    data_long$stim_ordered <- factor(\n        data_long$stim_name,\n        levels = c(\"low\", \"med\", \"high\")\n    )\n    data_long$cue_ordered <- factor(\n        data_long$cue_name,\n        levels = c(\"low cue\", \"high cue\")\n    )\n    subject <- \"src_subject_id\"\n    model_iv1 <- \"stim_ordered\"\n    model_iv2 <- \"cue_ordered\"\n    rating <- \"rating_type\"\n    dv <- \"rating_value\"\n    trialorder_subjectwise <- meanSummary(\n        data_long,\n        c(subject, model_iv2, rating, \"trial_index\"), dv\n    )\n\n    subjectwise_naomit <- na.omit(trialorder_subjectwise)\n\n    trialorder_groupwise <- summarySEwithin(\n        data = subjectwise_naomit,\n        measurevar = \"mean_per_sub\",\n        withinvars = c(\"cue_ordered\", \"rating_type\",  \"trial_index\"), idvar = subject\n    )## Automatically converting the following non-factors to factors: rating_type, trial_index\ntrialorder_subjectwise$rating_type_key <- mapvalues(trialorder_subjectwise$rating_type,\n                                                from = c(\"event02_expect_angle\", \"event04_actual_angle\"),\n                                                to = c(\"expect\", \"actual\"))\ntrialorder_groupwise$rating_type_key <- mapvalues(trialorder_groupwise$rating_type,\n                                                from = c(\"event02_expect_angle\", \"event04_actual_angle\"),\n                                                to = c(\"expect\", \"actual\"))\nactual_trialorder_groupwise <- trialorder_groupwise[which(trialorder_groupwise$rating_type_key == \"actual\"),]\nexpect_trialorder_groupwise <-trialorder_groupwise[which(trialorder_groupwise$rating_type_key == \"expect\"),]\nactual_trialorder_subjectwise <- trialorder_subjectwise[which(trialorder_subjectwise$rating_type_key == \"actual\"),]\nexpect_trialorder_subjectwise <-trialorder_subjectwise[which(trialorder_subjectwise$rating_type_key == \"expect\"),]\n# * dataset: trialorder_groupwise\n# * x-axis: trial_index (sorted)\n# * y-axis: rating\n# * group: cue_ordered, rating_type\n# * DV: mean_per_sub_norm_mean\n# * error bar: se\n\niv1 = \"trial_index\"\niv2 = \"cue_ordered\"\ndata =\ng <- ggplot(\n  data = trialorder_groupwise,\n  aes(x = trial_index,\n      y = mean_per_sub_norm_mean,\n      color = cue_ordered,\n      group = rating_type_key\n      )\n  ) +\n    geom_point(\n    data = trialorder_groupwise,\n    aes(\n      shape = as.character(rating_type_key),\n      x =trial_index,\n      y = mean_per_sub_norm_mean,\n      group = rating_type_key,\n      #color = cue_ordered\n      ),\n    #position = position_jitter(width = .05),\n    size = 3\n    ) +\n  scale_shape_manual(values=c(16, 21))+\n\n  # geom_point(\n  #   data = trialorder_subjectwise,\n  #   aes(\n  #     x = as.numeric(trial_index) - .15,\n  #     y = mean_per_sub,\n  #     color = cue_ordered\n  #     ),\n  #   position = position_jitter(width = .05),\n  #   size = 1, alpha = 0.8, shape = 20\n  #   ) +\n  geom_errorbar(\n    data = trialorder_groupwise,\n    aes(\n      x = as.numeric(trial_index),\n      y = mean_per_sub_norm_mean,\n      group = rating_type_key,\n      colour = cue_ordered,\n      ymin = mean_per_sub_norm_mean - se,\n      ymax = mean_per_sub_norm_mean + se\n      ), width = .01, size = 0.5\n    ) +\n  scale_color_manual(values = c(\"high cue\" = \"red\",\n                                \"low cue\" = \"blue\")) +\n    xlab(\"no. of trials\") +\n  ylab(\"rating\") +\n  ylim(0,100) +\n  theme_bw() +\n  theme(    axis.text.x = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    axis.title.x = element_text(size = 15),\n    axis.title.y = element_text(size = 15))## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.\ng"},{"path":"jepma.html","id":"plot-2---average-across-participant-but-spread-all-6-runs-in-one-x-axis","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.3 plot 2 - average across participant, but spread all 6 runs in one x axis","text":"load data combine participant data","code":"\nmain_dir = dirname(dirname(getwd()))\ndatadir = file.path(main_dir, 'data', 'beh', 'beh02_preproc')\n# parameters _____________________________________ # nolint\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"\ndv <- \"event03_RT\"\ndv_keyword <- \"RT\"\nxlab <- \"\"\ntaskname <- \"pain\"\n\nylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0999|sub-0001|sub-0002|sub-0003|sub-0004|sub-0005|sub-0006|sub-0007|sub-0008|sub-0009|sub-0010|sub-0011\"\n\n# load data _____________________________________\ndata <- df_load_beh(datadir, taskname = taskname, subject_varkey = subject_varkey, iv = iv, exclude = exclude)"},{"path":"jepma.html","id":"p2-check-number-of-trials-per-participant","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"p2 :: check number of trials per participant","text":"","code":"\ndata_p2= data %>%\n  arrange(src_subject_id ) %>%\n  group_by(src_subject_id) %>%\n  mutate(trial_index = row_number())\n# df_clean <- data_p2[complete.cases(data_p2$event02_expect_angle), ]\ndf_clean <- data_p2[complete.cases(data_p2$event04_actual_angle), ]"},{"path":"jepma.html","id":"check-if-every-participant-has-maximum-of-72-trials.-anything-beyond-that-is-erroneous","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.3.0.1 check if every participant has maximum of 72 trials. Anything beyond that is erroneous","text":"","code":"\n# Assuming participant IDs are in a column named \"participant_id\"\n# and row numbers are in a column named \"row_number\"\n# Replace \"your_data\" with the name of your dataset\n\n# Calculate the maximum row number for each participant\nmax_rows <- aggregate(trial_index ~ src_subject_id, data_p2, max)\n\n# Check if any participant's maximum row number is not 72\nmax_rows[max_rows$trial_index > 72,]$src_subject_id## [1] 98"},{"path":"jepma.html","id":"p2-identify-erroneous-participant","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"p2 :: identify erroneous participant","text":"","code":"\n# participants who have more than 72 trials will be flagged\n# excluded for now\n# TODO: resolve subject 98\ncount_trial <- df_clean %>% count(\"src_subject_id\")\ncount_trial[count_trial$freq > 72,]## [1] src_subject_id freq          \n## <0 rows> (or 0-length row.names)\ncount_trial[count_trial$freq > 60,]$src_subject_id##  [1]  18  29  31  33  34  36  37  38  39  43  44  46  50  51  52  53  55  57  58\n## [20]  60  61  62  65  73  74  78  80  86  87  88  90  91  93  94  95  99 100 101\n## [39] 105 106 109 111 115 116 122 124 126 127 128 130 132 133"},{"path":"jepma.html","id":"p2-convert-to-long-form","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"p2 :: convert to long form","text":"","code":"\ndf_clean <- df_clean[df_clean$src_subject_id != 98, ]\ndata_p2_long = df_clean %>%\n  pivot_longer(cols = c('event02_expect_angle', 'event04_actual_angle'),\n               names_to = \"rating_type\",\n               values_to = \"rating_value\")"},{"path":"jepma.html","id":"p2-plot-data","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"p2 :: plot data","text":"’m plotting trials per participant. case, trialwise variability, ’re plotting 72 trials.\nAveraging across participants source variability, reflected error barsggplot","code":"\n# PLOT\n  # I'm plotting\n    data_p2_long$cue_name[data_p2_long$param_cue_type == \"high_cue\"] <- \"high cue\"## Warning: Unknown or uninitialised column: `cue_name`.\n    data_p2_long$cue_name[data_p2_long$param_cue_type == \"low_cue\"] <- \"low cue\"\n\n    data_p2_long$stim_name[data_p2_long$param_stimulus_type == \"high_stim\"] <- \"high\"## Warning: Unknown or uninitialised column: `stim_name`.\n    data_p2_long$stim_name[data_p2_long$param_stimulus_type == \"med_stim\"] <- \"med\"\n    data_p2_long$stim_name[data_p2_long$param_stimulus_type == \"low_stim\"] <- \"low\"\n\n    data_p2_long$stim_ordered <- factor(\n        data_p2_long$stim_name,\n        levels = c(\"low\", \"med\", \"high\")\n    )\n    data_p2_long$cue_ordered <- factor(\n        data_p2_long$cue_name,\n        levels = c(\"low cue\", \"high cue\")\n    )\n    model_iv1 <- \"stim_ordered\"\n    model_iv2 <- \"cue_ordered\"\n    rating <- \"rating_type\"\n    dv <- \"rating_value\"\n\n    trialorder_subjectwise_p2 <- meanSummary(\n        data_p2_long,\n        c( model_iv2, rating, \"trial_index\"), dv\n    )\n\n    subjectwise_naomit_p2 <- na.omit(trialorder_subjectwise_p2)\n    trialorder_groupwise_p2 <- summarySEwithin(\n        data = subjectwise_naomit_p2,\n        measurevar = \"mean_per_sub\",\n        withinvars = c(\"cue_ordered\", \"rating_type\", \"trial_index\"), idvar = subject\n    )## Automatically converting the following non-factors to factors: rating_type, trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced\ntrialorder_groupwise_p2$rating_type_key <- mapvalues(trialorder_groupwise_p2$rating_type,\n                                                from = c(\"event02_expect_angle\", \"event04_actual_angle\"),\n                                                to = c(\"expect\", \"actual\"))"},{"path":"jepma.html","id":"plot-data-version-2","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.4 plot data version 2","text":"","code":"## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"jepma.html","id":"subset-of-participants","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.5 subset of participants","text":"","code":"## # A tibble: 5,851 × 60\n## # Groups:   src_subject_id [110]\n##    src_subject_id session_id param_task_name param_run_num\n##             <int>      <int> <chr>                   <int>\n##  1              2          1 pain                        1\n##  2              2          1 pain                        1\n##  3              2          1 pain                        1\n##  4              2          1 pain                        1\n##  5              2          1 pain                        1\n##  6              2          1 pain                        1\n##  7              2          1 pain                        1\n##  8              2          1 pain                        1\n##  9              2          1 pain                        1\n## 10              2          1 pain                        1\n## # ℹ 5,841 more rows\n## # ℹ 56 more variables: param_counterbalance_ver <int>,\n## #   param_counterbalance_block_num <int>, param_cue_type <chr>,\n## #   param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>, …## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: rating_type, trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"jepma.html","id":"vicarious-3","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.6 vicarious","text":"","code":"## # A tibble: 5,851 × 60\n## # Groups:   src_subject_id [110]\n##    src_subject_id session_id param_task_name param_run_num\n##             <int>      <int> <chr>                   <int>\n##  1              2          1 pain                        1\n##  2              2          1 pain                        1\n##  3              2          1 pain                        1\n##  4              2          1 pain                        1\n##  5              2          1 pain                        1\n##  6              2          1 pain                        1\n##  7              2          1 pain                        1\n##  8              2          1 pain                        1\n##  9              2          1 pain                        1\n## 10              2          1 pain                        1\n## # ℹ 5,841 more rows\n## # ℹ 56 more variables: param_counterbalance_ver <int>,\n## #   param_counterbalance_block_num <int>, param_cue_type <chr>,\n## #   param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>, …## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: rating_type, trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"jepma.html","id":"cognitive-3","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.7 cognitive","text":"","code":"## # A tibble: 5,851 × 60\n## # Groups:   src_subject_id [110]\n##    src_subject_id session_id param_task_name param_run_num\n##             <int>      <int> <chr>                   <int>\n##  1              2          1 pain                        1\n##  2              2          1 pain                        1\n##  3              2          1 pain                        1\n##  4              2          1 pain                        1\n##  5              2          1 pain                        1\n##  6              2          1 pain                        1\n##  7              2          1 pain                        1\n##  8              2          1 pain                        1\n##  9              2          1 pain                        1\n## 10              2          1 pain                        1\n## # ℹ 5,841 more rows\n## # ℹ 56 more variables: param_counterbalance_ver <int>,\n## #   param_counterbalance_block_num <int>, param_cue_type <chr>,\n## #   param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>, …## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: rating_type, trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"jepma.html","id":"within-subject-vicarious","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.8 within subject vicarious","text":"","code":"## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index, rating_type## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in geom_point(data = trialorder_groupwise_p2, aes(shape =\n## as.character(rating_type), : Ignoring unknown aesthetics: linetype## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"tor-request-only-outcome-ratings.-3-tasks","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.9 Tor request – only outcome ratings. 3 tasks","text":"","code":""},{"path":"jepma.html","id":"pain-3","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.9.1 pain","text":"","code":"## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"vicarious-4","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.9.2 vicarious","text":"","code":"## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"cognitive-4","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.9.3 cognitive","text":"","code":"## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"tor-request-only-expect-ratings.-3-tasks","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.10 Tor request – only expect ratings. 3 tasks","text":"","code":""},{"path":"jepma.html","id":"pain-4","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.10.1 pain","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## event04_actual_angle ~ trial_index * param_cue_type + (param_cue_type |  \n##     src_subject_id)\n##    Data: df_clean\n## \n## REML criterion at convergence: 51815.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.1391 -0.6157  0.0088  0.6196  4.0913 \n## \n## Random effects:\n##  Groups         Name                  Variance Std.Dev. Corr \n##  src_subject_id (Intercept)           860.95   29.342        \n##                 param_cue_typelow_cue  41.77    6.463   -0.11\n##  Residual                             582.58   24.137        \n## Number of obs: 5571, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                     Estimate Std. Error         df t value\n## (Intercept)                         74.58379    2.94621  125.10816  25.315\n## trial_index                         -0.14818    0.02397 5358.25599  -6.183\n## param_cue_typelow_cue              -10.07630    1.42124  568.67767  -7.090\n## trial_index:param_cue_typelow_cue    0.05386    0.03307 4679.39277   1.629\n##                                   Pr(>|t|)    \n## (Intercept)                        < 2e-16 ***\n## trial_index                       6.76e-10 ***\n## param_cue_typelow_cue             4.00e-12 ***\n## trial_index:param_cue_typelow_cue    0.103    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) trl_nd prm___\n## trial_index -0.258              \n## prm_c_typl_ -0.241  0.524       \n## trl_ndx:___  0.184 -0.688 -0.765## Type III Analysis of Variance Table with Satterthwaite's method\n##                             Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \n## trial_index                28321.1 28321.1     1 5407.0 48.6134 3.490e-12 ***\n## param_cue_type             29283.6 29283.6     1  568.7 50.2655 3.999e-12 ***\n## trial_index:param_cue_type  1545.4  1545.4     1 4679.4  2.6527    0.1034    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"vicarious-5","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.10.2 vicarious","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## event04_actual_angle ~ trial_index * param_cue_type + (param_cue_type |  \n##     src_subject_id)\n##    Data: df_clean\n## \n## REML criterion at convergence: 54872.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.8647 -0.6683 -0.2164  0.4658  5.5008 \n## \n## Random effects:\n##  Groups         Name                  Variance Std.Dev. Corr \n##  src_subject_id (Intercept)           132.485  11.510        \n##                 param_cue_typelow_cue   4.966   2.229   -0.89\n##  Residual                             578.849  24.059        \n## Number of obs: 5936, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                     Estimate Std. Error         df t value\n## (Intercept)                         26.04180    1.42259  222.10012  18.306\n## trial_index                          0.14033    0.02205 5791.42518   6.363\n## param_cue_typelow_cue              -10.93655    1.27427 1283.22709  -8.583\n## trial_index:param_cue_typelow_cue    0.08509    0.03037 5513.06146   2.802\n##                                   Pr(>|t|)    \n## (Intercept)                        < 2e-16 ***\n## trial_index                       2.13e-10 ***\n## param_cue_typelow_cue              < 2e-16 ***\n## trial_index:param_cue_typelow_cue  0.00509 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) trl_nd prm___\n## trial_index -0.543              \n## prm_c_typl_ -0.556  0.594       \n## trl_ndx:___  0.387 -0.697 -0.854## Type III Analysis of Variance Table with Satterthwaite's method\n##                            Sum Sq Mean Sq NumDF  DenDF  F value    Pr(>F)    \n## trial_index                 77430   77430     1 5869.4 133.7658 < 2.2e-16 ***\n## param_cue_type              42638   42638     1 1283.2  73.6606 < 2.2e-16 ***\n## trial_index:param_cue_type   4546    4546     1 5513.1   7.8532  0.005091 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"cognitive-5","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.10.3 cognitive","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## event04_actual_angle ~ trial_index * param_cue_type + (param_cue_type |  \n##     src_subject_id)\n##    Data: df_clean\n## \n## REML criterion at convergence: 52049.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.1640 -0.6201 -0.1508  0.4678  6.3870 \n## \n## Random effects:\n##  Groups         Name                  Variance Std.Dev. Corr \n##  src_subject_id (Intercept)           197.53   14.054        \n##                 param_cue_typelow_cue  26.61    5.158   -0.54\n##  Residual                             369.48   19.222        \n## Number of obs: 5901, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                     Estimate Std. Error         df t value\n## (Intercept)                         34.74794    1.52822  156.81597  22.737\n## trial_index                         -0.06251    0.01795 5781.38971  -3.482\n## param_cue_typelow_cue              -10.41305    1.13179  632.34807  -9.201\n## trial_index:param_cue_typelow_cue    0.06544    0.02468 5538.06618   2.651\n##                                   Pr(>|t|)    \n## (Intercept)                        < 2e-16 ***\n## trial_index                       0.000502 ***\n## param_cue_typelow_cue              < 2e-16 ***\n## trial_index:param_cue_typelow_cue 0.008037 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) trl_nd prm___\n## trial_index -0.411              \n## prm_c_typl_ -0.514  0.547       \n## trl_ndx:___  0.296 -0.705 -0.776## Type III Analysis of Variance Table with Satterthwaite's method\n##                             Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \n## trial_index                 2020.5  2020.5     1 5783.0  5.4686  0.019395 *  \n## param_cue_type             31276.3 31276.3     1  632.3 84.6500 < 2.2e-16 ***\n## trial_index:param_cue_type  2597.6  2597.6     1 5538.1  7.0304  0.008037 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1## Warning: Unknown or uninitialised column: `cue_name`.## Warning: Unknown or uninitialised column: `stim_name`.## Automatically converting the following non-factors to factors: trial_index## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## Warning in stats::qt(conf.interval/2 + 0.5, datac$N - 1): NaNs produced## `geom_smooth()` using formula = 'y ~ x'"},{"path":"jepma.html","id":"lmer","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.11 lmer","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## event04_actual_angle ~ trial_index * param_cue_type + (param_cue_type |  \n##     src_subject_id)\n##    Data: df_clean\n## \n## REML criterion at convergence: 52049.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.1640 -0.6201 -0.1508  0.4678  6.3870 \n## \n## Random effects:\n##  Groups         Name                  Variance Std.Dev. Corr \n##  src_subject_id (Intercept)           197.53   14.054        \n##                 param_cue_typelow_cue  26.61    5.158   -0.54\n##  Residual                             369.48   19.222        \n## Number of obs: 5901, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                     Estimate Std. Error         df t value\n## (Intercept)                         34.74794    1.52822  156.81597  22.737\n## trial_index                         -0.06251    0.01795 5781.38971  -3.482\n## param_cue_typelow_cue              -10.41305    1.13179  632.34807  -9.201\n## trial_index:param_cue_typelow_cue    0.06544    0.02468 5538.06618   2.651\n##                                   Pr(>|t|)    \n## (Intercept)                        < 2e-16 ***\n## trial_index                       0.000502 ***\n## param_cue_typelow_cue              < 2e-16 ***\n## trial_index:param_cue_typelow_cue 0.008037 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) trl_nd prm___\n## trial_index -0.411              \n## prm_c_typl_ -0.514  0.547       \n## trl_ndx:___  0.296 -0.705 -0.776## Type III Analysis of Variance Table with Satterthwaite's method\n##                             Sum Sq Mean Sq NumDF  DenDF F value    Pr(>F)    \n## trial_index                 2020.5  2020.5     1 5783.0  5.4686  0.019395 *  \n## param_cue_type             31276.3 31276.3     1  632.3 84.6500 < 2.2e-16 ***\n## trial_index:param_cue_type  2597.6  2597.6     1 5538.1  7.0304  0.008037 ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1"},{"path":"jepma.html","id":"lmer-histogram","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.11.1 lmer histogram","text":"","code":"\nhist(random_slopes)\ndf <- data.frame(sub = group_ids, cue_randomslope = random_slopes)\nwrite.csv(df, file.path(main_dir,\"data\",\"RL\", \"cue_trial_ranef_{taskname}.csv\"), row.names = FALSE)\n# TODO: create a json file that also keeps track of which participants are include hree, using what model\n# comment"},{"path":"jepma.html","id":"do-current-expectation-ratings-predict-outcome-ratings","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.12 Do current expectation ratings predict outcome ratings?","text":"","code":""},{"path":"jepma.html","id":"additional-analyse-01182023","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"Additional analyse 01/18/2023","text":"see current expectation ratings predict outcome ratingssee prior stimulus experience (N-1) predicts current expectation ratingssee current expectation ratings explained function prior outcome rating current expectation ratingwhen loading dataset, need add trial index per dataframe.\n, shift rating?","code":"\ndata_a3 <- data_p2 %>%\n  group_by(src_subject_id, session_id, param_run_num) %>%\n  mutate(trial_index = row_number(param_run_num))\n\ndata_a3lag <-\n    data_a3 %>%\n    group_by(src_subject_id, session_id, param_run_num) %>%\n    mutate(lag.04outcomeangle = dplyr::lag(event04_actual_angle, n = 1, default = NA))\ndata_a3lag_omit <- data_a3lag[complete.cases(data_a3lag$lag.04outcomeangle),]\n    trialorder_subjectwise_lagoutcome <- meanSummary(\n        data_a3lag_omit,\n        c(\"src_subject_id\", \"session_id\", \"param_run_num\"), \"lag.04outcomeangle\" )\n    trialorder_subjectwise_lagoutcome <- meanSummary(\n        data_a3lag_omit,\n        c(\"src_subject_id\", \"session_id\", \"param_run_num\"), \"lag.04outcomeangle\" )\n\n    # subjectwise_naomit <- na.omit(trialorder_subjectwise)\n    # trialorder_groupwise <- summarySEwithin(\n    #     data = subjectwise_naomit,\n    #     measurevar = \"mean_per_sub\",\n    #     withinvars = c(\"cue_ordered\", \"rating_type\",  \"trial_index\"), idvar = subject\n    # )\nmodel.lagoutcome = lmer(event02_expect_angle ~ lag.04outcomeangle + (1 | src_subject_id) + (1|session_id) , data = data_a3lag_omit)\nsummary(model.lagoutcome)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: event02_expect_angle ~ lag.04outcomeangle + (1 | src_subject_id) +  \n##     (1 | session_id)\n##    Data: data_a3lag_omit\n## \n## REML criterion at convergence: 49728.1\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.8551 -0.7402 -0.1322  0.6351  6.3909 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept) 121.4858 11.0221 \n##  session_id     (Intercept)   0.2696  0.5192 \n##  Residual                   531.1376 23.0464 \n## Number of obs: 5427, groups:  src_subject_id, 110; session_id, 3\n## \n## Fixed effects:\n##                     Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)        2.873e+01  1.230e+00 6.852e+01   23.36   <2e-16 ***\n## lag.04outcomeangle 1.780e-01  1.562e-02 5.374e+03   11.40   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## lg.04tcmngl -0.365\nmeanSummary_2continuous <- function(DATA, GROUP, DV1, DV2) {\n    z <- ddply(DATA, GROUP, .fun = function(xx) {\n        c(\n            DV1_mean_per_sub = mean(xx[, DV1], na.rm = TRUE),\n            DV1_sd = sd(xx[, DV1], na.rm = TRUE),\n            DV2_mean_per_sub = mean(xx[, DV2], na.rm = TRUE),\n            DV2_sd = sd(xx[, DV1], na.rm = TRUE)\n        )\n    })\n    return(z)\n}\nsubjectwise_2dv = meanSummary_2continuous(data_a3lag_omit,\n        c(\"src_subject_id\", \"trial_index\"),\n        \"lag.04outcomeangle\", \"event02_expect_angle\")\nsubjectwise_naomit_2dv <- na.omit(subjectwise_2dv)\nsp <- ggplot(data=subjectwise_naomit_2dv,\n             aes(x=DV1_mean_per_sub, y=DV2_mean_per_sub)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, color=\"green\",\n                 linetype=\"dashed\", size=0.5) +\n  theme(aspect.ratio=1) +\n  xlab(\"n-1 outcome rating\") +\n  ylab(\"n expectation rating\")\nsp\n# plot(subjectwise_naomit_2dv$DV1_mean_per_sub, subjectwise_naomit_2dv$DV2_mean_per_sub) + lines(x = c(0,200), y = c(0,200))\n    trialorder_groupwise <- summarySEwithin(\n        data = subjectwise_naomit_2dv,\n        measurevar = \"DV1_mean_per_sub\",\n        # betweenvars = \"src_subject_id\",\n        withinvars = factor( \"trial_index\"),\n         idvar = \"src_subject_id\"\n    )## Automatically converting the following non-factors to factors: src_subject_id\n    trialorder_groupwise <- summarySEwithin(\n        data = subset(subjectwise_naomit_2dv, select = -c(src_subject_id)),\n        measurevar = \"DV1_mean_per_sub\",\n        # betweenvars = \"src_subject_id\",\n        withinvars = as.factor( \"trial_index\")\n         #idvar = \"trial_index\"\n    )## Automatically converting the following non-factors to factors: trial_index\ndata_a3lag_omit$src_subject_id <- as.factor(data_a3lag_omit$src_subject_id)\n\nlag.raw <- ggplot(aes(x=lag.04outcomeangle, y=event02_expect_angle), data=data_a3lag_omit) +\n  geom_smooth(method='lm', se=F, size=0.75) +\n  geom_point(size=0.1) +\n    geom_abline(intercept = 0, slope = 1, color=\"green\",\n                 linetype=\"dashed\", size=0.5) +\n  facet_wrap(~src_subject_id) +\n  theme(legend.position='none') +\n  xlim(0,180) + ylim(0,180) +\n  xlab(\"raw data from each participant: n-1 lagged outcome angle\") +\n  ylab(\"n current expectation rating\")\nlag.raw +\n  labs(title = paste(taskname, \"- Is there a linear relationship between current expectation ratings and the previous outcome ratings?\"),\n       subtitle = \"Plotting the raw data - with all of the datapoints ignoring run differences\",\n       caption = \"Blue = fitted linear slope per participant; Green: 1:1 slope\")## `geom_smooth()` using formula = 'y ~ x'## Warning: Removed 276 rows containing non-finite values (`stat_smooth()`).## Warning: Removed 276 rows containing missing values (`geom_point()`).\nsubjectwise_naomit_2dv$src_subject_id <- as.factor(subjectwise_naomit_2dv$src_subject_id)\n\nlag.avg <- ggplot(aes(x=DV1_mean_per_sub, y=DV2_mean_per_sub), data=subjectwise_naomit_2dv) +\n  geom_smooth(method='lm', se=F, size=0.75) +\n  geom_point(size=0.1) +\n    geom_abline(intercept = 0, slope = 1, color=\"green\",\n                 linetype=\"dashed\", size=0.5) +\n  facet_wrap(~src_subject_id) +\n  theme(legend.position='none') +\n  xlim(0,180) + ylim(0,180) +\n  xlab(\"raw data from each participant: n-1 lagged outcome angle\") +\n  ylab(\"n current expectation rating\")\n\nlag.avg +\n  labs(title = paste(taskname, \"- Is there a linear relationship between current expectation ratings and the previous outcome ratings?\"),\n       subtitle = \"Observation notes: 1) The relationship is more of an attenuated one, where the higher outcome ratings lead to a slightly lower expectation rating, and a low outcome leads to a higher expectation rating, when considering a 1:1 relationship. This pattern could be explained by regression to the mean type mechanism, where participants are accounting for the fact that their previous experience was extreme on either ends and that this current trial will be under/over estimated. It probably will make sense to also see the relationship between current expectation ratings influencing current outcome ratings. \",\n       caption = \"Blue = fitted linear slope per participant; Green: 1:1 slope\")## `geom_smooth()` using formula = 'y ~ x'\n# https://gist.github.com/even4void/5074855\nggplot(data_a3lag_omit, aes(y = event02_expect_angle,\n                       x = lag.04outcomeangle,\n                       colour = subject), size = .3, color = 'gray') +\n  geom_point(size = .1) +\n  geom_smooth(method = 'lm', formula= y ~ x, se = FALSE, size = .3) +\n  theme_bw()## Warning: Removed 276 rows containing non-finite values (`stat_smooth()`).## Warning: Removed 276 rows containing missing values (`geom_point()`)."},{"path":"jepma.html","id":"additional-analysis","chapter":"6 beh :: expect-outcome ~ cue * trial","heading":"6.13 Additional analysis","text":"01/23/2023","code":"\nmodel.lag_cue = lmer(event02_expect_angle ~ lag.04outcomeangle*param_cue_type + (1 | src_subject_id) + (1|session_id) , data = data_a3lag_omit)\nsummary(model.lag_cue)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: event02_expect_angle ~ lag.04outcomeangle * param_cue_type +  \n##     (1 | src_subject_id) + (1 | session_id)\n##    Data: data_a3lag_omit\n## \n## REML criterion at convergence: 46175.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.3458 -0.6383 -0.0833  0.5246  9.8300 \n## \n## Random effects:\n##  Groups         Name        Variance  Std.Dev.\n##  src_subject_id (Intercept) 128.73691 11.3462 \n##  session_id     (Intercept)   0.03408  0.1846 \n##  Residual                   272.07427 16.4947 \n## Number of obs: 5427, groups:  src_subject_id, 110; session_id, 3\n## \n## Fixed effects:\n##                                            Estimate Std. Error         df\n## (Intercept)                                42.76857    1.21398  129.42606\n## lag.04outcomeangle                          0.23730    0.01465 5394.92176\n## param_cue_typelow_cue                     -27.33964    0.71898 5316.67781\n## lag.04outcomeangle:param_cue_typelow_cue   -0.15072    0.01922 5309.65154\n##                                          t value Pr(>|t|)    \n## (Intercept)                               35.230  < 2e-16 ***\n## lag.04outcomeangle                        16.197  < 2e-16 ***\n## param_cue_typelow_cue                    -38.026  < 2e-16 ***\n## lag.04outcomeangle:param_cue_typelow_cue  -7.842  5.3e-15 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) lg.04t prm___\n## lg.04tcmngl -0.350              \n## prm_c_typl_ -0.293  0.500       \n## lg.04tc:___  0.227 -0.639 -0.781\nmeanSummary_2continuous <- function(DATA, GROUP, DV1, DV2) {\n    z <- ddply(DATA, GROUP, .fun = function(xx) {\n        c(\n            DV1_mean_per_sub = mean(xx[, DV1], na.rm = TRUE),\n            DV1_sd = sd(xx[, DV1], na.rm = TRUE),\n            DV2_mean_per_sub = mean(xx[, DV2], na.rm = TRUE),\n            DV2_sd = sd(xx[, DV1], na.rm = TRUE)\n        )\n    })\n    return(z)\n}\nsubjectwise_cuetype = meanSummary_2continuous(data_a3lag_omit,\n        c(\"src_subject_id\", \"trial_index\", \"param_cue_type\"),\n        \"lag.04outcomeangle\", \"event02_expect_angle\")\n# subjectwise_cuetype_2dv <- na.omit(subjectwise_cuetype)\nsubjectwise_cuetype$param_cue_type <- as.factor(subjectwise_cuetype$param_cue_type)\nsp <- ggplot(data=subjectwise_cuetype,\n             aes(x=DV1_mean_per_sub, y=DV2_mean_per_sub,\n             color = param_cue_type)) +\n  geom_point() +\n  geom_abline(intercept = 0, slope = 1, color=\"green\",\n                 linetype=\"dashed\", size=0.5) +\n  geom_smooth(method = 'lm') +\n  theme(aspect.ratio=1) +\n  xlab(\"n-1 outcome rating\") +\n  ylab(\"n expectation rating\")\nsp +\n    labs(title = paste(taskname, \"- Does the linear relationship between current expectation ratings and the previous outcome ratings differ as a function of cue?\"),\n       subtitle = \"Plotting the raw data - with all of the datapoints averaged across runs per 12 trials\",\n       caption = \"high cue vs low cue. The slope is significant, theree is not interaction; Green: 1:1 slope\")## `geom_smooth()` using formula = 'y ~ x'## Warning: Removed 49 rows containing non-finite values (`stat_smooth()`).## Warning: Removed 49 rows containing missing values (`geom_point()`).\n# plot(subjectwise_naomit_2dv$DV1_mean_per_sub, subjectwise_naomit_2dv$DV2_mean_per_sub) + lines(x = c(0,200), y = c(0,200))"},{"path":"scaling.html","id":"scaling","chapter":"7 within / between subject effect and Scaling","heading":"7 within / between subject effect and Scaling","text":"","code":""},{"path":"scaling.html","id":"what-is-the-purpose-of-this-notebook-4","chapter":"7 within / between subject effect and Scaling","heading":"What is the purpose of this notebook?","text":", want examine within subject effects subjective ratings.\nscale usage differences across individuals. ’s evident behavioral data.\nscale usage differences really reflecting underlying experience, compresses scale.\none reasons including -subject term improves performance mediation model.\n’s also line Enders Tofighi’s illustration centering multilevel models.\nlogic multiple components go subjective ratings\nway individual uses scale (“-subject effect”)\nfact rating reflect subjective experience (“within-subject effect”)\nwant rid subject effect focus subjective experience.\nOne way resolve z-scoring.\nHypothesis: z-scoring, see high correlation across tasks terms cue effects, can safely conclude way people think expectations highly domain general\ncue effect raw scores can conflated scale artifact also common domain general expectation mechanisms.\nQ. task-specific components?\nthoughts:\n* scaling artifact big driving factor, pain brain going lead weak signal.\n* within person pain effects. weakly tracks individual differences.\n/n\n* Main model: lmer( OUTCOME ~ EXPECT) vs. lmer( OUTCOME ~ zscoreEXPECT)\n* Main question: Z-scoring lead improvement predicting pain? effect shrink, indicating pain ratings byproduct participants using scale differently?\n* {{ HYPOTHESES/EXPECTED OUTCOME }}\n* slopes increase z-scoring, effects\n* IV:\n- {{ Zscore }} ( {{ LEVELS}} )\n* DV: {{ Outcome }}Enders, C. K., & Tofighi, D. (2007). Centering predictor variables cross-sectional multilevel models: new look old issue. Psychological Methods, 12(2), 121–138.https://philippmasur.de/2018/05/23/--center--multilevel-models/displaying lmer html tables: https://strengejacke.github.io/sjPlot/articles/tab_mixed.html","code":""},{"path":"scaling.html","id":"todo-1","chapter":"7 within / between subject effect and Scaling","heading":"7.1 TODO:","text":"","code":"- [x] zscore the ratings (ignore sessions)\n- [x] predict outcome ratings\n- [x] model compare zscore vs just raw score\n- [x] include between subject level scores as covariates. AS ALWAYS\n- [ ]identify why model doesn't converge for OUTCOME ~ EXPECT + (EXPECT|SUB)\nIt might be the zero ratings \n- [ ] Drop trials with ratings of 0. \n- [ ] raw cue effect, raw stim effect, raw cue/stimeffect, raw cue/stim + 1 effect"},{"path":"scaling.html","id":"load-libraries","chapter":"7 within / between subject effect and Scaling","heading":"load libraries","text":"","code":""},{"path":"scaling.html","id":"computed_enderstofighi","chapter":"7 within / between subject effect and Scaling","heading":"7.2 computed_enderstofighi","text":"","code":"\ncompute_enderstofighi <- function(data, sub, outcome, expect, ses, run) {\n  maindata <- data %>%\n    group_by(!!sym(sub)) %>%\n    mutate(OUTCOME = as.numeric(!!sym(outcome))) %>%\n    mutate(EXPECT = as.numeric(!!sym(expect))) %>%\n    mutate(OUTCOME_cm = mean(OUTCOME, na.rm = TRUE)) %>%\n    mutate(OUTCOME_demean = OUTCOME - OUTCOME_cm) %>%\n    mutate(EXPECT_cm = mean(EXPECT, na.rm = TRUE)) %>%\n    mutate(EXPECT_demean = EXPECT - EXPECT_cm) %>%\n    #mutate(OUTCOME_zscore = as.numeric(scale(OUTCOME, center = TRUE, scale = TRUE)[, 1])) %>%\n    #mutate(EXPECT_zscore = as.numeric(scale(EXPECT, center = TRUE, scale = TRUE)[, 1])) \n    mutate(OUTCOME_zscore = (OUTCOME - mean(OUTCOME, na.rm = TRUE))/sd(OUTCOME, na.rm = TRUE)) %>% #as.numeric(scale(OUTCOME, center = TRUE, scale = TRUE)[, 1])) %>%\n    mutate(EXPECT_zscore = (EXPECT - mean(EXPECT, na.rm = TRUE))/sd(EXPECT, na.rm = TRUE)) #as.numeric(scale(EXPECT, center = TRUE, scale = TRUE)[, 1])) \n  \n  data_p2 <- maindata %>%\n    arrange(!!sym(sub)) %>%\n    group_by(!!sym(sub)) %>%\n    mutate(trial_index = row_number())\n  \n  data_a3 <- data_p2 %>%\n    group_by(!!sym(sub), !!sym(ses), !!sym(run)) %>%\n    mutate(trial_index = row_number(!!sym(run)))\n  \n  data_a3lag <- data_a3 %>%\n    group_by(!!sym(sub), !!sym(ses), !!sym(run)) %>%\n    mutate(lag.OUTCOME_demean = dplyr::lag(OUTCOME_demean, n = 1, default = NA))\n  \n  # Create Subjectwise Mean, centered in relation to the group mean\n  data_a3cmc <- data_a3lag %>%\n    ungroup %>%\n    mutate(EXPECT_cmc = EXPECT_cm - mean(EXPECT_cm, na.rm=TRUE)) %>%\n    mutate(OUTCOME_cmc = OUTCOME_cm - mean(OUTCOME_cm, na.rm=TRUE))\n  \n  \n  # Remove NA values ___________________________________________________________\n  data_centered_NA <- data_a3cmc %>% \n    filter(!is.na(OUTCOME)) %>% # Remove NA values\n    filter(!is.na(EXPECT))\n\n  return(data_centered_NA)\n  \n}"},{"path":"scaling.html","id":"analysis-1-pain-display-distribution-of-data","chapter":"7 within / between subject effect and Scaling","heading":"7.3 Analysis 1: Pain display distribution of data","text":"Let’s look distribution data. X axis: Y axis:\n’s loaded dataset, filtered Outcome Ratings NA","code":"\n# remove NA values first\ndf.centered_NA <- data_centered %>% filter(!is.na(OUTCOME))  # Remove NA values\nhead(df.centered_NA)## # A tibble: 6 × 75\n##   src_subject_id session_id param_task_name param_run_num param_counterbalance…¹\n##            <int>      <int> <chr>                   <int>                  <int>\n## 1              2          1 pain                        1                      3\n## 2              2          1 pain                        1                      3\n## 3              2          1 pain                        1                      3\n## 4              2          1 pain                        1                      3\n## 5              2          1 pain                        1                      3\n## 6              2          1 pain                        1                      3\n## # ℹ abbreviated name: ¹​param_counterbalance_ver\n## # ℹ 70 more variables: param_counterbalance_block_num <int>,\n## #   param_cue_type <chr>, param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>,\n## #   event01_cue_filename <chr>, ISI01_onset <dbl>, ISI01_biopac <dbl>, …"},{"path":"scaling.html","id":"plot-outcome-rating-distribution","chapter":"7 within / between subject effect and Scaling","heading":"7.3.1 Plot Outcome rating distribution","text":"Ratings sorted based Median values Outcome rating","code":""},{"path":"scaling.html","id":"identify-subjects-with-narrow-iqr","chapter":"7 within / between subject effect and Scaling","heading":"7.3.2 Identify subjects with narrow IQR","text":"plan use filter participants","code":"\nlibrary(dplyr)\n\n# Assuming df.centered_NA is your dataframe and it's already loaded\n\n# Task 1: Top and Bottom 5% Subjects\nsorted_data <- df.centered_NA %>%\n  group_by(subject) %>%\n  summarize(median_outcome = median(OUTCOME, na.rm = TRUE)) %>%\n  arrange(median_outcome)\n\nnum_subjects <- nrow(sorted_data)\ntop_bottom_count <- ceiling(num_subjects * 0.05)\n\ntop_5_percent_subjects <- head(sorted_data, top_bottom_count)$subject\nbottom_5_percent_subjects <- tail(sorted_data, top_bottom_count)$subject\n\n# Task 2: Narrow IQR Subjects\niqr_data <- df.centered_NA %>%\n  group_by(subject) %>%\n  summarize(IQR = IQR(OUTCOME, na.rm = TRUE)) %>%\n  arrange(IQR)\n\n# Output the subjects\ncat(\"Top 5% Subjects based on Median Outcome:\\n\", toString(as.character(top_5_percent_subjects)), \"\\n\")## Top 5% Subjects based on Median Outcome:\n##  3, 4, 5, 60, 130, 19\ncat(\"Bottom 5% Subjects based on Median Outcome:\\n\", toString(as.character(bottom_5_percent_subjects)), \"\\n\")## Bottom 5% Subjects based on Median Outcome:\n##  74, 46, 32, 15, 9, 50\n# If you want to see the subjects with the narrowest IQRs\n# cat(\"Subjects with the Narrowest IQRs:\\n\", head(iqr_data)$subject, \"\\n\")\ncat(\"Subjects with the Narrowest IQRs:\\n\", toString(as.character(head(iqr_data)$subject)), \"\\n\")## Subjects with the Narrowest IQRs:\n##  117, 85, 66, 29, 63, 123\nnarrowest_iqr_string <- paste0('\"', as.character(head(iqr_data)$subject), '\"', collapse = \", \")\ncat(\"Subjects with the Narrowest IQRs:\\n\", narrowest_iqr_string, \"\\n\")## Subjects with the Narrowest IQRs:\n##  \"117\", \"85\", \"66\", \"29\", \"63\", \"123\"\n# head(iqr_data)$subject\n\n# Create filter string based on narrow variability\nsubject_ids <- as.character(head(iqr_data)$subject)\nformatted_subjects <- paste0(\"sub-\", sprintf(\"%04d\", as.numeric(subject_ids)))\nfilter_string <- paste(formatted_subjects, collapse = \"|\")\nfilter_string <- paste0(\"sub-0001|\", filter_string)\n# Output the filter string\ncat(\"Filter String: \", filter_string, \"\\n\")## Filter String:  sub-0001|sub-0117|sub-0085|sub-0066|sub-0029|sub-0063|sub-0123"},{"path":"scaling.html","id":"analysis-2-z-score-vs.-not-model-comparison","chapter":"7 within / between subject effect and Scaling","heading":"7.4 Analysis 2: Z score vs. not model comparison","text":"","code":""},{"path":"scaling.html","id":"lmer-model-compare-z-score-vs-nonzscore","chapter":"7 within / between subject effect and Scaling","heading":"lmer model compare z score vs nonzscore","text":"Q. coefficients change function Z scoring vs ?","code":"\nmodel.z <- lmer(OUTCOME ~ EXPECT_zscore + (EXPECT_zscore|subject), df.centered_NA)\nmodel.nonz <- lmer(OUTCOME ~ EXPECT + (EXPECT|subject), df.centered_NA)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 4.21058 (tol = 0.002, component 1)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (1|subject), df.centered_NA)\n\nprint_dash(\"model with Z scores\")## \n## \n## ----------------------------------------\n## model with Z scores\n## ----------------------------------------\nsummary(model.z)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | subject)\n##    Data: df.centered_NA\n## \n## REML criterion at convergence: 53494.5\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5605 -0.5920  0.0064  0.5904  4.3988 \n## \n## Random effects:\n##  Groups   Name          Variance Std.Dev. Corr\n##  subject  (Intercept)   877.15   29.62        \n##           EXPECT_zscore  48.44    6.96    0.16\n##  Residual               507.09   22.52        \n## Number of obs: 5825, groups:  subject, 114\n## \n## Fixed effects:\n##               Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)    64.4462     2.7981 113.2011  23.032   <2e-16 ***\n## EXPECT_zscore   7.1939     0.7309 115.3281   9.842   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## EXPECT_zscr 0.142\nprint_dash(\"model with raw scores, i.e. non Zscores\")## \n## \n## ----------------------------------------\n## model with raw scores, i.e. non Zscores\n## ----------------------------------------\nsummary(model.nonz)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT + (EXPECT | subject)\n##    Data: df.centered_NA\n## \n## REML criterion at convergence: 53378.1\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5878 -0.5923  0.0121  0.5977  4.4260 \n## \n## Random effects:\n##  Groups   Name        Variance  Std.Dev. Corr \n##  subject  (Intercept) 869.44478 29.4863       \n##           EXPECT        0.03975  0.1994  -0.58\n##  Residual             503.76679 22.4447       \n## Number of obs: 5825, groups:  subject, 114\n## \n## Fixed effects:\n##             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept) 47.20152    2.89746 56.84800   16.29   <2e-16 ***\n## EXPECT       0.28268    0.02266 87.47735   12.47   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##        (Intr)\n## EXPECT -0.597\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 4.21058 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nprint_dash(\"model with raw scores CMC and CWC\")## \n## \n## ----------------------------------------\n## model with raw scores CMC and CWC\n## ----------------------------------------\nsummary(model.cmc)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_demean + EXPECT_cmc + (1 | subject)\n##    Data: df.centered_NA\n## \n## REML criterion at convergence: 53537.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.3594 -0.6055  0.0008  0.6163  4.8740 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  subject  (Intercept) 159.3    12.62   \n##  Residual             544.4    23.33   \n## Number of obs: 5825, groups:  subject, 114\n## \n## Fixed effects:\n##                Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   6.474e+01  1.234e+00 1.114e+02   52.48   <2e-16 ***\n## EXPECT_demean 2.964e-01  1.072e-02 5.712e+03   27.64   <2e-16 ***\n## EXPECT_cmc    9.203e-01  4.250e-02 1.109e+02   21.65   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) EXPECT_d\n## EXPECT_demn -0.001         \n## EXPECT_cmc   0.007  0.001\nprint_dash(\"model comparison\")## \n## \n## ----------------------------------------\n## model comparison\n## ----------------------------------------\nanova(model.z, model.nonz)## refitting model(s) with ML (instead of REML)## Data: df.centered_NA\n## Models:\n## model.z: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | subject)\n## model.nonz: OUTCOME ~ EXPECT + (EXPECT | subject)\n##            npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)\n## model.z       6 53512 53552 -26750    53500                     \n## model.nonz    6 53380 53420 -26684    53368 131.43  0"},{"path":"scaling.html","id":"plot-subjectwise-slopes-of-zscore-and-nonzscore","chapter":"7 within / between subject effect and Scaling","heading":"7.4.1 plot :: subjectwise slopes of Zscore and nonZscore","text":"TODO: change color scheme increase figure size","code":""},{"path":"scaling.html","id":"analysis-3-across-pvc-are-these-expectation-effects-domain-general-or-domain-specific","chapter":"7 within / between subject effect and Scaling","heading":"7.5 Analysis 3: across PVC, Are these expectation effects domain-general or domain-specific?","text":"","code":""},{"path":"scaling.html","id":"load-entire-data-of-painvicariouscognitive","chapter":"7 within / between subject effect and Scaling","heading":"load entire data of pain,vicarious,cognitive","text":"","code":""},{"path":"scaling.html","id":"validate-correlation-matrix-across-centered-variables","chapter":"7 within / between subject effect and Scaling","heading":"7.6 Validate: correlation matrix across centered variables","text":"::::{.todolist}zscores seem scaled within participant.\nLet’s check ’s going .\nmean value 0 participants\n::::","code":"\nlibrary(dplyr)\nhead(df.PVC_center)## # A tibble: 6 × 33\n##   src_subject_id session_id param_run_num param_task_name event02_expect_angle\n##            <int>      <int>         <int> <chr>                          <dbl>\n## 1              2          1             1 pain                            5.53\n## 2              2          1             1 pain                           18.9 \n## 3              2          1             1 pain                          103.  \n## 4              2          1             1 pain                           81.2 \n## 5              2          1             1 pain                           97.2 \n## 6              2          1             1 pain                          117.  \n## # ℹ 28 more variables: param_cue_type <chr>, param_stimulus_type <chr>,\n## #   event04_actual_angle <dbl>, trial_index <int>, trial_count_sub <int>,\n## #   trial_ind <dbl>, sub <chr>, ses <chr>, run <chr>, runtype <chr>,\n## #   task <chr>, trial_sub <int>, trial <chr>, cuetype <chr>,\n## #   stimintensity <chr>, DEPc <chr>, DEP <chr>, OUTCOME <dbl>, EXPECT <dbl>,\n## #   OUTCOME_cm <dbl>, OUTCOME_demean <dbl>, EXPECT_cm <dbl>,\n## #   EXPECT_demean <dbl>, OUTCOME_zscore <dbl>, EXPECT_zscore <dbl>, …\n# Assuming df is your dataframe, and 'participant', 'col1', 'col2', 'col3' are your column names\ndf.PVC_center$subject <- factor(df.PVC_center$sub)\ndf.PVC_center$OUTCOME <- as.numeric(df.PVC_center$OUTCOME)\ndf.PVC_center$EXPECT_cmc <- as.numeric(df.PVC_center$EXPECT_cmc)\ndf.PVC_center$EXPECT_demean <- as.numeric(df.PVC_center$EXPECT_demean)\ncorrelation_matrix_per_participant <- df.PVC_center %>%\n  group_by(sub) %>%\n  summarize(\n    cor_matrix = list(cor(.[, c(\"OUTCOME\", \"EXPECT_cmc\", \"EXPECT_demean\", \"EXPECT_zscore\")], \n                        use = \"complete.obs\"))\n  )\n# To view the correlation matrix for the first participant\n# correlation_matrix_per_participant$cor_matrix[[1]]\n\n# plot correlatin matrix _______________________________________________________\nlibrary(ggplot2)\nlibrary(reshape2)\nlibrary(dplyr)\n\n# Assuming correlation_matrix_per_participant is the result from the previous step\nfor(i in 1:nrow(correlation_matrix_per_participant)) {\n  participant_id <- correlation_matrix_per_participant$sub[i]\n  cor_matrix <- correlation_matrix_per_participant$cor_matrix[[i]]\n\n  # Convert the correlation matrix to long format\n  long_cor_matrix <- melt(cor_matrix)\n  names(long_cor_matrix) <- c(\"Var1\", \"Var2\", \"value\")\n\n  # Plotting\n  p <- ggplot(long_cor_matrix, aes(Var1, Var2, fill = value)) +\n    geom_tile() +\n    scale_fill_gradient2(low = \"blue\", high = \"red\", mid = \"white\", \n                         midpoint = 0, limit = c(-1, 1), space = \"Lab\", \n                         name=\"Correlation\") +\n    theme_minimal() +\n    ggtitle(paste(\"Correlation Matrix for Participant\", participant_id))\n\n  print(p)\n}"},{"path":"scaling.html","id":"plot-per-participant.-outcome-expect-demean","chapter":"7 within / between subject effect and Scaling","heading":"7.6.1 plot per participant. Outcome, Expect, demean","text":"","code":"\npain.df <- df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ]\nsub_0063pain.df <- pain.df[pain.df$sub == \"sub-0060\",]\nhead(sub_0063pain.df)## # A tibble: 6 × 34\n##   src_subject_id session_id param_run_num param_task_name event02_expect_angle\n##            <int>      <int>         <int> <chr>                          <dbl>\n## 1             60          1             1 pain                             0  \n## 2             60          1             1 pain                            51.0\n## 3             60          1             1 pain                            45.3\n## 4             60          1             1 pain                            28.4\n## 5             60          1             1 pain                            66.1\n## 6             60          1             1 pain                             0  \n## # ℹ 29 more variables: param_cue_type <chr>, param_stimulus_type <chr>,\n## #   event04_actual_angle <dbl>, trial_index <int>, trial_count_sub <int>,\n## #   trial_ind <dbl>, sub <chr>, ses <chr>, run <chr>, runtype <chr>,\n## #   task <chr>, trial_sub <int>, trial <chr>, cuetype <chr>,\n## #   stimintensity <chr>, DEPc <chr>, DEP <chr>, OUTCOME <dbl>, EXPECT <dbl>,\n## #   OUTCOME_cm <dbl>, OUTCOME_demean <dbl>, EXPECT_cm <dbl>,\n## #   EXPECT_demean <dbl>, OUTCOME_zscore <dbl>, EXPECT_zscore <dbl>, …\n# hist(sub_0063pain.df$EXPECT)\n# hist(sub_0063pain.df$EXPECT_zscore)\n# hist(sub_0063pain.df$EXPECT_cm)\n# hist(sub_0063pain.df$EXPECT_demean)\n\nplot(sub_0063pain.df$EXPECT_demean, sub_0063pain.df$OUTCOME)\nplot(sub_0063pain.df$EXPECT_zscore, sub_0063pain.df$OUTCOME)\nr <- ggplot(sub_0063pain.df, aes(x = EXPECT)) + \n  geom_histogram(bins = 30, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"Histogram of Variable\", x = \"Expect (Raw)\", y = \"Outcome\")+\n  theme_classic()\n\nz <- ggplot(sub_0063pain.df, aes(x = EXPECT_zscore)) + \n  geom_histogram(bins = 30, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"Histogram of Variable\", x = \"Expect (Z)\", y = \"Outcome\")+\n  theme_classic()\n\ncmc <- ggplot(sub_0063pain.df, aes(x = EXPECT_cm)) + \n  geom_histogram(bins = 30, fill = \"blue\", alpha = 0.7) +\n  labs(title = \"Histogram of Variable\", x = \"Expect (CMC)\", y = \"Outcome\") +\n  theme_classic()\narranged_plots <- (ggpubr::ggarrange(\n        r, z, cmc,\n        common.legend = FALSE,\n        legend = \"none\",\n        ncol = 3,\n        nrow = 1,\n        widths = c(1,1,1),\n        heights = c(1),\n        align = \"v\"\n      ))\ngrid.draw(arranged_plots)"},{"path":"scaling.html","id":"analysis-3","chapter":"7 within / between subject effect and Scaling","heading":"7.7 Analysis 3","text":"","code":""},{"path":"scaling.html","id":"lmer-model-compare-z-score-vs-nonzscore-1","chapter":"7 within / between subject effect and Scaling","heading":"7.7.1 lmer model compare z score vs nonzscore","text":"","code":"\npain.df <- df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ]\nvic.df <- df.PVC_center[df.PVC_center$runtype == \"runtype-vicarious\", ]\ncog.df <- df.PVC_center[df.PVC_center$runtype == \"runtype-cognitive\", ]\nmodel.pain_z <- lmer(OUTCOME ~ EXPECT_zscore + (EXPECT_zscore|sub), pain.df)\nmodel.vic_z <- lmer(OUTCOME ~ EXPECT_zscore + (EXPECT_zscore|sub), vic.df)\nmodel.cog_z <- lmer(OUTCOME ~ EXPECT_zscore + (EXPECT_zscore|sub), cog.df)\nmodel.pain_raw <- lmer(OUTCOME ~ EXPECT + (EXPECT|sub), pain.df)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 5.82673 (tol = 0.002, component 1)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.vic_raw <- lmer(OUTCOME ~ EXPECT + (EXPECT|sub),  vic.df)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.0529862 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.cog_raw <- lmer(OUTCOME ~ EXPECT + (EXPECT|sub), cog.df)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 2.36973 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.pain_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (1|sub), pain.df)\nmodel.vic_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (1|sub),  vic.df)\nmodel.cog_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (1|sub), cog.df)\n\n\nmodel.pain_z <- lmer(OUTCOME ~ EXPECT_zscore + (EXPECT_zscore|sub), pain.df)\nmodel.pain_bothz <- lmer(OUTCOME_zscore ~ EXPECT_zscore + (EXPECT_zscore|sub), pain.df)\nmodel.pain_bothCM <- lmer(OUTCOME_demean ~ EXPECT_demean + (EXPECT_demean|sub), pain.df)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.0126555 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.pain_CM <- lmer(OUTCOME ~ EXPECT_demean + (EXPECT_demean|sub), pain.df)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.161577 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nprint_dash(\"model with Z scores :: Pain\")## \n## \n## ----------------------------------------\n## model with Z scores :: Pain\n## ----------------------------------------\nsummary(model.pain_z)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | sub)\n##    Data: pain.df\n## \n## REML criterion at convergence: 52401.2\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5165 -0.5939  0.0074  0.6040  4.3649 \n## \n## Random effects:\n##  Groups   Name          Variance Std.Dev. Corr\n##  sub      (Intercept)   636.60   25.231       \n##           EXPECT_zscore  45.32    6.732   0.25\n##  Residual               516.89   22.735       \n## Number of obs: 5701, groups:  sub, 108\n## \n## Fixed effects:\n##               Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)    60.2351     2.4643 103.9474   24.44   <2e-16 ***\n## EXPECT_zscore   8.1635     0.7389 102.9673   11.05   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## EXPECT_zscr 0.169\nprint_dash(\"model with Z scores :: Vicarious\")## \n## \n## ----------------------------------------\n## model with Z scores :: Vicarious\n## ----------------------------------------\nsummary(model.vic_z)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | sub)\n##    Data: vic.df\n## \n## REML criterion at convergence: 55765.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.0181 -0.6539 -0.2608  0.4712  5.1554 \n## \n## Random effects:\n##  Groups   Name          Variance Std.Dev. Corr\n##  sub      (Intercept)   128.10   11.32        \n##           EXPECT_zscore  20.16    4.49    0.56\n##  Residual               581.72   24.12        \n## Number of obs: 6023, groups:  sub, 109\n## \n## Fixed effects:\n##               Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)     28.910      1.148 110.354   25.19   <2e-16 ***\n## EXPECT_zscore    5.741      0.593 113.213    9.68   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## EXPECT_zscr 0.483\nprint_dash(\"model with Z scores :: Cognitive\")## \n## \n## ----------------------------------------\n## model with Z scores :: Cognitive\n## ----------------------------------------\nsummary(model.cog_z)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | sub)\n##    Data: cog.df\n## \n## REML criterion at convergence: 52720.9\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.0458 -0.6033 -0.1539  0.4586  6.6938 \n## \n## Random effects:\n##  Groups   Name          Variance Std.Dev. Corr\n##  sub      (Intercept)   163.82   12.799       \n##           EXPECT_zscore  23.29    4.825   0.38\n##  Residual               367.83   19.179       \n## Number of obs: 5977, groups:  sub, 109\n## \n## Fixed effects:\n##               Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)    30.4662     1.2622 108.1152   24.14   <2e-16 ***\n## EXPECT_zscore   7.1026     0.5792 108.5177   12.26   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## EXPECT_zscr 0.345\nprint_dash(\"model with raw scores, i.e. non Zscores :: Pain\")## \n## \n## ----------------------------------------\n## model with raw scores, i.e. non Zscores :: Pain\n## ----------------------------------------\nsummary(model.pain_raw)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT + (EXPECT | sub)\n##    Data: pain.df\n## \n## REML criterion at convergence: 52342.5\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5451 -0.5990  0.0130  0.6041  4.3842 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr \n##  sub      (Intercept) 885.9061 29.7642       \n##           EXPECT        0.0407  0.2017  -0.58\n##  Residual             513.2390 22.6548       \n## Number of obs: 5701, groups:  sub, 108\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)  48.2011     2.9898 50.6459   16.12   <2e-16 ***\n## EXPECT        0.2798     0.0231 81.9412   12.12   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##        (Intr)\n## EXPECT -0.601\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 5.82673 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nprint_dash(\"model with raw scores, i.e. non Zscores :: Vicarious\")## \n## \n## ----------------------------------------\n## model with raw scores, i.e. non Zscores :: Vicarious\n## ----------------------------------------\nsummary(model.vic_raw)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT + (EXPECT | sub)\n##    Data: vic.df\n## \n## REML criterion at convergence: 55709.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.0287 -0.6525 -0.2573  0.4708  5.1655 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev. Corr \n##  sub      (Intercept)  61.4815  7.8410       \n##           EXPECT        0.0205  0.1432  -0.30\n##  Residual             581.2022 24.1081       \n## Number of obs: 6023, groups:  sub, 109\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)  19.85080    0.92571 104.49803   21.44   <2e-16 ***\n## EXPECT        0.21925    0.01981 119.99847   11.06   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##        (Intr)\n## EXPECT -0.492\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 0.0529862 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nprint_dash(\"model with raw scores, i.e. non Zscores :: Cognitive\")## \n## \n## ----------------------------------------\n## model with raw scores, i.e. non Zscores :: Cognitive\n## ----------------------------------------\nsummary(model.cog_raw)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT + (EXPECT | sub)\n##    Data: cog.df\n## \n## REML criterion at convergence: 52652\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.7736 -0.6043 -0.1597  0.4548  6.6799 \n## \n## Random effects:\n##  Groups   Name        Variance  Std.Dev. Corr \n##  sub      (Intercept)  64.12102  8.0076       \n##           EXPECT        0.01698  0.1303  -0.09\n##  Residual             369.70089 19.2276       \n## Number of obs: 5977, groups:  sub, 109\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)  19.47584    0.89942 119.72844   21.65   <2e-16 ***\n## EXPECT        0.25735    0.01726 121.97945   14.91   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##        (Intr)\n## EXPECT -0.339\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 2.36973 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nprint_dash(\"model with raw Pain scores CMC and CWC\")## \n## \n## ----------------------------------------\n## model with raw Pain scores CMC and CWC\n## ----------------------------------------\n# summary(model.pain_cmc)\nsjPlot::tab_model(model.pain_cmc, p.val = \"kr\", show.df = TRUE)\nprint_dash(\"model comparison\")## \n## \n## ----------------------------------------\n## model comparison\n## ----------------------------------------\nanova(model.pain_z, model.pain_raw)## refitting model(s) with ML (instead of REML)## Data: pain.df\n## Models:\n## model.pain_z: OUTCOME ~ EXPECT_zscore + (EXPECT_zscore | sub)\n## model.pain_raw: OUTCOME ~ EXPECT + (EXPECT | sub)\n##                npar   AIC   BIC logLik deviance  Chisq Df Pr(>Chisq)\n## model.pain_z      6 52418 52458 -26203    52406                     \n## model.pain_raw    6 52344 52384 -26166    52332 74.224  0\n# _______________________________________________________\n# # Example using broom to get a tidied summary\n# library(broom)\n# \n# tidy_model_pain_z <- tidy(model.pain_z)\n# tidy_model_vic_z <- tidy(model.vic_z)\n# # ... and so on for the other models\n# \n# # Combine tidied summaries into one data frame\n# all_tidy_effects <- bind_rows(\n#   tidy_model_pain_z %>% mutate(model = \"Pain Z\"),\n#   tidy_model_vic_z %>% mutate(model = \"Vicarious Z\"),\n#   # ... and so on for the other models\n# )\n# \n# # Print the combined tidied model summaries\n# print(all_tidy_effects)"},{"path":"scaling.html","id":"check-lmer-cmc-model","chapter":"7 within / between subject effect and Scaling","heading":"7.7.2 check lmer CMC model","text":"","code":"\nsjPlot::tab_model(model.pain_cmc, p.val = \"kr\", show.df = TRUE)"},{"path":"scaling.html","id":"lmer-combined-coefficients-into-table","chapter":"7 within / between subject effect and Scaling","heading":"7.7.3 lmer combined coefficients into table","text":"Since multiple models, combine coefficients (within subject expectation effects) one table","code":"\nlibrary(DT)\n# Print or use kable/DT for a nicer table in R Markdown ________________________\nDT::datatable(all_fixed_effects,\n                            options = list(\n                              pageLength = 25,\n                columnDefs = list(\n                  list(targets = c(4,5,6),  # Assuming 2nd and 3rd columns are numeric\n                       render = JS(\n                         \"function(data, type, row, meta) {\",\n                         \"return type === 'display' || type === 'filter' ?\",\n                         \"parseFloat(data).toFixed(3) : data;\",\n                         \"}\"\n                       )\n                  )\n                )\n              ),\n             caption = \"Summary of Non-Intercept Fixed Effects across Models\")"},{"path":"scaling.html","id":"plot-how-much-of-the-cmcs-predict-outcome-ratings","chapter":"7 within / between subject effect and Scaling","heading":"7.7.4 plot how much of the CMCs predict outcome ratings","text":"","code":""},{"path":"scaling.html","id":"plot-how-much-of-the-demeans-predict-outcome-ratings","chapter":"7 within / between subject effect and Scaling","heading":"7.7.5 plot how much of the demeans predict outcome ratings","text":"Demeaning similar efect zscoring, difference mean forced 0 standard deviation 1 zscore.\nsense, removing subject effects homing onthe within subject effects.","code":"\nlibrary(ggplot2)\nlibrary(gridExtra)\nlibrary(grid)\n\nplot_endertofighi <- function(data, taskname, color_low=\"gray\", color_high=\"black\") {\n  runtype_filter <- paste0(\"runtype-\", taskname)\n  data$sub_numeric <- as.numeric(as.factor(data$sub))\n  # Plot for demean ____________________________________________________________\n  g.Odemean <- ggplot(data, \n                     aes(y = OUTCOME_demean, x = EXPECT_demean, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n    #geom_point(size = .1) +\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = .3) +\n    theme_classic() +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    # theme(legend.position = \"none\") + \n        theme(legend.position = \"none\",\n          plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) \n    # ylim(0,200)\n  g.Odemean <- ggplot_largetext(g.Odemean)  # Assuming ggplot_largetext is a defined function\n  \n\n  # Plot for demean ____________________________________________________________\n  g.demean <- ggplot(data, \n                     aes(y = OUTCOME, x = EXPECT_demean, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n    geom_point(size = .1, alpha = .1) +\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = .3) +\n    theme_classic() +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    # theme(legend.position = \"none\") + \n        theme(legend.position = \"none\",\n          plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) +\n    ylim(0,200)\n  g.demean <- ggplot_largetext(g.demean)  # Assuming ggplot_largetext is a defined function\n  \n    # Plot for Cluster-wise means ________________________________________________\n  g.Ocm <- ggplot(data, \n                 aes(y = OUTCOME, x = EXPECT_cm, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n    #geom_point(size = .1, alpha = .1) +\n  stat_summary(\n    fun = mean, geom = \"point\",\n    aes(group = sub), # Group by subject\n    size = 1\n  ) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = 1) + #size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) +\n    ylim(0,200)\n  g.Ocm <- ggplot_largetext(g.Ocm)  # Assuming ggplot_largetext is a defined function\n  \n  \n  \n  \n  # Plot for Cluster-wise means ________________________________________________\n  g.cm <- ggplot(data, \n                 aes(y = OUTCOME_cm, x = EXPECT_cm, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n      stat_summary(\n    fun.y = mean, geom = \"point\",\n    aes(group =sub_numeric), #EXPECT_cm),\n    size = 1\n  ) +\n   geom_point(size = .1, alpha = .1) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = 1) + #size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) +\n    ylim(-10,200)\n  g.cm <- ggplot_largetext(g.cm)  # Assuming ggplot_largetext is a defined function\n  \n  \n  # Plot for Zscore ____________________________________________________________\n  g.z <- ggplot(data, \n                 aes(y = OUTCOME, x = EXPECT_zscore, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n    #geom_point(size = .1) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\", plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n\n    coord_fixed(ratio = 1)\n  g.z <- ggplot_largetext(g.z)  # Assuming ggplot_largetext is a defined function\n  \n  \n    # Plot for Zscore ____________________________________________________________\n  g.z2 <- ggplot(data, \n                 aes(y = OUTCOME_zscore, x = EXPECT_zscore, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n    #geom_point(size = .1) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\", plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n\n    coord_fixed(ratio = 1)\n  g.z2 <- ggplot_largetext(g.z2)  # Assuming ggplot_largetext is a defined function\n  \n  # Combine plots\n  title_text <- paste(tools::toTitleCase(taskname), \"task: within-subject centered vs. subject-cluster means\\n\")\n  title_grob <- grid::textGrob(title_text, gp = gpar(fontsize = 18), vjust = 1)\n\n  # grid.draw(gridExtra::grid.arrange(g.demean, g.cm, g.z, ncol = 3,\n  #                         widths = c(1,  1, 1), heights = c(1, 1, 1), \n  #                         top = title_grob\n  # ))\n  \n  \n    # Plot for Cluster-wise means ________________________________________________\n  g.cmc <- ggplot(data, \n                 aes(y = OUTCOME_cmc, x = EXPECT_cmc, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n      stat_summary(\n    fun.y = mean, geom = \"point\",\n    aes(group =sub_numeric), #EXPECT_cm),\n    size = 1\n  ) +\n   geom_point(size = .1, alpha = .1) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = 1) + #size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) +\n    ylim(-10,200)\n  g.cmc <- ggplot_largetext(g.cmc)  # Assuming ggplot_largetext is a defined function\n  \n      # Plot for raw means ________________________________________________\n  g.raw <- ggplot(data, \n                 aes(y = OUTCOME, x = EXPECT, colour = sub_numeric, group = sub), size = .3, color = 'gray') +\n  #     stat_summary(\n  #   fun.y = mean, geom = \"point\",\n  #   aes(group =sub_numeric), #EXPECT_cm),\n  #   size = .1, alpha = .1\n  # ) +\n   geom_point(size = .1, alpha = .1) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = .3) + #size = .3) +\n    theme_classic() + \n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) + \n    coord_fixed(ratio = 1) +\n    ylim(-10,200)\n  g.raw <- ggplot_largetext(g.raw)  # Assuming ggplot_largetext is a defined function\n  \n  \n  arranged_plots <- (ggpubr::ggarrange(\n        g.demean, g.Ocm, g.cm, g.z, g.z2, g.Odemean, g.cmc, g.raw,\n        common.legend = FALSE,\n        legend = \"none\",\n        ncol = 4,\n        nrow = 2,\n        widths = c(1,1,1),\n        heights = c(1,1),\n        align = \"v\"\n      ))\n  #return(wbeffect)\n  \n  annotated_plots <- ggpubr::annotate_figure(arranged_plots,\n                                   top = title_grob)\n  grid.draw(annotated_plots)\n\n  \n}\n\n#plot_endertofighi(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ], \"pain\")## Warning: The `fun.y` argument of `stat_summary()` is deprecated as of ggplot2 3.3.0.\n## ℹ Please use the `fun` argument instead.\n## ℹ The deprecated feature was likely used in the cueR package.\n##   Please report the issue to the authors.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.## Warning: Removed 2 rows containing missing values (`geom_smooth()`).\nsubjectwise <- meanSummary_2continuous(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ], \n                                            c(\"sub\"),\"OUTCOME\", \"EXPECT\")\nsubjectwise$EXPECT_cm <- subjectwise$DV2_mean_per_sub\nsubjectwise$OUTCOME_cm <- subjectwise$DV1_mean_per_sub\ncolor_low = \"red\"; color_high = \"darkred\"\n    # Plot for Cluster-wise means ________________________________________________\n# cueR::plot_ggplot_correlation(subjectwise, y = DV1_mean_per_sub, x = DV2_mean_per_sub,\n#                         p_acc = 0.001, r_acc = 0.001, limit_min = 0, limit_max = 200, label_position = 180)\nsubjectwise$sub_numeric <- as.numeric((subjectwise$sub))## Warning: NAs introduced by coercion\ng.manualOcm <- ggplot(subjectwise,\n                 aes(y = OUTCOME_cm, x = EXPECT_cm, colour = sub_numeric, group = sub), size = .3, color = ) +\n    geom_point(size = 2, alpha = 1, color = \"red\") +\n  # stat_summary(\n  #   fun.y = mean, geom = \"point\",\n  #   aes(group = sub), # Group by subject\n  #   size = 1\n  # ) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    #geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = 1) + #size = .3) +\n    theme_classic() +\n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) +\n    coord_fixed(ratio = 1) +\n    ylim(0,200)\n  g.manualOcm <- ggplot_largetext(g.manualOcm)  # Assuming ggplot_largetext is a defined function\n  g.manualOcm\n#### TODO: DEBUG WHY?\n  mean_xy <- function(x, y) {\n  data.frame(x = mean(x, na.rm = TRUE), y = mean(y, na.rm = TRUE))\n}\ndf.PVC_center$sub_numeric <- as.numeric(df.PVC_center$sub)## Warning: NAs introduced by coercion\n    g.Ocm <- ggplot(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ],\n                 aes(y = OUTCOME, x = EXPECT_cm, colour = sub_numeric, group = as.factor(sub)), size = .3, color = 'gray') +\n    #geom_point(size = .1, alpha = .1) +\n  stat_summary(\n    fun.data = mean_xy, geom = \"point\",\n    aes(group = as.factor(sub)), # Group by subject\n    size = 1\n  ) +\n    scale_colour_gradient(low = color_low, high = color_high) +\n    geom_abline(intercept = 0, slope = 1, linetype = \"dashed\", color = color_low) +  # Add the identity line\n    geom_smooth(method = 'lm', formula = y ~ x, se = FALSE, size = 1) + #size = .3) +\n    theme_classic() +\n        theme(legend.position = \"none\",\n              plot.margin = margin(t = .3, r = .1, b = .1, l = .1, unit = \"pt\")) +\n    coord_fixed(ratio = 1) +\n    ylim(0,200)\n  g.Ocm <- ggplot_largetext(g.Ocm)  # Assuming ggplot_largetext is a defined function\n  g.Ocm## Warning: Computation failed in `stat_summary()`\n## Caused by error in `h()`:\n## ! error in evaluating the argument 'x' in selecting a method for function 'mean': argument \"y\" is missing, with no default\n# Checks\nlibrary(dplyr)\ngroup_counts <- df.PVC_center %>% count(sub)\nprint(group_counts)## # A tibble: 109 × 2\n##    sub          n\n##    <chr>    <int>\n##  1 sub-0002    92\n##  2 sub-0003   205\n##  3 sub-0004   197\n##  4 sub-0005   200\n##  5 sub-0006   200\n##  6 sub-0007   199\n##  7 sub-0008   143\n##  8 sub-0009   209\n##  9 sub-0010   192\n## 10 sub-0011   190\n## # ℹ 99 more rows\n# plot\nggplot(df.PVC_center, aes(x = EXPECT_cm, y = OUTCOME, color = as.factor(sub))) +\n  geom_point() + theme(legend.position = \"none\")"},{"path":"scaling.html","id":"analysis-4-random-effects-of-expectation.-extract-subjectwise-coefficients.-see-if-they-are-similar-across-tasks.","chapter":"7 within / between subject effect and Scaling","heading":"7.8 Analysis 4: Random effects of Expectation. extract subjectwise coefficients. see if they are similar across tasks.","text":"","code":""},{"path":"scaling.html","id":"function-extract-random-effect-of-expectation","chapter":"7 within / between subject effect and Scaling","heading":"7.8.0.1 function; extract random effect of expectation","text":"","code":"\nextract_fix_rand_effect <- function(model, taskname){\nfixEffect <<- as.data.frame(fixef(model))\nrandEffect <<- as.data.frame(ranef(model))\n\n\nrandEffect$newcoef <- mapvalues(randEffect$term,\n    from = c(as.character(unique(randEffect$term)[1]),\n             as.character(unique(randEffect$term)[2])\n             ),\n    to = c(\"rand_intercept\", \"rand_withinexpect\" )\n)\n\nrand_subset <- subset(randEffect, select = -c(grpvar, term, condsd))\nwide_rand <- tidyr::spread(rand_subset, key = newcoef, value = condval)\n\nwide_fix <- do.call(\n    \"rbind\",\n    replicate(nrow(wide_rand),\n        as.data.frame(t(as.matrix(fixEffect))),\n        simplify = FALSE\n    )\n)\nrownames(wide_fix) <- NULL\nnew_wide_fix <- dplyr::rename(wide_fix,\n    fix_intercept = colnames(wide_fix)[1],\n    fix_withinexpect = colnames(wide_fix)[2],\n)\n\ntotal <- cbind(wide_rand, new_wide_fix)\ntotal$task <- taskname\nnew_total <- total %>% dplyr::select(task, everything())\nnew_total <- dplyr::rename(total, subj = grp)\nreturn(new_total)\n}\nrange(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", \"EXPECT_cmc\"])## [1] -24.73651  42.19812\nrange(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", \"EXPECT_demean\"])## [1] -70.10835 114.77069\ncueR::print_dash(\"Correlation Pain\")## \n## \n## ----------------------------------------\n## Correlation Pain\n## ----------------------------------------\ncor(df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", c(\"OUTCOME\", \"EXPECT_demean\",\"EXPECT_cm\", \"EXPECT_cmc\")])##                 OUTCOME EXPECT_demean EXPECT_cm EXPECT_cmc\n## OUTCOME       1.0000000     0.5363011 0.5845030  0.5845030\n## EXPECT_demean 0.5363011     1.0000000 0.3406594  0.3406594\n## EXPECT_cm     0.5845030     0.3406594 1.0000000  1.0000000\n## EXPECT_cmc    0.5845030     0.3406594 1.0000000  1.0000000\ncueR::print_dash(\"Correlation Vicarious\")## \n## \n## ----------------------------------------\n## Correlation Vicarious\n## ----------------------------------------\ncor(df.PVC_center[df.PVC_center$runtype == \"runtype-vicarious\", c(\"OUTCOME\", \"EXPECT_demean\",\"EXPECT_cm\", \"EXPECT_cmc\")])##                 OUTCOME EXPECT_demean  EXPECT_cm EXPECT_cmc\n## OUTCOME       1.0000000     0.1824976  0.2518361  0.2518361\n## EXPECT_demean 0.1824976     1.0000000 -0.2433859 -0.2433859\n## EXPECT_cm     0.2518361    -0.2433859  1.0000000  1.0000000\n## EXPECT_cmc    0.2518361    -0.2433859  1.0000000  1.0000000\ncueR::print_dash(\"Correlation Cognitive\")## \n## \n## ----------------------------------------\n## Correlation Cognitive\n## ----------------------------------------\ncor(df.PVC_center[df.PVC_center$runtype == \"runtype-cognitive\", c(\"OUTCOME\", \"EXPECT_demean\",\"EXPECT_cm\", \"EXPECT_cmc\")])##                 OUTCOME EXPECT_demean  EXPECT_cm EXPECT_cmc\n## OUTCOME       1.0000000     0.2925215  0.3183978  0.3183978\n## EXPECT_demean 0.2925215     1.0000000 -0.2133532 -0.2133532\n## EXPECT_cm     0.3183978    -0.2133532  1.0000000  1.0000000\n## EXPECT_cmc    0.3183978    -0.2133532  1.0000000  1.0000000\nmodel.pain_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean|sub), df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ], )## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, :\n## Model failed to converge with max|grad| = 1.03868 (tol = 0.002, component 1)## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.vic_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean|sub), df.PVC_center[df.PVC_center$runtype == \"runtype-vicarious\", ])## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 2.02926 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\nmodel.cog_cmc <- lmer(OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean|sub), df.PVC_center[df.PVC_center$runtype == \"runtype-cognitive\", ])## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model failed to converge with max|grad| = 0.00247733 (tol = 0.002, component 1)\n\n## Warning in checkConv(attr(opt, \"derivs\"), opt$par, ctrl = control$checkConv, : Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\ncueR::print_dash(\"lmer Pain\")## \n## \n## ----------------------------------------\n## lmer Pain\n## ----------------------------------------\nsummary(model.pain_cmc)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean | sub)\n##    Data: df.PVC_center[df.PVC_center$runtype == \"runtype-pain\", ]\n## \n## REML criterion at convergence: 52285.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5259 -0.5983  0.0133  0.6028  4.3769 \n## \n## Random effects:\n##  Groups   Name          Variance  Std.Dev. Corr \n##  sub      (Intercept)   310.23596 17.6135       \n##           EXPECT_demean   0.03432  0.1853  -0.24\n##  Residual               515.88891 22.7132       \n## Number of obs: 5701, groups:  sub, 108\n## \n## Fixed effects:\n##               Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)    60.1999     1.7497  91.4795   34.41   <2e-16 ***\n## EXPECT_demean   0.2731     0.0218 110.6741   12.53   <2e-16 ***\n## EXPECT_cmc      1.2508     0.1165  98.0229   10.73   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) EXPECT_d\n## EXPECT_demn -0.264         \n## EXPECT_cmc   0.018 -0.044  \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 1.03868 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\ncueR::print_dash(\"lmer Vicarious\")## \n## \n## ----------------------------------------\n## lmer Vicarious\n## ----------------------------------------\nsummary(model.vic_cmc)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean | sub)\n##    Data: df.PVC_center[df.PVC_center$runtype == \"runtype-vicarious\", ]\n## \n## REML criterion at convergence: 55700.6\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.9305 -0.6507 -0.2508  0.4686  5.1421 \n## \n## Random effects:\n##  Groups   Name          Variance  Std.Dev. Corr\n##  sub      (Intercept)    50.07515  7.0764      \n##           EXPECT_demean   0.01785  0.1336  0.43\n##  Residual               583.37834 24.1532      \n## Number of obs: 6023, groups:  sub, 109\n## \n## Fixed effects:\n##                Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)    29.52784    0.77616 133.06762   38.04   <2e-16 ***\n## EXPECT_demean   0.21937    0.01912 121.52452   11.48   <2e-16 ***\n## EXPECT_cmc      0.53845    0.04916 137.72661   10.95   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) EXPECT_d\n## EXPECT_demn 0.404          \n## EXPECT_cmc  0.044  0.119   \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 2.02926 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\ncueR::print_dash(\"lmer Cognitive\")## \n## \n## ----------------------------------------\n## lmer Cognitive\n## ----------------------------------------\nsummary(model.cog_cmc)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: OUTCOME ~ EXPECT_demean + EXPECT_cmc + (EXPECT_demean | sub)\n##    Data: df.PVC_center[df.PVC_center$runtype == \"runtype-cognitive\", ]\n## \n## REML criterion at convergence: 52623.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.0906 -0.6040 -0.1525  0.4628  6.6981 \n## \n## Random effects:\n##  Groups   Name          Variance  Std.Dev. Corr\n##  sub      (Intercept)    69.73672  8.3509      \n##           EXPECT_demean   0.01815  0.1347  0.16\n##  Residual               367.61753 19.1734      \n## Number of obs: 5977, groups:  sub, 109\n## \n## Fixed effects:\n##                Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)    31.08096    0.85428 102.58765   36.38   <2e-16 ***\n## EXPECT_demean   0.25659    0.01762 112.72401   14.56   <2e-16 ***\n## EXPECT_cmc      0.65240    0.05792 107.46486   11.26   <2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr) EXPECT_d\n## EXPECT_demn 0.192          \n## EXPECT_cmc  0.029  0.044   \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## Model failed to converge with max|grad| = 0.00247733 (tol = 0.002, component 1)\n## Model is nearly unidentifiable: very large eigenvalue\n##  - Rescale variables?\n# stack random effects across pain, vicarious, cognitive task __________________\ndfP <- extract_fix_rand_effect(model.pain_cmc, \"pain\")\ndfV <- extract_fix_rand_effect(model.vic_cmc, \"vicarious\")\ndfC <- extract_fix_rand_effect(model.cog_cmc, \"cognitive\")\npvc_rand <- reshape::merge_recurse(list(dfP, dfV, dfC))\ncolnames(pvc_rand)## [1] \"subj\"              \"rand_intercept\"    \"rand_withinexpect\"\n## [4] \"fix_intercept\"     \"fix_withinexpect\"  \"EXPECT_cmc\"       \n## [7] \"task\"\n# subset data with just the random slopes ______________________________________\npvc_rand_within_subset <- subset(pvc_rand, select = c(task, subj, rand_withinexpect))\npvc_rand_cue <- tidyr::spread(pvc_rand_within_subset, key = task, value = rand_withinexpect)\n\n\n# plot per task and aggregate __________________________________________________\npv <- cueR::plot_ggplot_correlation(data = pvc_rand_cue, x = 'vicarious', y = 'pain', \n                                    p_acc = 0.001, r_acc = 0.01, \n                                    limit_min = -.75, limit_max = .75, label_position = .6)\nvc <- cueR::plot_ggplot_correlation(data = pvc_rand_cue, x = 'cognitive', y = 'vicarious', \n                                    p_acc = 0.001, r_acc = 0.01, \n                                    limit_min = -.75, limit_max = .75, label_position = .6)\ncp <- cueR::plot_ggplot_correlation(data = pvc_rand_cue, x = 'pain', y = 'cognitive', \n                                    p_acc = 0.001, r_acc = 0.01, \n                                    limit_min = -.75, limit_max = .75, label_position = .6)\n\nplots <- ggpubr::ggarrange(pv, vc, cp, ncol = 3, nrow = 1, common.legend = FALSE, legend = \"bottom\")## Warning: Removed 1 rows containing non-finite values (`stat_cor()`).## Warning: Removed 1 rows containing missing values (`geom_point()`).## Warning: Removed 1 rows containing non-finite values (`stat_cor()`).## Warning: Removed 1 rows containing missing values (`geom_point()`).\ntitle_text <- paste(tools::toTitleCase(\"individual differences\\n - expectation effects on outcome ratings\"))\ntitle_grob <- grid::textGrob(title_text, gp = gpar(fontsize = 18), vjust = 1)\nplots_title <- annotate_figure(plots, top = title_grob)\n\n\n# save plots ___________________________________________________________________\n# save_plotname <- file.path(\n#     analysis_dir,\n#     paste(\"randeffect_scatterplot_task-all_\",\n#         as.character(Sys.Date()), \".png\",\n#         sep = \"\"\n#     )\n# )\n# ggsave(save_plotname, width = 10, height = 3)\nplots_title"},{"path":"scaling.html","id":"random-effect-distribution","chapter":"7 within / between subject effect and Scaling","heading":"7.9 Random effect distribution","text":"","code":"\nlibrary(tidyr)## \n## Attaching package: 'tidyr'## The following object is masked from 'package:reshape2':\n## \n##     smiths## The following objects are masked from 'package:Matrix':\n## \n##     expand, pack, unpack\nlibrary(ggplot2)\n\n# Reshape the data to long format ______________________________________________\nlong_data <- pivot_longer(pvc_rand_cue, cols = c(pain, vicarious, cognitive), names_to = \"task\", values_to = \"expectation_randomeffects\")\nlong_data$task <- factor(long_data$task, levels = c(\"pain\", \"vicarious\", \"cognitive\"))\ncustom_colors <- c(\"pain\" = \"#941100\", \"vicarious\" = \"#008F51\", \"cognitive\" = \"#011891\")\n\n# Plotting all three distributions in one plot ______________________________________________\nggplot(long_data, aes(x = expectation_randomeffects, fill = task)) +\n    geom_histogram(position = \"identity\", alpha = 0.5, bins = 30) +\n    scale_fill_manual(values = custom_colors) +\n  scale_color_manual(values = custom_colors) +\n    geom_density(aes(color = task), size = 1.2, alpha = 1, fill = NA) +\n    facet_wrap(~ task) +\n    theme_classic() +\n    ggtitle(\"Random effects of Expectation ratings - distributions of Pain, Vicarious, and Cognitive\")## Warning: Removed 1 rows containing non-finite values (`stat_bin()`).## Warning: Removed 1 rows containing non-finite values (`stat_density()`).\n# overlay at once ______________________________________________\n# Plotting all three distributions overlaid in one plot\nggplot(long_data, aes(x = expectation_randomeffects, fill = task)) +\n    geom_histogram(position = \"identity\", alpha = 0.5, bins = 50, aes(y = ..density..)) +\n    #geom_density(alpha = 0.5, size = .5) +\n    geom_density(aes(color = task), size = 1.2, alpha = 1, fill = NA) +\n    scale_fill_manual(values = custom_colors) +\n    scale_color_manual(values = custom_colors) +\n    theme_classic() +\n    ggtitle(\"Random effects of Expectation ratings - distributions of Pain, Vicarious, and Cognitive\")## Warning: The dot-dot notation (`..density..`) was deprecated in ggplot2 3.4.0.\n## ℹ Please use `after_stat(density)` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.## Warning: Removed 1 rows containing non-finite values (`stat_bin()`).## Warning: Removed 1 rows containing non-finite values (`stat_density()`).\n# Random effect ________________________________________________________________\n# fixEffect <<- as.data.frame(fixef(model.pain_cmc))\n# randEffect <<- as.data.frame(ranef(model.pain_cmc))\n# \n# \n# randEffect$newcoef <- mapvalues(randEffect$term,\n#     from = c(as.character(unique(randEffect$term)[1]),\n#              as.character(unique(randEffect$term)[2])\n#              ),\n#     to = c(\"rand_intercept\", \"rand_withinexpect\" )\n# )\n# \n# rand_subset <- subset(randEffect, select = -c(grpvar, term, condsd))\n# wide_rand <- tidyr::spread(rand_subset, key = newcoef, value = condval)\n# \n# wide_fix <- do.call(\n#     \"rbind\",\n#     replicate(nrow(wide_rand),\n#         as.data.frame(t(as.matrix(fixEffect))),\n#         simplify = FALSE\n#     )\n# )\n# rownames(wide_fix) <- NULL\n# new_wide_fix <- dplyr::rename(wide_fix,\n#     fix_intercept = colnames(wide_fix)[1],\n#     fix_withinexpect = colnames(wide_fix)[2],\n# )\n# \n# total <- cbind(wide_rand, new_wide_fix)\n# total$task <- taskname\n# new_total <- total %>% dplyr::select(task, everything())\n# new_total <- dplyr::rename(total, subj = grp)\n# \n# rand_savefname <- file.path(\n#     analysis_dir,\n#     paste(\"randeffect_task-\", taskname, \"_\",\n#         as.character(Sys.Date()), \"_outlier-cooksd.csv\",\n#         sep = \"\"\n#     )\n# )\n# write.csv(new_total, rand_savefname, row.names = FALSE)\n\n###################################### reference\n#     cooksd <- cueR::lmer_onefactor_cooksd(data, taskname, iv, dv, subject, dv_keyword, model_savefname, print_lmer_output) # run lmer\n#     influential <- as.numeric(names(cooksd)[\n#     (cooksd > (4 / as.numeric(length(unique(data$subject)))))])\n#     data_screen <- data[-influential, ]\n# \n#     ## summary statistics\n#     subjectwise <- meanSummary(data_screen, c(subject, iv), dv)\n#     groupwise <- summarySEwithin(\n#         data = subjectwise,\n#         measurevar = subjectwise_mean, # variable created from above\n#         withinvars = c(iv), # iv\n#         idvar = \"subject\"\n#     )\n# \n#     ## designate plot save location\n#     ggtitle <- paste0(str_to_title(taskname), ggtitle_phrase, \" N = (\", length(unique(data$subject)), \")\");\n#     title <- paste0(str_to_title(taskname), \" - \", str_to_title(dv_keyword))\n#     w = 5; h = 3;\n#     plot_savefname <- file.path(analysis_dir,\n#                                 paste0(\"raincloud_task\", taskname,\"iv-\", iv_keyword, \"_dv-rating-\", dv_keyword,\"_\", as.character(Sys.Date()), \".png\")\n#                                 )\n# \n#     # plot_rainclouds_onefactor\n#     p1 <- plot_halfrainclouds_onefactor(\n#         subjectwise, groupwise,\n#         iv, subjectwise_mean, group_mean, se, subject,\n#         ggtitle, title, xlab, ylab, task_name,ylim,\n#         w, h, dv_keyword, color_scheme, plot_savefname\n#     )\n# randEffect$newcoef <- mapvalues(randEffect$term,\n#     from = c(as.character(unique(randEffect$term)[1]),\n#              as.character(unique(randEffect$term)[2])\n#              ),\n#     to = c(\"rand_intercept\", \"rand_cue\")\n# )\n# \n# rand_subset <- subset(randEffect, select = -c(grpvar, term, condsd))\n# wide_rand <- spread(rand_subset, key = newcoef, value = condval)\n# \n# wide_fix <- do.call(\n#     \"rbind\",\n#     replicate(nrow(wide_rand),\n#         as.data.frame(t(as.matrix(fixEffect))),\n#         simplify = FALSE\n#     )\n# )\n# rownames(wide_fix) <- NULL\n# new_wide_fix <- dplyr::rename(wide_fix,\n#     fix_intercept = colnames(wide_fix)[1],\n#     fix_cue = colnames(wide_fix)[2],\n# )\n# \n# total <- cbind(wide_rand, new_wide_fix)\n# total$task <- taskname\n# new_total <- total %>% dplyr::select(task, everything())\n# new_total <- dplyr::rename(total, subj = grp)\n# \n# rand_savefname <- file.path(\n#     analysis_dir,\n#     paste(\"randeffect_task-\", taskname, \"_\",\n#         as.character(Sys.Date()), \"_outlier-cooksd.csv\",\n#         sep = \"\"\n#     )\n# )\n# write.csv(new_total, rand_savefname, row.names = FALSE)"},{"path":"scaling.html","id":"analysis-5-buchel.-plot-the-distribution-of-stimulus-intensity-as-a-function-of-pain-sensitivity-people","chapter":"7 within / between subject effect and Scaling","heading":"7.10 Analysis 5: Buchel. plot the distribution of stimulus intensity as a function of pain sensitivity people","text":"","code":""},{"path":"scaling.html","id":"analysis-6-create-rawzscore-cue-effect","chapter":"7 within / between subject effect and Scaling","heading":"7.11 Analysis 6: create raw/zscore cue effect","text":"TODO: create new RmdSummary:","code":"\nhead(df.PVC_center)## # A tibble: 6 × 35\n##   src_subject_id session_id param_run_num param_task_name event02_expect_angle\n##            <int>      <int>         <int> <chr>                          <dbl>\n## 1              2          1             1 pain                            5.53\n## 2              2          1             1 pain                           18.9 \n## 3              2          1             1 pain                          103.  \n## 4              2          1             1 pain                           81.2 \n## 5              2          1             1 pain                           97.2 \n## 6              2          1             1 pain                          117.  \n## # ℹ 30 more variables: param_cue_type <chr>, param_stimulus_type <chr>,\n## #   event04_actual_angle <dbl>, trial_index <int>, trial_count_sub <int>,\n## #   trial_ind <dbl>, sub <chr>, ses <chr>, run <chr>, runtype <chr>,\n## #   task <chr>, trial_sub <int>, trial <chr>, cuetype <chr>,\n## #   stimintensity <chr>, DEPc <chr>, DEP <chr>, OUTCOME <dbl>, EXPECT <dbl>,\n## #   OUTCOME_cm <dbl>, OUTCOME_demean <dbl>, EXPECT_cm <dbl>,\n## #   EXPECT_demean <dbl>, OUTCOME_zscore <dbl>, EXPECT_zscore <dbl>, …\ndv <- \"OUTCOME\"\n\n# 3. calculate difference scores and summarize _____________________________\nsub_diff <- subset(df.PVC_center,\n                   select = c(\"sub\", \"ses\", \"run\", \"task\", \"stimintensity\", \"cuetype\", dv))\nhead(sub_diff)## # A tibble: 6 × 7\n##   sub      ses    run    task  stimintensity cuetype      OUTCOME\n##   <chr>    <chr>  <chr>  <chr> <chr>         <chr>          <dbl>\n## 1 sub-0002 ses-01 run-01 pain  low           cuetype-low     40.1\n## 2 sub-0002 ses-01 run-01 pain  high          cuetype-low    107. \n## 3 sub-0002 ses-01 run-01 pain  low           cuetype-high    70.8\n## 4 sub-0002 ses-01 run-01 pain  med           cuetype-high    77.7\n## 5 sub-0002 ses-01 run-01 pain  high          cuetype-high   115. \n## 6 sub-0002 ses-01 run-01 pain  low           cuetype-high    76.6\nsub_diff_NA <- sub_diff %>% filter(!is.na(dv))  # drop NA\n# ___ 1) first, summarize each condition _______________________________________\nsubjectwise <- meanSummary(sub_diff_NA, c(\n    \"sub\", \"ses\", \"run\",\n    \"task\", \"cuetype\",\n    \"stimintensity\"), dv)\n# ___ 2) spread out high and low cue columns ___________________________________\nmean_outcome <- subjectwise[1:(length(subjectwise) - 1)]\nwide <- mean_outcome %>%\n    tidyr::spread(cuetype, mean_per_sub)\n# ___ 3) calculate difference score \"cue effect\" _______________________________\nwide$diff <- wide$`cuetype-high` - wide$`cuetype-low`\nsubjectwise_diff <- meanSummary(wide, c(\"sub\", \"task\"), \"diff\")\nsubjectwise_NA <- subjectwise_diff %>% filter(!is.na(sd)) # drop na values\n# ___ 4) calculate group wise contrast  _______________________________________\ngroupwise_diff <- Rmisc::summarySEwithin(\n    data = subjectwise_NA,\n    measurevar = \"mean_per_sub\", # variable created from above\n    withinvars = \"task\", # iv\n    idvar = \"sub\"\n)## Automatically converting the following non-factors to factors: task\nhead(groupwise_diff)##        task   N mean_per_sub       sd        se       ci\n## 1 cognitive 109     8.164638 6.102858 0.5845478 1.158675\n## 2      pain 108     8.184808 7.561432 0.7275991 1.442380\n## 3 vicarious 109     8.212411 5.560329 0.5325829 1.055672\n# save dataframe _______________________________________________________________\nsorted_df <- subjectwise_diff %>%\n  dplyr::arrange(task) %>%\n  dplyr::rename(cue_contrast_high_gt_low = mean_per_sub)\n# write.csv(sorted_df, file = file.path(main_dir,\"analysis\", \"mixedeffect\", \"dataframes\", \"beh_cueeffect_rawoutcome.csv\"), row.names = FALSE)\n\n# TODO: create json file for describing file metadata. BIDS format please\n# column_metadata <- list(\n#   sub = list(\n# description = \"subject id in BIDS formats\"\n# labels = \"sub-%04d\"\n# ),\n#   task = list(\n#     description = \"Task performed by the subject in cue expectancy task\",\n#     generation_info = \"counter balanced across runs. However number of runs performed are included in computations. Subjects may have different frequencies of tasks performed. Some may have completed 6 pain runs, whereas other may have completed 2 pain runs, depending on how many sessions they attended. \",\n#     labels = c(\"pain\", \"vicarious\", \"cognitive\")\n#   ),\n#   cue_contrast_high_gt_low = list(\n#     description = \"Mean cue difference (high vs. low cue) per subject\",\n#     generation_info = \"Calculated as the mean of cue effects across participants, per task \",\n#   ),\n#   sd = list(\n#     description = \"Standard deviasion\",\n#     generation_info = \"How column3 was generated\",\n#     labels = c(\"Label1\", \"Label2\", \"Label3\")\n#   )\n# )"},{"path":"scaling.html","id":"plot","chapter":"7 within / between subject effect and Scaling","heading":"plot","text":"’ll plot Y function B\nX axis:\nY axis:\ndata point indicates …Conclusion:Include actual content . thoughtsInclude actual content . thoughts","code":""},{"path":"variability.html","id":"variability","chapter":"8 beh :: rating variability","heading":"8 beh :: rating variability","text":"greater variability greater placebo effects.Harris (2005) Effect variability 7-day baseline pain diary assay sensitivity neuropathic pain randomized clinical trials: ACTTION study. doi: 10.1002/art.21407Farrar et al (2014) Effect variability 7-day baseline pain diary assay sensitivity neuropathic pain randomized clinical trials: ACTTION study","code":""},{"path":"variability.html","id":"load-libraries-1","chapter":"8 beh :: rating variability","heading":"load libraries","text":"","code":"\n# parameters ___________________________________________________________________\nmain_dir <- dirname(dirname(getwd()))\ndatadir <- file.path(main_dir, 'data', 'beh', 'beh02_preproc')\nanalysis_dir <- file.path(main_dir, \"analysis\", \"mixedeffect\", \"model09_var\", as.character(Sys.Date()))\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"\ndv <- \"event03_RT\"\ndv_keyword <- \"RT\"\nxlab <- \"\"\ntaskname <- \"pain\"\nylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001\"\n# 1. load data _________________________________________________________________\ndata <- cueR::df_load_beh(datadir,\n                            taskname = taskname,\n                            subject_varkey = subject_varkey,\n                            iv = iv,\n                            exclude = exclude)\n\ncolumn_mapping <- c(\"src_subject_id\" = \"subject\", \n                    \"session_id\" = \"ses\", \n                    \"param_run_num\" = \"run\", \n                    \"param_task_name\" = \"runtype\",\n                    \"param_cue_type\" = \"cue\", \n                    \"param_stimulus_type\" = \"stimintensity\")\ndata <- df_rename_columns(data, column_mapping)\ndata_centered <- cueR::compute_enderstofighi(data, sub=\"subject\",\n                                    outcome = \"event04_actual_angle\",expect= \"event02_expect_angle\",\n                                    ses = \"ses\", run = \"run\")"},{"path":"variability.html","id":"analysis-1-pain-display-distribution-of-data-1","chapter":"8 beh :: rating variability","heading":"8.1 Analysis 1: Pain display distribution of data","text":"Let’s look distribution data. X axis: Y axis:","code":"\n# remove NA values first\ndf.centered_NA <- data_centered %>% filter(!is.na(OUTCOME))  # Remove NA values\nhead(df.centered_NA)## # A tibble: 6 × 75\n##   src_subject_id session_id param_task_name param_run_num param_counterbalance…¹\n##            <int>      <int> <chr>                   <int>                  <int>\n## 1              2          1 pain                        1                      3\n## 2              2          1 pain                        1                      3\n## 3              2          1 pain                        1                      3\n## 4              2          1 pain                        1                      3\n## 5              2          1 pain                        1                      3\n## 6              2          1 pain                        1                      3\n## # ℹ abbreviated name: ¹​param_counterbalance_ver\n## # ℹ 70 more variables: param_counterbalance_block_num <int>,\n## #   param_cue_type <chr>, param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>,\n## #   event01_cue_filename <chr>, ISI01_onset <dbl>, ISI01_biopac <dbl>, …"},{"path":"variability.html","id":"sort-based-on-median-outcome-rating-order","chapter":"8 beh :: rating variability","heading":"8.1.1 Sort based on Median Outcome rating order","text":"","code":"\n# Sort the data by median \"outcome\" in ascending order\nsorted_data <- df.centered_NA %>%\n  group_by(subject) %>%\n  summarize(median_outcome = median(OUTCOME, na.rm = TRUE)) %>%\n  arrange(median_outcome) %>%\n  select(subject)\n\n# Reorder the \"subject\" factor based on the sorted order\ndf.centered_NA$subject <- factor(df.centered_NA$subject, levels = sorted_data$subject)\n\n# Create the ggplot\ng <- ggplot(df.centered_NA, aes(x = subject, y = OUTCOME, fill = subject)) +\n  geom_boxplot(outlier.shape = NA, width = 1.2, position = position_dodge(2)) +  \n  geom_jitter(width = .1, alpha = 0, size = 1) +\n  labs(x = \"Subject\", y = \"Pain Outcome Rating\") +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  scale_x_discrete(breaks = NULL) \n\n# Convert ggplot object to a plotly object with hover information\ng_plotly <- ggplotly(ggplot_largetext(g), tooltip = c(\"x\", \"y\"))## Warning: `position_dodge()` requires non-overlapping x intervals## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\n\n## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\ng_plotly"},{"path":"variability.html","id":"calculate-cue-effect","chapter":"8 beh :: rating variability","heading":"8.2 calculate cue effect","text":"","code":""},{"path":"variability.html","id":"q.-do-those-who-use-the-scale-widely-show-greater-cue-effects","chapter":"8 beh :: rating variability","heading":"8.3 Q. Do those who use the scale widely show greater cue effects?","text":"design conflated variability placebo effect, high cues variability.\nactually ! IQR differ function cue leve.\n’s !pretty obvious now think . larger cue effects wil larger IQRs.\norder one cue effect, need report outcome ratings drastically different depending cue presented.","code":"\ndf.centered_NA$run_order <- NA\ndv <- \"OUTCOME\"\n\n  # 3. calculate difference scores and summarize _____________________________\ndf.centered_NA$run_order[df.centered_NA$run > 3] <- \"a\"\ndf.centered_NA$run_order[df.centered_NA$run <= 3] <- \"b\"\nsub_diff <- subset(df.centered_NA, select = c(\n    \"subject\", \"ses\", \"run\",\n    \"runtype\", \"cue\",\n    \"stimintensity\", dv\n))\n\n# drop NA\nsub_diff_NA <- sub_diff %>% filter(!is.na(dv)) \nsubjectwise <- meanSummary(sub_diff_NA, c(\n    \"subject\", \"ses\", \"run\",\n    \"runtype\", \"cue\",\n    \"stimintensity\"), dv)\n\nmean_outcome <- subjectwise[1:(length(subjectwise) - 1)]\nwide <- mean_outcome %>%\n    tidyr::spread(cue, mean_per_sub)\nwide$stim_name <- NA\nwide$diff <- wide$high_cue - wide$low_cue\nwide$stim_name[wide$stimintensity == \"high_stim\"] <- \"high\"\nwide$stim_name[wide$stimintensity == \"med_stim\"] <- \"med\"\nwide$stim_name[wide$stimintensity == \"low_stim\"] <- \"low\"\nwide$stim_ordered <- factor(wide$stim_name,\n    levels = c(\"low\", \"med\", \"high\")\n)\n\n\nsubjectwise_diff <- meanSummary(wide, c(\"subject\"), \"diff\")\n# subjectwise_diff$stim_ordered <- factor(subjectwise_diff$stim_ordered,\n#     levels = c(\"low\", \"med\", \"high\")\n# )\nsubjectwise_NA <- subjectwise_diff %>% filter(!is.na(sd))\ngroupwise_diff <- summarySE(\n    data = subjectwise_NA,\n    measurevar = \"mean_per_sub\", # variable created from above\n    #withinvars = c(\"stim_ordered\"), # iv\n    #idvar = \"subject\"\n)\n\n# per stim _____________________________________________________________________\n# subjectwise_diff <- meanSummary(wide, c(\"subject\", \"stim_ordered\"), \"diff\")\n# subjectwise_diff$stim_ordered <- factor(subjectwise_diff$stim_ordered,\n#     levels = c(\"low\", \"med\", \"high\")\n# )\n# subjectwise_NA <- subjectwise_diff %>% filter(!is.na(sd)) \n# groupwise_diff <- summarySEwithin(\n#     data = subjectwise_NA,\n#     measurevar = \"mean_per_sub\", # variable created from above\n#     withinvars = c(\"stim_ordered\"), # iv\n#     idvar = \"subject\"\n# )\ncue.iqr <- df.centered_NA %>%\n  group_by(subject, cue) %>%\n  summarize(IQR = IQR(OUTCOME, na.rm = TRUE)) %>%\n  arrange(IQR)## `summarise()` has grouped output by 'subject'. You can override using the\n## `.groups` argument.\nmodel.iqr <- lmer(IQR ~ cue + (1|subject), data = cue.iqr)\nsummary(model.iqr)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: IQR ~ cue + (1 | subject)\n##    Data: cue.iqr\n## \n## REML criterion at convergence: 1794.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.0326 -0.5190 -0.1210  0.4566  2.6943 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  subject  (Intercept) 165.60   12.87   \n##  Residual              66.75    8.17   \n## Number of obs: 227, groups:  subject, 114\n## \n## Fixed effects:\n##             Estimate Std. Error      df t value Pr(>|t|)    \n## (Intercept)   29.550      1.431 149.757  20.654   <2e-16 ***\n## cuelow_cue     0.831      1.086 111.517   0.765    0.446    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##            (Intr)\n## cuelow_cue -0.382\nexpect.iqr <- df.centered_NA %>%\n  group_by(subject) %>%\n  summarize(IQR = IQR(EXPECT, na.rm = TRUE)) %>%\n  arrange(IQR)\n\ncolnames(expect.iqr)## [1] \"subject\" \"IQR\"\ncolnames(subjectwise_NA)## [1] \"subject\"      \"mean_per_sub\" \"sd\"\nmerge_cueeffect_IQR <- merge(subjectwise_NA, expect.iqr, by = \"subject\")\nhead(merge_cueeffect_IQR)##   subject mean_per_sub        sd       IQR\n## 1      10    10.267275 14.728124 45.927555\n## 2     100     5.513644 10.175649 23.331188\n## 3     101     8.155616 21.706200 38.016011\n## 4     103    -4.610429  9.444593  9.118222\n## 5     104     6.278523 18.905402 36.252133\n## 6     105     4.393742 13.162857 24.395731\nrange(merge_cueeffect_IQR$mean_per_sub)## [1] -35.99724  37.83760\nrange(merge_cueeffect_IQR$IQR)## [1]   6.940743 109.358498\ng<- cueR::plot_ggplot_correlation(data = merge_cueeffect_IQR, \n                              x = 'mean_per_sub', y = 'IQR', \n                                    p_acc = 0.001, r_acc = 0.01, \n                                    limit_min = -40, limit_max = 200, label_position = .6)\ng + xlab(\"cue effect (high vs. low cue OUTCOME)\") + ylab(\"EXPECT IQR\") + ylim(0,150) + xlim(-50, 50)## Scale for y is already present.\n## Adding another scale for y, which will replace the existing scale.\n## Scale for x is already present.\n## Adding another scale for x, which will replace the existing scale."},{"path":"variability.html","id":"here-i-plot-the-expectation-rating-distribution-but-sorted-based-on-ones-cue-effect-difference","chapter":"8 beh :: rating variability","heading":"8.4 Here I plot the expectation rating distribution, BUT sorted based on one’s cue effect difference","text":"","code":"\nmerge_df_cue <- merge(subjectwise_NA, df.centered_NA, by = \"subject\")\nhead(merge_df_cue)##   subject mean_per_sub       sd src_subject_id session_id param_task_name\n## 1      10     10.26727 14.72812             10          4            pain\n## 2      10     10.26727 14.72812             10          1            pain\n## 3      10     10.26727 14.72812             10          3            pain\n## 4      10     10.26727 14.72812             10          4            pain\n## 5      10     10.26727 14.72812             10          4            pain\n## 6      10     10.26727 14.72812             10          4            pain\n##   param_run_num param_counterbalance_ver param_counterbalance_block_num\n## 1             2                        4                              2\n## 2             6                        4                              1\n## 3             3                        4                              1\n## 4             2                        4                              2\n## 5             2                        4                              2\n## 6             2                        4                              2\n##   param_cue_type param_stimulus_type param_cond_type param_trigger_onset\n## 1        low_cue            med_stim               2          1616614186\n## 2        low_cue            low_stim               1          1615231970\n## 3       high_cue           high_stim               6          1616008227\n## 4        low_cue            med_stim               2          1616614186\n## 5       high_cue            low_stim               4          1616614186\n## 6       high_cue            low_stim               4          1616614186\n##   param_start_biopac  ITI_onset ITI_biopac ITI_duration event01_cue_onset\n## 1         1616614186 1616614549 1616614549    3.5644388        1616614553\n## 2         1615231970 1615232215 1615232215    0.6961169        1615232216\n## 3         1616008227 1616008469 1616008469    2.1638486        1616008471\n## 4         1616614186 1616614225 1616614225    0.9021652        1616614226\n## 5         1616614186 1616614480 1616614480    3.8734350        1616614484\n## 6         1616614186 1616614521 1616614521    0.8413310        1616614522\n##   event01_cue_biopac event01_cue_type event01_cue_filename ISI01_onset\n## 1         1616614553          low_cue             l007.png  1616614554\n## 2         1615232216          low_cue             l039.png  1615232217\n## 3         1616008471         high_cue             h003.png  1616008472\n## 4         1616614226          low_cue             l003.png  1616614227\n## 5         1616614484         high_cue             h028.png  1616614485\n## 6         1616614522         high_cue             h009.png  1616614523\n##   ISI01_biopac ISI01_duration event02_expect_displayonset event02_expect_biopac\n## 1   1616614554      0.8951526                  1616614555            1616614555\n## 2   1615232217      2.0953798                  1615232219            1615232219\n## 3   1616008472      1.9952071                  1616008474            1616008474\n## 4   1616614227      1.9835362                  1616614229            1616614229\n## 5   1616614485      1.7873995                  1616614487            1616614487\n## 6   1616614523      1.8900447                  1616614525            1616614525\n##   event02_expect_responseonset event02_expect_RT event02_expect_angle\n## 1                   1616614556          1.617795             2.070031\n## 2                   1615232220          1.518819            36.869898\n## 3                   1616008477          3.368093            55.799516\n## 4                   1616614232          3.089105            40.451958\n## 5                   1616614490          2.976417            99.462322\n## 6                   1616614527          2.601101            71.417000\n##   event02_expect_angle_label ISI02_onset ISI02_biopac ISI02_duration\n## 1                        FIX  1616614559   1616614559      7.5599790\n## 2                        FIX  1615232223   1615232223      4.5597293\n## 3                        FIX  1616008478   1616008478      0.6596248\n## 4                        FIX  1616614233   1616614233      0.5646281\n## 5                        FIX  1616614491   1616614491     14.6685627\n## 6                        FIX  1616614529   1616614529      0.7711728\n##   event03_stimulus_type event03_stimulus_displayonset event03_stimulus_biopac\n## 1              med_stim                    1616614566              1616614566\n## 2              low_stim                    1615232228              1615232228\n## 3             high_stim                    1616008479              1616008479\n## 4              med_stim                    1616614234              1616614234\n## 5              low_stim                    1616614506              1616614506\n## 6              low_stim                    1616614529              1616614529\n##   event03_stimulus_C_stim_match event03_stimulusC_response\n## 1                            NA                          0\n## 2                            NA                          0\n## 3                            NA                          0\n## 4                            NA                          0\n## 5                            NA                          0\n## 6                            NA                          0\n##   event03_stimulusC_responsekeyname event03_stimulusC_reseponseonset\n## 1                                NA                                0\n## 2                                NA                                0\n## 3                                NA                                0\n## 4                                NA                                0\n## 5                                NA                                0\n## 6                                NA                                0\n##   event03_stimulusC_RT ISI03_onset ISI03_biopac ISI03_duration\n## 1                    0  1616614575   1616614575       4.987133\n## 2                    0  1615232237   1615232237       4.287938\n## 3                    0  1616008488   1616008488       1.989352\n## 4                    0  1616614243   1616614243       6.494392\n## 5                    0  1616614515   1616614515       2.193067\n## 6                    0  1616614538   1616614538       6.684188\n##   event04_actual_displayonset event04_actual_biopac\n## 1                  1616614580            1616614580\n## 2                  1615232241            1615232241\n## 3                  1616008490            1616008490\n## 4                  1616614249            1616614249\n## 5                  1616614517            1616614517\n## 6                  1616614545            1616614545\n##   event04_actual_responseonset event04_actual_RT event04_actual_angle\n## 1                   1616614583          2.508353            33.562744\n## 2                   1615232244          2.684495            13.253716\n## 3                   1616008493          3.525335            69.957683\n## 4                   1616614252          2.417763            28.316355\n## 5                   1616614519          1.984204             9.954607\n## 6                   1616614548          2.704694            20.609693\n##   event04_actual_angle_label param_end_instruct_onset param_end_biopac\n## 1                        FIX               1616614584       1616614584\n## 2                        FIX               1615232368       1615232368\n## 3                        FIX               1616008626       1616008626\n## 4                        FIX               1616614584       1616614584\n## 5                        FIX               1616614584       1616614584\n## 6                        FIX               1616614584       1616614584\n##   param_experiment_duration                        event03_stimulus_P_trigger\n## 1                  398.5102 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n## 2                  398.1037 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n## 3                  399.0270 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n## 4                  398.5102 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n## 5                  398.5102 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n## 6                  398.5102 Command Recieved: TRIGGER_AND_Response: RESULT_OK\n##   event03_stimulus_P_delay_between_medoc event03_stimulus_V_patientid\n## 1                                      0                           NA\n## 2                                      0                           NA\n## 3                                      0                           NA\n## 4                                      0                           NA\n## 5                                      0                           NA\n## 6                                      0                           NA\n##   event03_stimulus_V_filename event03_stimulus_C_stim_num\n## 1                          NA                           0\n## 2                          NA                           0\n## 3                          NA                           0\n## 4                          NA                           0\n## 5                          NA                           0\n## 6                          NA                           0\n##   event03_stimulus_C_stim_filename delay_between_medoc ses run runtype      cue\n## 1                               NA          0.05064011   4   2    pain  low_cue\n## 2                               NA          0.05586195   1   6    pain  low_cue\n## 3                               NA          0.04395199   3   3    pain high_cue\n## 4                               NA          0.08373189   4   2    pain  low_cue\n## 5                               NA          0.06575012   4   2    pain high_cue\n## 6                               NA          0.04667401   4   2    pain high_cue\n##   stimintensity   OUTCOME    EXPECT OUTCOME_cm OUTCOME_demean EXPECT_cm\n## 1      med_stim 33.562744  2.070031   40.66489      -7.102146  42.56259\n## 2      low_stim 13.253716 36.869898   40.66489     -27.411174  42.56259\n## 3     high_stim 69.957683 55.799516   40.66489      29.292793  42.56259\n## 4      med_stim 28.316355 40.451958   40.66489     -12.348535  42.56259\n## 5      low_stim  9.954607 99.462322   40.66489     -30.710283  42.56259\n## 6      low_stim 20.609693 71.417000   40.66489     -20.055197  42.56259\n##   EXPECT_demean OUTCOME_zscore EXPECT_zscore trial_index lag.OUTCOME_demean\n## 1    -40.492556     -0.3268431   -1.40964500          12          -20.05520\n## 2     -5.692689     -1.2614711   -0.19817644           9           43.30186\n## 3     13.236929      1.3480638    0.46080992           8          -19.97422\n## 4     -2.110629     -0.5682836   -0.07347616           2          -28.36097\n## 5     56.899736     -1.4132971    1.98081910          10           46.57600\n## 6     28.854414     -0.9229466    1.00449278          11          -30.71028\n##   EXPECT_cmc OUTCOME_cmc run_order\n## 1  -18.68492   -23.95299         b\n## 2  -18.68492   -23.95299         a\n## 3  -18.68492   -23.95299         b\n## 4  -18.68492   -23.95299         b\n## 5  -18.68492   -23.95299         b\n## 6  -18.68492   -23.95299         b\n# validate _____________________________________________________________________\n# sorted_data <- merge_df_cue %>%\n#   group_by(subject) %>%\n#   arrange(mean_per_sub)\n\n# Reorder the \"subject\" factor based on the sorted order\ng <- ggplot(merge_df_cue, aes(x = reorder(subject, mean_per_sub), y = EXPECT, fill = subject)) +\n  geom_boxplot(outlier.shape = NA, width = 1.2, position = position_dodge(2)) +  \n  geom_jitter(width = .1, alpha = 0, size = 1) +\n  labs(x = \"Subject (sorted based on Cue effect size (High vs. Low Outcome rating)\", y = \"Pain Expect Rating\") +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  scale_x_discrete(breaks = NULL) \n\n# Convert ggplot object to a plotly object with hover information\ng_plotly <- ggplotly(ggplot_largetext(g), tooltip = c(\"x\", \"y\"))## Warning: `position_dodge()` requires non-overlapping x intervals## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\n\n## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\ng_plotly"},{"path":"variability.html","id":"those-who-use-the-scale-widely-will-have-greater-cue-effects-simply-because-they-use-the-scale-widely","chapter":"8 beh :: rating variability","heading":"8.5 those who use the scale widely will have greater cue effects, simply because they use the scale widely!","text":"doesn’t necessarily indicate expectation cue correlations high\ngrater scale use, also susceiptible cues?\nwider IQR -> greater correlation expectation outcome ratings?\n> wider scale use, likely expectation outcome ratings corerlated\nmakes sense, anchoring bias, expectation follow cue, thereby scale might wider? compared ignore cue? ’m sure.","code":"\n# expect.iqr <- df.centered_NA %>%\n#   group_by(subject) %>%\n#   summarize(IQR = IQR(EXPECT, na.rm = TRUE)) %>%\n#   arrange(IQR)\nhead(df.centered_NA)## # A tibble: 6 × 76\n##   src_subject_id session_id param_task_name param_run_num param_counterbalance…¹\n##            <int>      <int> <chr>                   <int>                  <int>\n## 1              2          1 pain                        1                      3\n## 2              2          1 pain                        1                      3\n## 3              2          1 pain                        1                      3\n## 4              2          1 pain                        1                      3\n## 5              2          1 pain                        1                      3\n## 6              2          1 pain                        1                      3\n## # ℹ abbreviated name: ¹​param_counterbalance_ver\n## # ℹ 71 more variables: param_counterbalance_block_num <int>,\n## #   param_cue_type <chr>, param_stimulus_type <chr>, param_cond_type <int>,\n## #   param_trigger_onset <dbl>, param_start_biopac <dbl>, ITI_onset <dbl>,\n## #   ITI_biopac <dbl>, ITI_duration <dbl>, event01_cue_onset <dbl>,\n## #   event01_cue_biopac <dbl>, event01_cue_type <chr>,\n## #   event01_cue_filename <chr>, ISI01_onset <dbl>, ISI01_biopac <dbl>, …\ncorr_n_iqr <- df.centered_NA %>%\n  dplyr::group_by(subject) %>%\n  dplyr::summarise(\n    correlation = cor(EXPECT, OUTCOME, use = \"complete.obs\"),\n    IQR = IQR(EXPECT, na.rm = TRUE)\n  )\n\nggplot(corr_n_iqr, aes(x = correlation, y = IQR)) +\n  geom_point() +  # This adds the scatter plot points\n  theme_classic() +  # Optional: Adds a minimal theme to the plot\n  # coord_fixed(aspect.ratio = 1) +\n  labs(\n    title = \"Scatter Plot of Correlation vs. IQR\",\n    x = \"Correlation\",\n    y = \"IQR\"\n  )## Warning: Removed 1 rows containing missing values (`geom_point()`).\ncueR::plot_ggplot_correlation(data = corr_n_iqr, x = 'correlation', y = 'IQR',\n                                    p_acc = 0.001, r_acc = 0.01,\n                                    limit_min = -40, limit_max = 200, label_position = .6)## Warning: Removed 1 rows containing non-finite values (`stat_cor()`).\n## Removed 1 rows containing missing values (`geom_point()`)."},{"path":"variability.html","id":"sort-based-on-iqr","chapter":"8 beh :: rating variability","heading":"8.5.1 Sort based on IQR","text":"","code":"\nsorted_data <- df.centered_NA %>%\n  group_by(subject) %>%\n  summarize(IQR = IQR(OUTCOME, na.rm = TRUE)) %>%\n  arrange(IQR)\n# Reorder the \"subject\" factor based on the sorted order\ndf.centered_NA$subject <- factor(df.centered_NA$subject, levels = sorted_data$subject)\n\n# Create the ggplot\ng <- ggplot(df.centered_NA, aes(x = subject, y = OUTCOME, fill = subject)) +\n  geom_boxplot(outlier.shape = NA, width = 1.2, position = position_dodge(2)) +  \n  geom_jitter(width = .1, alpha = 0, size = 1) +\n  labs(x = \"Subject\", y = \"Pain Outcome Rating\") +\n  theme_classic() +\n  theme(legend.position = \"none\") +\n  scale_x_discrete(breaks = NULL) \n\n# Convert ggplot object to a plotly object with hover information\ng_plotly <- ggplotly(ggplot_largetext(g), tooltip = c(\"x\", \"y\"))## Warning: `position_dodge()` requires non-overlapping x intervals## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\n\n## Warning: Aspect ratios aren't yet implemented, but you can manually set a\n## suitable height/width\ng_plotly"},{"path":"cueeffects.html","id":"cueeffects","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"9 beh :: Different scaling methods ~ Cue effects","text":"","code":""},{"path":"cueeffects.html","id":"what-is-the-purpose-of-this-notebook-5","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"What is the purpose of this notebook?","text":", extract cue effects across different types ratings\n* cue effects raw outcome rating (“cue_raw_outcome”)\n* cue effects z-scored outcome rating (“cue_z_outcome”)\n* stim effects raw outcome rating (“stim_raw_outcome”)\n* stim effects z-scored outcome rating (“stim_z_outcome”)\n* cue effects / stim effect using raw outcome rating (“cuestim_raw_outcome”)\n* cue effects / stim effects using z score ratings (“cuestim_z_outcome”)\n* regularized cue effects +1 / stim effect +1 using raw outcome rating (“cuestim_raw_outcome_reg”)\n* regularized cue effects / stim effects using z score ratings (“cuestim_z_outcome_reg”)","code":""},{"path":"cueeffects.html","id":"load-libraries-2","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"load libraries","text":"","code":"\nlibrary(car)\nlibrary(psych)\nlibrary(lme4); library(lmerTest)\nlibrary(glmmTMB)\nlibrary(plyr)\nlibrary(dplyr)\nlibrary(cueR)\nlibrary(ggplot2)\nlibrary(plotly)\nlibrary(gridExtra)\nlibrary(broom.mixed)\nlibrary(knitr)\nlibrary(grid)\nlibrary(ggpubr)\n\nlibrary(dplyr)\nlibrary(broom.mixed)\nlibrary(effectsize)\nlibrary(corrplot)\ncompute_enderstofighi <- function(data, sub, outcome, expect, ses, run) {\n  maindata <- data %>%\n    group_by(!!sym(sub)) %>%\n    mutate(OUTCOME = as.numeric(!!sym(outcome))) %>%\n    mutate(EXPECT = as.numeric(!!sym(expect))) %>%\n    mutate(OUTCOME_cm = mean(OUTCOME, na.rm = TRUE)) %>%\n    mutate(OUTCOME_demean = OUTCOME - OUTCOME_cm) %>%\n    mutate(EXPECT_cm = mean(EXPECT, na.rm = TRUE)) %>%\n    mutate(EXPECT_demean = EXPECT - EXPECT_cm) %>%\n    #mutate(OUTCOME_zscore = as.numeric(scale(OUTCOME, center = TRUE, scale = TRUE)[, 1])) %>%\n    #mutate(EXPECT_zscore = as.numeric(scale(EXPECT, center = TRUE, scale = TRUE)[, 1])) \n    mutate(OUTCOME_zscore = (OUTCOME - mean(OUTCOME, na.rm = TRUE))/sd(OUTCOME, na.rm = TRUE)) %>% #as.numeric(scale(OUTCOME, center = TRUE, scale = TRUE)[, 1])) %>%\n    mutate(EXPECT_zscore = (EXPECT - mean(EXPECT, na.rm = TRUE))/sd(EXPECT, na.rm = TRUE)) #as.numeric(scale(EXPECT, center = TRUE, scale = TRUE)[, 1])) \n  \n  data_p2 <- maindata %>%\n    arrange(!!sym(sub)) %>%\n    group_by(!!sym(sub)) %>%\n    mutate(trial_index = row_number())\n  \n  data_a3 <- data_p2 %>%\n    group_by(!!sym(sub), !!sym(ses), !!sym(run)) %>%\n    mutate(trial_index = row_number(!!sym(run)))\n  \n  data_a3lag <- data_a3 %>%\n    group_by(!!sym(sub), !!sym(ses), !!sym(run)) %>%\n    mutate(lag.OUTCOME_demean = dplyr::lag(OUTCOME_demean, n = 1, default = NA))\n  \n  # Create Subjectwise Mean, centered in relation to the group mean\n  data_a3cmc <- data_a3lag %>%\n    ungroup %>%\n    mutate(EXPECT_cmc = EXPECT_cm - mean(EXPECT_cm, na.rm=TRUE)) %>%\n    mutate(OUTCOME_cmc = OUTCOME_cm - mean(OUTCOME_cm, na.rm=TRUE))\n  \n  \n  # Remove NA values ___________________________________________________________\n  data_centered_NA <- data_a3cmc %>% \n    filter(!is.na(OUTCOME)) %>% # Remove NA values\n    filter(!is.na(EXPECT))\n\n  return(data_centered_NA)\n  \n}"},{"path":"cueeffects.html","id":"display-distribution-of-data","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"9.0.1 display distribution of data","text":"Let’s look distribution data. X axis: Y axis:Summary:","code":"\nhead(df.PVC_center)## # A tibble: 6 × 33\n##   src_subject_id session_id param_run_num param_task_name event02_expect_angle\n##            <int>      <int>         <int> <chr>                          <dbl>\n## 1              2          1             1 pain                            5.53\n## 2              2          1             1 pain                           18.9 \n## 3              2          1             1 pain                          103.  \n## 4              2          1             1 pain                           81.2 \n## 5              2          1             1 pain                           97.2 \n## 6              2          1             1 pain                          117.  \n## # ℹ 28 more variables: param_cue_type <chr>, param_stimulus_type <chr>,\n## #   event04_actual_angle <dbl>, trial_index <int>, trial_count_sub <int>,\n## #   trial_ind <dbl>, sub <chr>, ses <chr>, run <chr>, runtype <chr>,\n## #   task <chr>, trial_sub <int>, trial <chr>, cuetype <chr>,\n## #   stimintensity <chr>, DEPc <chr>, DEP <chr>, OUTCOME <dbl>, EXPECT <dbl>,\n## #   OUTCOME_cm <dbl>, OUTCOME_demean <dbl>, EXPECT_cm <dbl>,\n## #   EXPECT_demean <dbl>, OUTCOME_zscore <dbl>, EXPECT_zscore <dbl>, …\n#colnames(df.PVC_center)"},{"path":"cueeffects.html","id":"function-compute-cue-effects","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"9.1 function: compute cue effects","text":"","code":"\n#' Compute Cue Effect\n#'\n#' This function processes a dataframe to compute the cue effect. It involves \n#' subsetting and filtering the data, summarizing conditions, calculating \n#' difference scores, and calculating group-wise contrast. The function also \n#' allows renaming of the resultant columns.\n#'\n#' @param df A dataframe containing the relevant data.\n#' @param dv The name of the dependent variable in the dataframe.\n#' @param new_col_name The new name for the column that will be created as a result \n#'        of computing the cue effect.\n#' @return A dataframe with the computed cue effect, sorted by task, with a new \n#'         column for the cue effect and its standard deviation, renamed as specified.\n#' @import dplyr\n#' @import tidyr\n#' @import Rmisc\n#' @export\n#' @examples\n#' # Assuming df is a dataframe with the necessary structure and \"OUTCOME\" is your dependent variable:\n#' result <- compute_cueeffect(df, \"OUTCOME\", \"new_cue_effect\")\ncompute_cueeffect <- function(df, dv, new_col_name) {\n  library(dplyr)\n  library(tidyr)\n  library(Rmisc)\n\n  # 1) Subset and filter data __________________________________________________\n  df$task <- factor(df$task)\n  sub_diff <- subset(df, select = c(\"sub\", \"ses\", \"run\", \"task\", \"stimintensity\", \"cuetype\", dv))\n  sub_diff_NA <- sub_diff %>% filter(!is.na(dv))\n\n  # 2) Summarize each condition and spread out columns _________________________\n  subjectwise <- meanSummary(sub_diff_NA, c(\"sub\", \"ses\", \"run\", \"task\", \"cuetype\", \"stimintensity\"), dv)\n  mean_outcome <- subjectwise[1:(length(subjectwise) - 1)]\n  wide <- mean_outcome %>% tidyr::spread(cuetype, mean_per_sub)\n\n  # 3) Calculate difference score ______________________________________________\n  wide$diff <- wide$`cuetype-high` - wide$`cuetype-low`\n  subjectwise_diff <- meanSummary(wide, c(\"sub\", \"task\"), \"diff\")\n  subjectwise_NA <- subjectwise_diff %>% filter(!is.na(sd))\n\n  # 4) Calculate group wise contrast ___________________________________________\n  groupwise_diff <- summarySEwithin(data = subjectwise_NA, measurevar = \"mean_per_sub\", withinvars = \"task\", idvar = \"sub\")\n  sd_col <- paste0(new_col_name, \"_sd\")\n  # sort data based on task and rename _________________________________________\n  sorted_df <- subjectwise_diff %>%\n    arrange(task) %>%\n    rename(!!new_col_name := mean_per_sub, \n           !!sd_col := sd\n           )\n\n  return(sorted_df)\n}"},{"path":"cueeffects.html","id":"function-compute-stim-effects","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"9.2 function: compute stim effects","text":"","code":"\n#' Compute Stimulus Effect\n#'\n#' This function calculates the stimulus effect based on the provided dataframe.\n#' It filters the data, computes summary statistics, calculates difference scores,\n#' and optionally renames the resulting columns.\n#'\n#' @param df Dataframe containing the data to be analyzed.\n#' @param dv Name of the dependent variable column in `df`.\n#' @param new_col_name New column name for the renamed mean_per_sub column.\n#' @return A dataframe with the computed stimulus effect, sorted by task, \n#'         and with columns optionally renamed.\n#' @import dplyr\n#' @import tidyr\n#' @import Rmisc\n#' @export\n#' @examples\n#' # Assuming df is your dataframe and \"OUTCOME\" is your dependent variable:\n#' result <- compute_stimeffect(df, \"OUTCOME\", \"new_mean_outcome\")\ncompute_stimeffect <- function(df, dv, new_col_name) {\n  # 1) Subset and filter data __________________________________________________\n  df$task <- factor(df$task)\n  sub_diff <- subset(df, select = c(\"sub\", \"ses\", \"run\", \"task\", \"stimintensity\", \"cuetype\", dv))\n  sub_diff_NA <- sub_diff %>% filter(!is.na(dv))\n\n \n  # 2) Summarize each condition and spread out columns _________________________\n  subjectwise <- meanSummary(sub_diff_NA, c(\"sub\", \"ses\", \"run\", \"task\", \"cuetype\", \"stimintensity\"), dv)\n  mean_outcome <- subjectwise[1:(length(subjectwise) - 1)]\n  wide <- mean_outcome %>% tidyr::spread(stimintensity, mean_per_sub)\n\n  # 3) Calculate difference score ______________________________________________\n  wide$diff <- wide$high - wide$low\n  subjectwise_diff <- meanSummary(wide, c(\"sub\", \"task\"), \"diff\")\n  subjectwise_NA <- subjectwise_diff %>% filter(!is.na(sd))\n  # \n  # # 4) Calculate group wise contrast _________________________________________\n  groupwise_diff <- Rmisc::summarySEwithin(data = subjectwise_NA, \n                                           measurevar = \"mean_per_sub\", \n                                           withinvars = \"task\", \n                                           idvar = \"sub\")\n  # \n  sd_col <- paste0(new_col_name, \"_sd\")\n  # sort data based on task and rename _________________________________________\n  sorted_df <- subjectwise_diff %>%\n    arrange(task) %>%\n    rename(!!new_col_name := mean_per_sub, \n           !!sd_col := sd\n           )\n  return(sorted_df)\n} "},{"path":"cueeffects.html","id":"compute-the-cue-and-stim-effects-for-further-analysis","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"compute the cue and stim effects for further analysis","text":"\n## Illustration plot labels\nvariable names indicate {effect}_{raw/z}_{ratings}effect illustrates contrasts compute, cue effects stim effects\ncue: high cue vs. low cue average values per participant\nstim: high stim vs. low stim average values per participant\ncue: high cue vs. low cue average values per participantstim: high stim vs. low stim average values per participantraw/z:\nraw: use raw behavioral ratings (per participant) compute aforementioned effects, \nz: use z scores (per participant) compute aforementioned effects\nraw: use raw behavioral ratings (per participant) compute aforementioned effects, orz: use z scores (per participant) compute aforementioned effectsratings\noutcome: outcome ratings\nexpect: expectation ratings\noutcome: outcome ratingsexpect: expectation ratingsexample: cue_raw_outcome illustrate cue effect, calculated based raw outcome ratings. average outcome rating difference high vs. low cues, calculated per participant.","code":"\n# calculate cue & stim effects per participant and rename column _______________\ncue_raw_outcome <- compute_cueeffect(df.PVC_center, dv = \"OUTCOME\", new_col_name = \"cue_raw_outcome\")## \n## Attaching package: 'tidyr'## The following objects are masked from 'package:Matrix':\n## \n##     expand, pack, unpack## Loading required package: lattice## \n## Attaching package: 'Rmisc'## The following objects are masked from 'package:cueR':\n## \n##     normDataWithin, summarySE\ncue_z_outcome <- compute_cueeffect(df.PVC_center, dv = \"OUTCOME_zscore\", new_col_name = \"cue_z_outcome\")\ncue_raw_expect <- compute_cueeffect(df.PVC_center, dv = \"EXPECT\", new_col_name = \"cue_raw_expect\")\ncue_z_expect <- compute_cueeffect(df.PVC_center, dv = \"EXPECT_zscore\", new_col_name = \"cue_z_expect\")\n\nrawstim_outcome <- compute_stimeffect(df.PVC_center, dv = \"OUTCOME\", new_col_name = \"stim_raw_outcome\")\nzstim_outcome <- compute_stimeffect(df.PVC_center, dv = \"OUTCOME_zscore\", new_col_name = \"stim_z_outcome\")\nrawstim_expect <- compute_stimeffect(df.PVC_center, dv = \"EXPECT\", new_col_name = \"stim_raw_expect\")\nzstim_expect <- compute_stimeffect(df.PVC_center, dv = \"EXPECT_zscore\", new_col_name = \"stim_z_expect\")\n\n\n# Merging all dataframes _______________________________________________________\nmerged_df <- cue_raw_outcome %>%\n  full_join(cue_z_outcome, by = c(\"sub\", \"task\")) %>%\n  full_join(cue_raw_expect, by = c(\"sub\", \"task\")) %>%\n  full_join(cue_z_expect, by = c(\"sub\", \"task\")) %>%\n  full_join(rawstim_outcome, by = c(\"sub\", \"task\")) %>%\n  full_join(zstim_outcome, by = c(\"sub\", \"task\")) %>%\n  full_join(rawstim_expect, by = c(\"sub\", \"task\")) %>%\n  full_join(zstim_expect, by = c(\"sub\", \"task\"))\n\n# calculate cue vs stim effect ratio ___________________________________________\nmerged_df$cuestim_raw_outcome <- merged_df$cue_raw_outcome/merged_df$stim_raw_outcome\nmerged_df$cuestim_raw_outcome_reg <- (merged_df$cue_raw_outcome+1)/(merged_df$stim_raw_outcome+1)\n\nmerged_df$cuestim_z_outcome <- merged_df$cue_z_outcome/merged_df$stim_z_outcome\nmerged_df$cuestim_z_outcome_reg <- (merged_df$cue_z_outcome+1)/(merged_df$stim_z_outcome+1)\n\n\nwrite.csv(merged_df, file.path(main_dir, \"data\", \"hlm\", \"cue_stim_effects_scaling.csv\"), row.names = FALSE)\n# Let's check what the cue & stim effects look like ____________________________\nhead(merged_df)##        sub      task cue_raw_outcome cue_raw_outcome_sd cue_z_outcome\n## 1 sub-0002 cognitive        4.540887           6.343282    0.12174487\n## 2 sub-0003 cognitive        7.636581          17.103371    0.47159597\n## 3 sub-0004 cognitive        1.627529           7.632712    0.07069328\n## 4 sub-0005 cognitive       13.130997          41.442596    0.33303376\n## 5 sub-0006 cognitive        5.148439          28.946650    0.15567303\n## 6 sub-0007 cognitive       14.076683           9.627143    0.63495614\n##   cue_z_outcome_sd cue_raw_expect cue_raw_expect_sd cue_z_expect\n## 1        0.1700686       23.90350          18.73398    0.5963963\n## 2        1.0562162       30.15502          25.17697    1.2605728\n## 3        0.3315341       33.77405          25.34289    1.0873435\n## 4        1.0510842       41.78567          37.36012    1.2517185\n## 5        0.8752581       30.56264          19.98909    1.0611074\n## 6        0.4342510       29.32456          11.57591    1.1869398\n##   cue_z_expect_sd stim_raw_outcome stim_raw_outcome_sd stim_z_outcome\n## 1       0.4674160        4.4896815           10.040412     0.12037201\n## 2       1.0524748        4.0612018           11.029078     0.25079893\n## 3       0.8159054        0.9329999            6.238765     0.04052574\n## 4       1.1191483        4.6718609           29.829606     0.11848966\n## 5       0.6940032       15.8650585           28.858031     0.47971082\n## 6       0.4685462       12.5187276           11.450963     0.56468155\n##   stim_z_outcome_sd stim_raw_expect stim_raw_expect_sd stim_z_expect\n## 1         0.2691916       -3.343426          20.107224   -0.08341906\n## 2         0.6810991       -4.285159           7.409842   -0.17913285\n## 3         0.2709867       -1.031139           9.824031   -0.03319716\n## 4         0.7565508       -2.959005           8.839276   -0.08863904\n## 5         0.8725786        7.058330          18.466885    0.24505886\n## 6         0.5165180       -4.460202           9.261081   -0.18053095\n##   stim_z_expect_sd cuestim_raw_outcome cuestim_raw_outcome_reg\n## 1        0.5016787           1.0114051               1.0093276\n## 2        0.3097542           1.8803747               1.7064289\n## 3        0.3162812           1.7444044               1.3593012\n## 4        0.2647866           2.8106567               2.4914216\n## 5        0.6411536           0.3245143               0.3645667\n## 6        0.3748512           1.1244500               1.1152442\n##   cuestim_z_outcome cuestim_z_outcome_reg\n## 1         1.0114051             1.0012254\n## 2         1.8803747             1.1765248\n## 3         1.7444044             1.0289926\n## 4         2.8106567             1.1918159\n## 5         0.3245143             0.7810128\n## 6         1.1244500             1.0449130\npain.df <-merged_df[merged_df$task == 'pain', ]\ncor(pain.df$cue_raw_outcome, pain.df$cue_z_outcome, use = \"complete.obs\")## [1] 0.9155303\n# Reshape the dataframe to a long format _______________________________________\npain.long_df <- pivot_longer(pain.df, \n                        cols = c(\"cue_raw_outcome\", \"cue_z_outcome\", \n                                 \"cue_raw_expect\", \"cue_z_expect\", \n                                 \"stim_raw_outcome\", \"stim_z_outcome\", \n                                 \"stim_raw_expect\", \"stim_z_expect\",\n                                 \n                                 \"cuestim_raw_outcome\", \"cuestim_raw_outcome_reg\",\n                                 \"cuestim_z_outcome\", \"cuestim_z_outcome_reg\"\n                                 ), \n                        names_to = \"variable\", \n                        values_to = \"value\")\n\npain_heatmap <- pain.long_df[, c(\"sub\", \"variable\", \"value\")]\n# Create the heatmap ___________________________________________________________\nggplotly(ggplot(pain_heatmap, aes(x = variable, y = sub, fill = value)) +\n  geom_tile() +\n  scale_fill_gradient(low = \"blue\", high = \"red\") +\n  #facet_grid(rows = vars(sub)) +\n  theme_minimal() +\n  coord_fixed(ratio = .1) +\n  labs(x = \"Variable\", y = \"Subject\", fill = \"Value\") +\n   theme(axis.text.x = element_text(angle = 45, hjust = 1),\n        axis.text.y = element_text(angle = 45, vjust = 1)))\n# correlation matrix ___________________________________________________________\npain.df.subset <- pain.df[, c(\"cue_raw_outcome\", \"cue_z_outcome\", \n                                 \"cue_raw_expect\", \"cue_z_expect\", \n                                 \"stim_raw_outcome\", \"stim_z_outcome\", \n                                 \"stim_raw_expect\", \"stim_z_expect\",\n                                 \n                                 \"cuestim_raw_outcome\", \"cuestim_raw_outcome_reg\",\n                                 \"cuestim_z_outcome\", \"cuestim_z_outcome_reg\")]\n                                 #\"cuestim_raw_expect\", \"cuestim_raw_expect_reg\",\n                                 #\"cuestim_z_expect\", \"cuestim_z_expect_reg\")]\n\nM <- cor(as.matrix(pain.df.subset), use =\"complete.obs\")\n#round(M, 2)\ntestRes = cor.mtest(M, conf.level = 0.95)\ncorrplot(M, p.mat = testRes$p, method = 'color', diag = TRUE, \n         sig.level = c( 0.05), pch.cex = 0.7,\n         tl.cex = 0.6,\n         insig = 'label_sig', pch.col = 'grey20')#, order = 'AOE')"},{"path":"cueeffects.html","id":"summary","chapter":"9 beh :: Different scaling methods ~ Cue effects","heading":"9.3 Summary:","text":"Given cue-effect scores subject measures, Z scored version raw scored version variance structure across participants.Taking look correlation matrix,know raw z scores effects significant correlation.\nknow raw z scores effects significant correlation.Validation:\nexpectation ratings function cue (“cue_raw_expect”) highly correlated outcome ratings function cue (“cue_raw_outcome”).\n\nStimulus effects correlation cue effects (.e. significant corerlation “stim_raw_outcome” & “cue_raw_outcome” ).\n\nexpectation ratings function cue (“cue_raw_expect”) highly correlated outcome ratings function cue (“cue_raw_outcome”).\nexpectation ratings function cue (“cue_raw_expect”) highly correlated outcome ratings function cue (“cue_raw_outcome”).Stimulus effects correlation cue effects (.e. significant corerlation “stim_raw_outcome” & “cue_raw_outcome” ).\nStimulus effects correlation cue effects (.e. significant corerlation “stim_raw_outcome” & “cue_raw_outcome” ).Question: cue effect proportional stim effect (“cuestim_raw_outcome”) correlated stim effect, cue effect. ?\nQuestion: cue effect proportional stim effect (“cuestim_raw_outcome”) correlated stim effect, cue effect. ?","code":"\nrand_norms_100 <- rnorm(n = 100, mean = 100, sd = 25)\nrand_norms_100.Z <- (rand_norms_100-mean(rand_norms_100))/sd(rand_norms_100)\ncor(rand_norms_100, rand_norms_100.Z)## [1] 1\nrand_norms_100.demean <- (rand_norms_100-mean(rand_norms_100))\ncor(rand_norms_100, rand_norms_100.demean)## [1] 1"},{"path":"demean-per-sub-n1.html","id":"demean-per-sub-n1","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","text":"","code":""},{"path":"demean-per-sub-n1.html","id":"what-is-the-purpose-of-this-notebook-6","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"What is the purpose of this notebook?","text":", model outcome ratings function cue, stimulus intensity, expectation ratings, N-1 outcome rating.opposed notebook 14, demean ratings within participantsAs opposed notebook 14, demean ratings within participantsIn words, calculate average within subjects subtract ratingsIn words, calculate average within subjects subtract ratingsMain model: lmer(outcome_rating ~ cue * stim * expectation rating + N-1 outcomerating)Main model: lmer(outcome_rating ~ cue * stim * expectation rating + N-1 outcomerating)Main question: constitutes reported outcome rating?Main question: constitutes reported outcome rating?Sub questions:\nlinear relationship expectation rating outcome rating, differ function cue?\nN-1 outcome rating affect current expectation ratings?\nLater, effect different across tasks similar?\nSub questions:linear relationship expectation rating outcome rating, differ function cue?N-1 outcome rating affect current expectation ratings?Later, effect different across tasks similar?IV:\nstim (high / med / low)\ncue (high / low)\nexpectation rating (continuous)\nN-1 outcome rating (continuous)IV:\nstim (high / med / low)\ncue (high / low)\nexpectation rating (continuous)\nN-1 outcome rating (continuous)DV: outcome ratingDV: outcome rating","code":""},{"path":"demean-per-sub-n1.html","id":"todos","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"TODOs","text":"Standardized coefficientsSlope difference? Intercept difference? ( cue expectation rating)Correct range (within participant)\nhypothesis:Larger expectation leads prediction errorIndividual differences ratingsOutcome experience, based behavioral experience\nbrain maps associated component.load data combine participant data","code":"##  event02_expect_RT event04_actual_RT event02_expect_angle event04_actual_angle\n##  Min.   :0.6504    Min.   :0.0168    Min.   :  0.00       Min.   :  0.00      \n##  1st Qu.:1.6341    1st Qu.:1.9197    1st Qu.: 30.18       1st Qu.: 38.80      \n##  Median :2.0517    Median :2.3510    Median : 58.56       Median : 60.77      \n##  Mean   :2.1397    Mean   :2.4005    Mean   : 62.94       Mean   : 66.33      \n##  3rd Qu.:2.5678    3rd Qu.:2.8512    3rd Qu.: 90.00       3rd Qu.: 88.38      \n##  Max.   :3.9912    Max.   :3.9930    Max.   :180.00       Max.   :180.00      \n##  NA's   :661       NA's   :638       NA's   :661          NA's   :641"},{"path":"demean-per-sub-n1.html","id":"groupby-subject-and-average","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.0.1 groupby subject and average","text":"","code":""},{"path":"demean-per-sub-n1.html","id":"linear-model-0508","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.1 linear model 0508","text":"","code":"\n# model.factorize_demean = lmer(demean_outcome~ CUE_high_gt_low*stim_factor*demean_expect +EXPECT_cmc+ lag.demean_outcome+(1|src_subject_id), data = pvc)\n# summary(model.factorize_demean)\n\nmodel.factorize_demean = lmer(demean_outcome~ CUE_high_gt_low*stim_con_linear*demean_expect +\n                                CUE_high_gt_low*stim_con_quad*demean_expect +\n                                EXPECT_cmc + (1|src_subject_id), data = pvc)## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient## boundary (singular) fit: see help('isSingular')\nsummary(model.factorize_demean)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ CUE_high_gt_low * stim_con_linear * demean_expect +  \n##     CUE_high_gt_low * stim_con_quad * demean_expect + EXPECT_cmc +  \n##     (1 | src_subject_id)\n##    Data: pvc\n## \n## REML criterion at convergence: 43246.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.3122 -0.5823 -0.0037  0.5936  5.1434 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept)   0.0     0.00   \n##  Residual                   370.8    19.26   \n## Number of obs: 4939, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                                 Estimate Std. Error         df\n## (Intercept)                                   -7.897e-01  3.461e-01  4.927e+03\n## CUE_high_gt_low                               -3.686e+00  6.922e-01  4.927e+03\n## stim_con_linear                                3.010e+01  8.554e-01  4.927e+03\n## demean_expect                                  3.306e-01  1.219e-02  4.927e+03\n## stim_con_quad                                  2.020e+00  7.350e-01  4.927e+03\n## CUE_high_gt_low:stim_con_linear                1.066e+00  1.711e+00  4.927e+03\n## CUE_high_gt_low:demean_expect                 -4.084e-02  2.438e-02  4.927e+03\n## stim_con_linear:demean_expect                  1.195e-02  2.993e-02  4.927e+03\n## CUE_high_gt_low:stim_con_quad                 -3.891e+00  1.470e+00  4.927e+03\n## demean_expect:stim_con_quad                    3.232e-03  2.606e-02  4.927e+03\n## CUE_high_gt_low:stim_con_linear:demean_expect  2.105e-01  5.986e-02  4.927e+03\n## CUE_high_gt_low:demean_expect:stim_con_quad   -3.814e-02  5.212e-02  4.927e+03\n##                                               t value Pr(>|t|)    \n## (Intercept)                                    -2.281 0.022563 *  \n## CUE_high_gt_low                                -5.324 1.06e-07 ***\n## stim_con_linear                                35.190  < 2e-16 ***\n## demean_expect                                  27.118  < 2e-16 ***\n## stim_con_quad                                   2.748 0.006013 ** \n## CUE_high_gt_low:stim_con_linear                 0.623 0.533311    \n## CUE_high_gt_low:demean_expect                  -1.675 0.094003 .  \n## stim_con_linear:demean_expect                   0.399 0.689707    \n## CUE_high_gt_low:stim_con_quad                  -2.647 0.008141 ** \n## demean_expect:stim_con_quad                     0.124 0.901304    \n## CUE_high_gt_low:stim_con_linear:demean_expect   3.516 0.000442 ***\n## CUE_high_gt_low:demean_expect:stim_con_quad    -0.732 0.464328    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                        (Intr) CUE_h__ stm_cn_l dmn_xp stm_cn_q\n## CUE_hgh_gt_             0.092                                 \n## stim_cn_lnr            -0.030 -0.028                          \n## demean_xpct            -0.100 -0.609   0.016                  \n## stim_con_qd            -0.026 -0.028   0.022    0.015         \n## CUE_hgh_gt_lw:stm_cn_l -0.028 -0.030   0.110    0.023  0.020  \n## CUE_hgh__:_            -0.609 -0.100   0.023    0.102  0.019  \n## stm_cn_ln:_             0.016  0.024  -0.109   -0.040 -0.012  \n## CUE_hgh_gt_lw:stm_cn_q -0.028 -0.026   0.020    0.019  0.074  \n## dmn_xpct:__             0.014  0.018  -0.011   -0.007 -0.091  \n## CUE___:__:_             0.024  0.016  -0.615   -0.001 -0.017  \n## CUE___:_:__             0.018  0.014  -0.017    0.001 -0.603  \n##                        CUE_hgh_gt_lw:stm_cn_l CUE_h__:_ st__:_\n## CUE_hgh_gt_                                                   \n## stim_cn_lnr                                                   \n## demean_xpct                                                   \n## stim_con_qd                                                   \n## CUE_hgh_gt_lw:stm_cn_l                                        \n## CUE_hgh__:_             0.016                                 \n## stm_cn_ln:_            -0.615                 -0.001          \n## CUE_hgh_gt_lw:stm_cn_q  0.022                  0.015    -0.017\n## dmn_xpct:__            -0.017                  0.001     0.028\n## CUE___:__:_            -0.109                 -0.040     0.101\n## CUE___:_:__            -0.011                 -0.007     0.001\n##                        CUE_hgh_gt_lw:stm_cn_q dm_:__ CUE___:__:\n## CUE_hgh_gt_                                                    \n## stim_cn_lnr                                                    \n## demean_xpct                                                    \n## stim_con_qd                                                    \n## CUE_hgh_gt_lw:stm_cn_l                                         \n## CUE_hgh__:_                                                    \n## stm_cn_ln:_                                                    \n## CUE_hgh_gt_lw:stm_cn_q                                         \n## dmn_xpct:__            -0.603                                  \n## CUE___:__:_            -0.012                  0.001           \n## CUE___:_:__            -0.091                  0.104  0.028    \n## fit warnings:\n## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')"},{"path":"demean-per-sub-n1.html","id":"linear-model","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.2 linear model","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ CUE_high_gt_low * stim_factor * demean_expect +  \n##     lag.demean_outcome + (1 | src_subject_id)\n##    Data: pvc\n## \n## REML criterion at convergence: 42884.2\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.6746 -0.5825  0.0064  0.5976  5.5568 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept)   0.0     0.00   \n##  Residual                   344.1    18.55   \n## Number of obs: 4939, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                                     Estimate Std. Error\n## (Intercept)                                        1.359e+01  5.718e-01\n## CUE_high_gt_low                                    2.734e-01  1.149e+00\n## stim_factorlow_stim                               -3.049e+01  8.242e-01\n## stim_factormed_stim                               -1.279e+01  8.054e-01\n## demean_expect                                      2.713e-01  2.015e-02\n## lag.demean_outcome                                 2.177e-01  1.111e-02\n## CUE_high_gt_low:stim_factorlow_stim               -4.737e-01  1.648e+00\n## CUE_high_gt_low:stim_factormed_stim               -5.026e+00  1.611e+00\n## CUE_high_gt_low:demean_expect                      1.048e-01  3.980e-02\n## stim_factorlow_stim:demean_expect                 -1.928e-02  2.883e-02\n## stim_factormed_stim:demean_expect                 -1.078e-03  2.838e-02\n## CUE_high_gt_low:stim_factorlow_stim:demean_expect -2.491e-01  5.770e-02\n## CUE_high_gt_low:stim_factormed_stim:demean_expect -1.639e-01  5.677e-02\n##                                                           df t value Pr(>|t|)\n## (Intercept)                                        4.926e+03  23.761  < 2e-16\n## CUE_high_gt_low                                    4.926e+03   0.238  0.81188\n## stim_factorlow_stim                                4.926e+03 -36.993  < 2e-16\n## stim_factormed_stim                                4.926e+03 -15.879  < 2e-16\n## demean_expect                                      4.926e+03  13.461  < 2e-16\n## lag.demean_outcome                                 4.926e+03  19.585  < 2e-16\n## CUE_high_gt_low:stim_factorlow_stim                4.926e+03  -0.287  0.77384\n## CUE_high_gt_low:stim_factormed_stim                4.926e+03  -3.120  0.00182\n## CUE_high_gt_low:demean_expect                      4.926e+03   2.633  0.00849\n## stim_factorlow_stim:demean_expect                  4.926e+03  -0.669  0.50373\n## stim_factormed_stim:demean_expect                  4.926e+03  -0.038  0.96969\n## CUE_high_gt_low:stim_factorlow_stim:demean_expect  4.926e+03  -4.317 1.61e-05\n## CUE_high_gt_low:stim_factormed_stim:demean_expect  4.926e+03  -2.888  0.00390\n##                                                      \n## (Intercept)                                       ***\n## CUE_high_gt_low                                      \n## stim_factorlow_stim                               ***\n## stim_factormed_stim                               ***\n## demean_expect                                     ***\n## lag.demean_outcome                                ***\n## CUE_high_gt_low:stim_factorlow_stim                  \n## CUE_high_gt_low:stim_factormed_stim               ** \n## CUE_high_gt_low:demean_expect                     ** \n## stim_factorlow_stim:demean_expect                    \n## stim_factormed_stim:demean_expect                    \n## CUE_high_gt_low:stim_factorlow_stim:demean_expect ***\n## CUE_high_gt_low:stim_factormed_stim:demean_expect ** \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')"},{"path":"demean-per-sub-n1.html","id":"q.-are-those-overestimating-for-high-cues-also-underestimators-for-low-cues","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.3 Q. Are those overestimating for high cues also underestimators for low cues?","text":"y axis: outcome rating\nx axis: high cuedistance 1:1 line\nUsing ODR, can test whether different cues lead different distances identity line","code":"## boundary (singular) fit: see help('isSingular')## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 42138.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.0513 -0.6728 -0.1352  0.5460  6.0466 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev. Corr\n##  src_subject_id (Intercept)  66.398   8.148       \n##                 cue_namelow   2.915   1.707   1.00\n##  Residual                   280.906  16.760       \n## Number of obs: 4939, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)  23.1557     0.8577 108.8675  26.998   <2e-16 ***\n## cue_namelow   0.7289     0.5052 478.1364   1.443     0.15    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## cue_namelow 0.032 \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')"},{"path":"demean-per-sub-n1.html","id":"todo-can-you-test-if-the-slopes-are-the-same-that-might-tell-us-something-about-whether-expectancies-translate-into-outcomes-with-the-same-efficacy-across-all-three-tasks.","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.4 TODO: Can you test if the slopes are the same? That might tell us something about whether, expectancies translate into outcomes with the same efficacy across all three tasks.","text":"","code":"## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 42138.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -3.0513 -0.6728 -0.1352  0.5460  6.0466 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev. Corr\n##  src_subject_id (Intercept)  66.398   8.148       \n##                 cue_namelow   2.915   1.707   1.00\n##  Residual                   280.906  16.760       \n## Number of obs: 4939, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##             Estimate Std. Error       df t value Pr(>|t|)    \n## (Intercept)  23.1557     0.8577 108.8675  26.998   <2e-16 ***\n## cue_namelow   0.7289     0.5052 478.1364   1.443     0.15    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## cue_namelow 0.032 \n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Warning: Removed 1 rows containing non-finite values (`stat_half_ydensity()`).## Warning: Removed 1 rows containing non-finite values (`stat_boxplot()`).## Warning: Removed 1 row containing missing values (`geom_line()`).## Warning: Removed 1 rows containing missing values (`geom_point()`).## Warning: Removed 1 rows containing non-finite values (`stat_half_ydensity()`).## Warning: Removed 1 rows containing non-finite values (`stat_boxplot()`).## Warning: Removed 1 row containing missing values (`geom_line()`).## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"demean-per-sub-n1.html","id":"pain-run-collapsed-across-stimulus-intensity","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.5 pain run, collapsed across stimulus intensity","text":"","code":""},{"path":"demean-per-sub-n1.html","id":"vicarious-6","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.6 vicarious","text":"","code":"\nmodel.factorize_demean = lmer(demean_outcome~ CUE_high_gt_low*stim_con_linear*demean_expect +\n                                CUE_high_gt_low*stim_con_quad*demean_expect +\n                                EXPECT_cmc + (1|src_subject_id), data = pvc)## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient## boundary (singular) fit: see help('isSingular')\nsummary(model.factorize_demean)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ CUE_high_gt_low * stim_con_linear * demean_expect +  \n##     CUE_high_gt_low * stim_con_quad * demean_expect + EXPECT_cmc +  \n##     (1 | src_subject_id)\n##    Data: pvc\n## \n## REML criterion at convergence: 45954.8\n## \n## Scaled residuals: \n##    Min     1Q Median     3Q    Max \n## -3.475 -0.602 -0.138  0.446  5.630 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept)   0.0     0.00   \n##  Residual                   469.7    21.67   \n## Number of obs: 5111, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                                 Estimate Std. Error         df\n## (Intercept)                                      0.21603    0.44918 5099.00000\n## CUE_high_gt_low                                  1.24687    0.89837 5099.00000\n## stim_con_linear                                 23.90084    1.10386 5099.00000\n## demean_expect                                    0.19711    0.01918 5099.00000\n## stim_con_quad                                   -4.72799    0.95934 5099.00000\n## CUE_high_gt_low:stim_con_linear                  6.38339    2.20771 5099.00000\n## CUE_high_gt_low:demean_expect                   -0.02451    0.03835 5099.00000\n## stim_con_linear:demean_expect                    0.03147    0.04753 5099.00000\n## CUE_high_gt_low:stim_con_quad                   -3.13553    1.91869 5099.00000\n## demean_expect:stim_con_quad                      0.01270    0.04060 5099.00000\n## CUE_high_gt_low:stim_con_linear:demean_expect    0.37387    0.09506 5099.00000\n## CUE_high_gt_low:demean_expect:stim_con_quad     -0.07222    0.08120 5099.00000\n##                                               t value Pr(>|t|)    \n## (Intercept)                                     0.481  0.63058    \n## CUE_high_gt_low                                 1.388  0.16522    \n## stim_con_linear                                21.652  < 2e-16 ***\n## demean_expect                                  10.278  < 2e-16 ***\n## stim_con_quad                                  -4.928 8.55e-07 ***\n## CUE_high_gt_low:stim_con_linear                 2.891  0.00385 ** \n## CUE_high_gt_low:demean_expect                  -0.639  0.52280    \n## stim_con_linear:demean_expect                   0.662  0.50793    \n## CUE_high_gt_low:stim_con_quad                  -1.634  0.10228    \n## demean_expect:stim_con_quad                     0.313  0.75449    \n## CUE_high_gt_low:stim_con_linear:demean_expect   3.933 8.50e-05 ***\n## CUE_high_gt_low:demean_expect:stim_con_quad    -0.889  0.37386    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                        (Intr) CUE_h__ stm_cn_l dmn_xp stm_cn_q\n## CUE_hgh_gt_            -0.193                                 \n## stim_cn_lnr             0.007 -0.063                          \n## demean_xpct             0.258 -0.736   0.052                  \n## stim_con_qd            -0.009  0.026  -0.005   -0.009         \n## CUE_hgh_gt_lw:stm_cn_l -0.063  0.007  -0.210   -0.015  0.045  \n## CUE_hgh__:_            -0.736  0.258  -0.015   -0.336  0.019  \n## stm_cn_ln:_             0.052 -0.015   0.261    0.019 -0.037  \n## CUE_hgh_gt_lw:stm_cn_q  0.026 -0.009   0.045    0.019 -0.176  \n## dmn_xpct:__            -0.010  0.019  -0.037   -0.034  0.255  \n## CUE___:__:_            -0.015  0.052  -0.738   -0.023  0.011  \n## CUE___:_:__             0.019 -0.010   0.011   -0.034 -0.734  \n##                        CUE_hgh_gt_lw:stm_cn_l CUE_h__:_ st__:_\n## CUE_hgh_gt_                                                   \n## stim_cn_lnr                                                   \n## demean_xpct                                                   \n## stim_con_qd                                                   \n## CUE_hgh_gt_lw:stm_cn_l                                        \n## CUE_hgh__:_             0.052                                 \n## stm_cn_ln:_            -0.738                 -0.023          \n## CUE_hgh_gt_lw:stm_cn_q -0.005                 -0.009     0.011\n## dmn_xpct:__             0.011                 -0.034    -0.014\n## CUE___:__:_             0.261                  0.019    -0.305\n## CUE___:_:__            -0.037                 -0.034     0.017\n##                        CUE_hgh_gt_lw:stm_cn_q dm_:__ CUE___:__:\n## CUE_hgh_gt_                                                    \n## stim_cn_lnr                                                    \n## demean_xpct                                                    \n## stim_con_qd                                                    \n## CUE_hgh_gt_lw:stm_cn_l                                         \n## CUE_hgh__:_                                                    \n## stm_cn_ln:_                                                    \n## CUE_hgh_gt_lw:stm_cn_q                                         \n## dmn_xpct:__            -0.734                                  \n## CUE___:__:_            -0.037                  0.017           \n## CUE___:_:__             0.255                 -0.369 -0.014    \n## fit warnings:\n## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 42592.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.8941 -0.6915 -0.1167  0.5386  5.2943 \n## \n## Random effects:\n##  Groups         Name        Variance  Std.Dev. Corr \n##  src_subject_id (Intercept) 4.520e+01  6.72295      \n##                 cue_namelow 9.234e-03  0.09609 -1.00\n##  Residual                   2.325e+02 15.24653      \n## Number of obs: 5111, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   20.3562     0.7177  111.0539  28.364   <2e-16 ***\n## cue_namelow   -0.2391     0.4276 4783.4156  -0.559    0.576    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## cue_namelow -0.319\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill## Warning: Removed 1 rows containing non-finite values (`stat_half_ydensity()`).## Warning: Removed 1 rows containing non-finite values (`stat_boxplot()`).## Warning: Removed 1 row containing missing values (`geom_line()`).## Warning: Removed 1 rows containing missing values (`geom_point()`).## Warning: Removed 1 rows containing non-finite values (`stat_half_ydensity()`).## Warning: Removed 1 rows containing non-finite values (`stat_boxplot()`).## Warning: Removed 1 row containing missing values (`geom_line()`).## Warning: Removed 1 rows containing missing values (`geom_point()`)."},{"path":"demean-per-sub-n1.html","id":"cognitive-6","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.7 cognitive","text":"","code":""},{"path":"demean-per-sub-n1.html","id":"linear-model-0508-1","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.8 linear model 0508","text":"","code":"\n# model.factorize_demean = lmer(demean_outcome~ CUE_high_gt_low*stim_factor*demean_expect +EXPECT_cmc+ lag.demean_outcome+(1|src_subject_id), data = pvc)\n# summary(model.factorize_demean)\n\nmodel.factorize_demean = lmer(demean_outcome~ CUE_high_gt_low*stim_con_linear*demean_expect +\n                                CUE_high_gt_low*stim_con_quad*demean_expect +\n                                EXPECT_cmc + (1|src_subject_id), data = pvc)## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient## boundary (singular) fit: see help('isSingular')\nsummary(model.factorize_demean)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ CUE_high_gt_low * stim_con_linear * demean_expect +  \n##     CUE_high_gt_low * stim_con_quad * demean_expect + EXPECT_cmc +  \n##     (1 | src_subject_id)\n##    Data: pvc\n## \n## REML criterion at convergence: 43807.3\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.1272 -0.6113 -0.1388  0.4529  7.1545 \n## \n## Random effects:\n##  Groups         Name        Variance Std.Dev.\n##  src_subject_id (Intercept)   0.0     0.00   \n##  Residual                   347.4    18.64   \n## Number of obs: 5041, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##                                                 Estimate Std. Error         df\n## (Intercept)                                    6.017e-02  3.729e-01  5.029e+03\n## CUE_high_gt_low                               -1.515e-02  7.458e-01  5.029e+03\n## stim_con_linear                                8.066e+00  8.920e-01  5.029e+03\n## demean_expect                                  2.374e-01  1.662e-02  5.029e+03\n## stim_con_quad                                  3.181e+00  8.174e-01  5.029e+03\n## CUE_high_gt_low:stim_con_linear                2.562e+00  1.784e+00  5.029e+03\n## CUE_high_gt_low:demean_expect                 -1.247e-02  3.324e-02  5.029e+03\n## stim_con_linear:demean_expect                  1.995e-02  3.894e-02  5.029e+03\n## CUE_high_gt_low:stim_con_quad                 -2.304e+00  1.635e+00  5.029e+03\n## demean_expect:stim_con_quad                    1.089e-03  3.710e-02  5.029e+03\n## CUE_high_gt_low:stim_con_linear:demean_expect  1.105e-01  7.788e-02  5.029e+03\n## CUE_high_gt_low:demean_expect:stim_con_quad   -9.891e-03  7.419e-02  5.029e+03\n##                                               t value Pr(>|t|)    \n## (Intercept)                                     0.161 0.871825    \n## CUE_high_gt_low                                -0.020 0.983797    \n## stim_con_linear                                 9.044  < 2e-16 ***\n## demean_expect                                  14.286  < 2e-16 ***\n## stim_con_quad                                   3.892 0.000101 ***\n## CUE_high_gt_low:stim_con_linear                 1.436 0.151056    \n## CUE_high_gt_low:demean_expect                  -0.375 0.707610    \n## stim_con_linear:demean_expect                   0.512 0.608536    \n## CUE_high_gt_low:stim_con_quad                  -1.410 0.158728    \n## demean_expect:stim_con_quad                     0.029 0.976584    \n## CUE_high_gt_low:stim_con_linear:demean_expect   1.419 0.156016    \n## CUE_high_gt_low:demean_expect:stim_con_quad    -0.133 0.893945    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                        (Intr) CUE_h__ stm_cn_l dmn_xp stm_cn_q\n## CUE_hgh_gt_            -0.165                                 \n## stim_cn_lnr            -0.006 -0.029                          \n## demean_xpct             0.225 -0.709   0.015                  \n## stim_con_qd             0.064 -0.036   0.004    0.050         \n## CUE_hgh_gt_lw:stm_cn_l -0.029 -0.006  -0.146   -0.005  0.020  \n## CUE_hgh__:_            -0.709  0.225  -0.005   -0.307 -0.079  \n## stm_cn_ln:_             0.015 -0.005   0.202    0.006 -0.011  \n## CUE_hgh_gt_lw:stm_cn_q -0.036  0.064   0.020   -0.079 -0.183  \n## dmn_xpct:__             0.049 -0.077  -0.010    0.115  0.245  \n## CUE___:__:_            -0.005  0.015  -0.698    0.014  0.003  \n## CUE___:_:__            -0.077  0.049   0.003   -0.078 -0.719  \n##                        CUE_hgh_gt_lw:stm_cn_l CUE_h__:_ st__:_\n## CUE_hgh_gt_                                                   \n## stim_cn_lnr                                                   \n## demean_xpct                                                   \n## stim_con_qd                                                   \n## CUE_hgh_gt_lw:stm_cn_l                                        \n## CUE_hgh__:_             0.015                                 \n## stm_cn_ln:_            -0.698                  0.014          \n## CUE_hgh_gt_lw:stm_cn_q  0.004                  0.050     0.003\n## dmn_xpct:__             0.003                 -0.078    -0.004\n## CUE___:__:_             0.202                  0.006    -0.273\n## CUE___:_:__            -0.010                  0.115    -0.009\n##                        CUE_hgh_gt_lw:stm_cn_q dm_:__ CUE___:__:\n## CUE_hgh_gt_                                                    \n## stim_cn_lnr                                                    \n## demean_xpct                                                    \n## stim_con_qd                                                    \n## CUE_hgh_gt_lw:stm_cn_l                                         \n## CUE_hgh__:_                                                    \n## stm_cn_ln:_                                                    \n## CUE_hgh_gt_lw:stm_cn_q                                         \n## dmn_xpct:__            -0.719                                  \n## CUE___:__:_            -0.011                 -0.009           \n## CUE___:_:__             0.245                 -0.336 -0.004    \n## fit warnings:\n## fixed-effect model matrix is rank deficient so dropping 1 column / coefficient\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')\n# model.factorize_C= lmer(demean_outcome~ CUE_high_gt_low*stim_factor*demean_expect +EXPECT_cmc+ (1|src_subject_id), data = pvc)\n# summary(model.factorize_demean)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: \n## as.formula(reformulate(c(iv, sprintf(\"(%s|%s)\", iv, subject_keyword)),  \n##     response = dv))\n##    Data: df\n## \n## REML criterion at convergence: 40996.5\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -2.4634 -0.6567 -0.1325  0.5028  6.6541 \n## \n## Random effects:\n##  Groups         Name        Variance  Std.Dev. Corr \n##  src_subject_id (Intercept)  43.94315  6.6290       \n##                 cue_namelow   0.03079  0.1755  -1.00\n##  Residual                   189.43985 13.7637       \n## Number of obs: 5041, groups:  src_subject_id, 110\n## \n## Fixed effects:\n##              Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)   18.8604     0.6959  107.7330  27.101   <2e-16 ***\n## cue_namelow   -0.5008     0.3891 4141.2072  -1.287    0.198    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## cue_namelow -0.319\n## optimizer (nloptwrap) convergence code: 0 (OK)\n## boundary (singular) fit: see help('isSingular')## Warning in geom_line(data = subjectwise, aes(group = .data[[subject]], x =\n## as.numeric(as.factor(.data[[iv]])) - : Ignoring unknown aesthetics: fill\n# library(plotly)\n# plot_ly(x=subjectwise_naomit_2dv$param_cue_type, y=subjectwise_naomit_2dv$DV1_mean_per_sub, z=subjectwise_naomit_2dv$DV2_mean_per_sub, type=\"scatter3d\", mode=\"markers\", color=subjectwise_naomit_2dv$param_cue_type)"},{"path":"demean-per-sub-n1.html","id":"across-tasks-pvc-is-the-slope-for-highvslow-cue-the-sametor-question","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.9 across tasks (PVC), is the slope for (highvslow cue) the same?Tor question","text":"Adding “participant” random effects leads singular boundary issue. reason random effects variance across participants.add task random effect, words, allowing differences across tasks, get following results:expectancy-outcome relationship differs across tasks, taskname_lin:demean_expect, t(14130) = 4.317, p < .001expectancy-outcome relationship differs across cue tasks, “tasknamelin:CUE_high_gt_low:demean_expect”, t(14130) = 5.758, p < .001\ntaskname_lin:CUE_high_gt_low -3.790e+00 1.448e+00 1.413e+04 -2.618 0.00886 \n++ taskname_lin:demean_expect 9.854e-02 2.283e-02 1.413e+04 4.317 1.59e-05 *\nCUE_high_gt_low:demean_expect -9.077e-02 1.987e-02 1.413e+04 -4.569 4.95e-06 **\nCUEhigh_gt_low:taskname_quad 5.352e+00 1.334e+00 1.413e+04 4.012 6.04e-05 \ndemean_expect:taskname_quad -1.596e-01 2.253e-02 1.413e+04 -7.084 1.47e-12 _\ntaskname_lin:CUE_high_gt_low:demean_expect 2.629e-01 4.565e-02 1.413e+04 5.758 8.67e-09 _**\nCUE_high_gt_low:demean_expect:taskname_quad -1.021e-01 4.505e-02 1.413e+04 -2.266 0.02348 *add sub random effect ignore singular. Plus, remove cue contrast…expectancy-outcome relationship differs across tasks, factor(param_task_name):demean_expect, F(2, 14136) = 54.765, p < .001","code":"\np <- df_load_beh(datadir, taskname = 'pain', subject_varkey = subject_varkey, iv = iv, exclude = exclude)\nv <- df_load_beh(datadir, taskname = 'vicarious', subject_varkey = subject_varkey, iv = iv, exclude = exclude)\nc <- df_load_beh(datadir, taskname = 'cognitive', subject_varkey = subject_varkey, iv = iv, exclude = exclude)\np_sub <- p[, c(\"param_task_name\", \"param_cue_type\", \"src_subject_id\",\"session_id\", \"param_run_num\", \"param_stimulus_type\", \"event04_actual_angle\", \"event02_expect_angle\")]\nv_sub <- v[, c(\"param_task_name\", \"param_cue_type\", \"src_subject_id\",\"session_id\", \"param_run_num\", \"param_stimulus_type\", \"event04_actual_angle\", \"event02_expect_angle\")]\nc_sub <- c[, c(\"param_task_name\", \"param_cue_type\", \"src_subject_id\", \"session_id\", \"param_run_num\",\"param_stimulus_type\", \"event04_actual_angle\", \"event02_expect_angle\")]\npvc_sub <- do.call(\"rbind\", list(p_sub, v_sub, c_sub))\nmaindata <- pvc_sub %>%\ngroup_by(src_subject_id) %>%\nmutate(event04_actual_angle = as.numeric(event04_actual_angle)) %>%\nmutate(event02_expect_angle = as.numeric(event02_expect_angle)) %>%\nmutate(avg_outcome = mean(event04_actual_angle, na.rm = TRUE)) %>%\nmutate(demean_outcome = event04_actual_angle - avg_outcome) %>%\nmutate(avg_expect = mean(event02_expect_angle, na.rm = TRUE)) %>%\nmutate(demean_expect = event02_expect_angle - avg_expect)\n\ndata_p2= maindata %>%\n  arrange(src_subject_id ) %>%\n  group_by(src_subject_id) %>%\n  mutate(trial_index = row_number())\ndata_a3 <- data_p2 %>%\n  group_by(src_subject_id, session_id, param_run_num) %>%\n  mutate(trial_index = row_number(param_run_num))\n\ndata_a3lag <-\n    data_a3 %>%\n    group_by(src_subject_id, session_id, param_run_num) %>%\n    mutate(lag.demean_outcome = dplyr::lag(demean_outcome, n = 1, default = NA))\ndata_a3lag_omit <- data_a3lag[complete.cases(data_a3lag$lag.demean_outcome),]\n\ndf <- data_a3lag_omit\npvc_sub <- simple_contrasts_beh(df)## Warning: Unknown or uninitialised column: `stim_con_linear`.## Warning: Unknown or uninitialised column: `stim_con_quad`.## Warning: Unknown or uninitialised column: `CUE_high_gt_low`.## Warning: Unknown or uninitialised column: `cue_name`.\n# contrast code 1 linear\npvc_sub$taskname_lin[pvc_sub$param_task_name == \"pain\"] <-  0.5## Warning: Unknown or uninitialised column: `taskname_lin`.\npvc_sub$taskname_lin[pvc_sub$param_task_name == \"vicarious\"] <-  0\npvc_sub$taskname_lin[pvc_sub$param_task_name == \"cognitive\"] <-  -0.5\n\n# contrast code 2 quadratic\npvc_sub$taskname_quad[pvc_sub$param_task_name == \"pain\"] <-  -0.33## Warning: Unknown or uninitialised column: `taskname_quad`.\npvc_sub$taskname_quad[pvc_sub$param_task_name == \"vicarious\"] <-  0.66\npvc_sub$taskname_quad[pvc_sub$param_task_name == \"cognitive\"] <-  -0.33\n\npvc_sub$sub = factor(pvc_sub$src_subject_id)\n# model_test = lm(pvc_sub$demean_outcome~ pvc_sub$demean_expect)\nmodel_task = lmer(demean_outcome~ taskname_lin*CUE_high_gt_low*demean_expect + taskname_quad*CUE_high_gt_low*demean_expect +  (1 | sub), data = pvc_sub)\nmodel_wotask = lmer(demean_outcome~ CUE_high_gt_low*demean_expect +(1 | sub), data = pvc_sub)## boundary (singular) fit: see help('isSingular')\nsummary(model_task)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ taskname_lin * CUE_high_gt_low * demean_expect +  \n##     taskname_quad * CUE_high_gt_low * demean_expect + (1 | sub)\n##    Data: pvc_sub\n## \n## REML criterion at convergence: 139399.8\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.5727 -0.6342 -0.1226  0.5514  5.3674 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept)   0.1232  0.351  \n##  Residual             600.5633 24.506  \n## Number of obs: 15091, groups:  sub, 111\n## \n## Fixed effects:\n##                                               Estimate Std. Error         df\n## (Intercept)                                 -3.019e-01  2.951e-01  2.477e+02\n## taskname_lin                                 1.801e+01  6.935e-01  1.447e+04\n## CUE_high_gt_low                             -9.551e+00  5.853e-01  1.369e+04\n## demean_expect                                4.696e-01  9.457e-03  1.156e+04\n## taskname_quad                               -1.082e+01  6.465e-01  1.482e+04\n## taskname_lin:CUE_high_gt_low                -4.377e+00  1.388e+00  7.418e+03\n## taskname_lin:demean_expect                   1.007e-01  2.163e-02  1.758e+03\n## CUE_high_gt_low:demean_expect               -8.861e-02  1.894e-02  4.064e+03\n## CUE_high_gt_low:taskname_quad                5.276e+00  1.294e+00  1.247e+04\n## demean_expect:taskname_quad                 -1.730e-01  2.157e-02  8.290e+03\n## taskname_lin:CUE_high_gt_low:demean_expect   2.685e-01  4.314e-02  1.405e+04\n## CUE_high_gt_low:demean_expect:taskname_quad -1.063e-01  4.310e-02  1.484e+04\n##                                             t value Pr(>|t|)    \n## (Intercept)                                  -1.023  0.30723    \n## taskname_lin                                 25.973  < 2e-16 ***\n## CUE_high_gt_low                             -16.319  < 2e-16 ***\n## demean_expect                                49.657  < 2e-16 ***\n## taskname_quad                               -16.741  < 2e-16 ***\n## taskname_lin:CUE_high_gt_low                 -3.153  0.00162 ** \n## taskname_lin:demean_expect                    4.655 3.48e-06 ***\n## CUE_high_gt_low:demean_expect                -4.679 2.98e-06 ***\n## CUE_high_gt_low:taskname_quad                 4.078 4.56e-05 ***\n## demean_expect:taskname_quad                  -8.022 1.18e-15 ***\n## taskname_lin:CUE_high_gt_low:demean_expect    6.224 4.98e-10 ***\n## CUE_high_gt_low:demean_expect:taskname_quad  -2.466  0.01368 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                  (Intr) tsknm_l CUE_h__ dmn_xp tsknm_q ts_:CUE___ tsk_:_\n## taskname_ln       0.005                                                 \n## CUE_hgh_gt_      -0.188  0.369                                          \n## demean_xpct       0.224 -0.360  -0.620                                  \n## taskname_qd       0.087 -0.004  -0.299   0.280                          \n## tsk_:CUE___       0.368  0.032   0.004   0.141 -0.253                   \n## tsknm_ln:d_      -0.374  0.022   0.146  -0.281  0.256  -0.574           \n## CUE_hgh_gt_lw:d_ -0.616  0.140   0.225  -0.197 -0.142  -0.362      0.151\n## CUE_hgh_gt_lw:t_ -0.298 -0.253   0.088  -0.143 -0.382  -0.005     -0.097\n## dmn_xpct:t_       0.271  0.240  -0.139   0.177  0.391  -0.091      0.183\n## t_:CUE___:_       0.145 -0.572  -0.375   0.150 -0.099   0.023     -0.120\n## CUE_h__:_:_      -0.137 -0.093   0.272  -0.123 -0.659   0.239     -0.099\n##                  CUE_hgh_gt_lw:d_ CUE_hgh_gt_lw:t_ dmn_:_ t_:CUE___:\n## taskname_ln                                                         \n## CUE_hgh_gt_                                                         \n## demean_xpct                                                         \n## taskname_qd                                                         \n## tsk_:CUE___                                                         \n## tsknm_ln:d_                                                         \n## CUE_hgh_gt_lw:d_                                                    \n## CUE_hgh_gt_lw:t_  0.281                                             \n## dmn_xpct:t_      -0.123           -0.660                            \n## t_:CUE___:_      -0.280            0.256           -0.099           \n## CUE_h__:_:_       0.176            0.391           -0.255  0.185\nanova(model_task)## Type III Analysis of Variance Table with Satterthwaite's method\n##                                              Sum Sq Mean Sq NumDF   DenDF\n## taskname_lin                                 405142  405142     1 14470.1\n## CUE_high_gt_low                              159941  159941     1 13687.7\n## demean_expect                               1480894 1480894     1 11560.3\n## taskname_quad                                168310  168310     1 14820.0\n## taskname_lin:CUE_high_gt_low                   5970    5970     1  7418.2\n## taskname_lin:demean_expect                    13016   13016     1  1757.8\n## CUE_high_gt_low:demean_expect                 13146   13146     1  4063.7\n## CUE_high_gt_low:taskname_quad                  9989    9989     1 12473.3\n## demean_expect:taskname_quad                   38647   38647     1  8289.7\n## taskname_lin:CUE_high_gt_low:demean_expect    23266   23266     1 14053.9\n## CUE_high_gt_low:demean_expect:taskname_quad    3652    3652     1 14843.7\n##                                               F value    Pr(>F)    \n## taskname_lin                                 674.6035 < 2.2e-16 ***\n## CUE_high_gt_low                              266.3187 < 2.2e-16 ***\n## demean_expect                               2465.8423 < 2.2e-16 ***\n## taskname_quad                                280.2539 < 2.2e-16 ***\n## taskname_lin:CUE_high_gt_low                   9.9409  0.001623 ** \n## taskname_lin:demean_expect                    21.6722 3.477e-06 ***\n## CUE_high_gt_low:demean_expect                 21.8899 2.981e-06 ***\n## CUE_high_gt_low:taskname_quad                 16.6325 4.565e-05 ***\n## demean_expect:taskname_quad                   64.3519 1.183e-15 ***\n## taskname_lin:CUE_high_gt_low:demean_expect    38.7401 4.979e-10 ***\n## CUE_high_gt_low:demean_expect:taskname_quad    6.0802  0.013681 *  \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(model_wotask, model_task)## refitting model(s) with ML (instead of REML)## Data: pvc_sub\n## Models:\n## model_wotask: demean_outcome ~ CUE_high_gt_low * demean_expect + (1 | sub)\n## model_task: demean_outcome ~ taskname_lin * CUE_high_gt_low * demean_expect + taskname_quad * CUE_high_gt_low * demean_expect + (1 | sub)\n##              npar    AIC    BIC logLik deviance  Chisq Df Pr(>Chisq)    \n## model_wotask    6 141394 141440 -70691   141382                         \n## model_task     14 139396 139502 -69684   139368 2014.4  8  < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n# summary(model_test)\nmodel_task1 = lmer(demean_outcome~ factor(param_task_name)*demean_expect  +  (1 | sub), data = pvc_sub)\nmodel_wotask1 = lmer(demean_outcome~ demean_expect+ (1 | sub), data = pvc_sub)## boundary (singular) fit: see help('isSingular')\nsummary(model_task1)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: demean_outcome ~ factor(param_task_name) * demean_expect + (1 |  \n##     sub)\n##    Data: pvc_sub\n## \n## REML criterion at convergence: 139725.4\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -4.2535 -0.6307 -0.1171  0.5506  5.2255 \n## \n## Random effects:\n##  Groups   Name        Variance  Std.Dev.\n##  sub      (Intercept)   0.03748  0.1936 \n##  Residual             613.93050 24.7776 \n## Number of obs: 15091, groups:  sub, 111\n## \n## Fixed effects:\n##                                                  Estimate Std. Error         df\n## (Intercept)                                    -8.081e+00  3.662e-01  8.076e+02\n## factor(param_task_name)pain                     2.304e+01  5.519e-01  1.465e+04\n## factor(param_task_name)vicarious               -1.434e+00  5.227e-01  1.508e+04\n## demean_expect                                   3.702e-01  1.369e-02  9.687e+03\n## factor(param_task_name)pain:demean_expect       1.136e-01  1.724e-02  3.523e+03\n## factor(param_task_name)vicarious:demean_expect -8.418e-02  1.912e-02  1.410e+04\n##                                                t value Pr(>|t|)    \n## (Intercept)                                    -22.067  < 2e-16 ***\n## factor(param_task_name)pain                     41.742  < 2e-16 ***\n## factor(param_task_name)vicarious                -2.744  0.00607 ** \n## demean_expect                                   27.033  < 2e-16 ***\n## factor(param_task_name)pain:demean_expect        6.589 5.07e-11 ***\n## factor(param_task_name)vicarious:demean_expect  -4.403 1.08e-05 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                     (Intr) fctr(prm_tsk_nm)p fctr(prm_tsk_nm)v dmn_xp\n## fctr(prm_tsk_nm)p   -0.662                                           \n## fctr(prm_tsk_nm)v   -0.699  0.464                                    \n## demean_xpct          0.298 -0.198            -0.209                  \n## fctr(prm_tsk_nm)p:_ -0.237 -0.080             0.166            -0.794\n## fctr(prm_tsk_nm)v:_ -0.214  0.142             0.336            -0.716\n##                     fctr(prm_tsk_nm)p:_\n## fctr(prm_tsk_nm)p                      \n## fctr(prm_tsk_nm)v                      \n## demean_xpct                            \n## fctr(prm_tsk_nm)p:_                    \n## fctr(prm_tsk_nm)v:_  0.569\nanova(model_task1)## Type III Analysis of Variance Table with Satterthwaite's method\n##                                        Sum Sq Mean Sq NumDF   DenDF  F value\n## factor(param_task_name)               1451299  725650     2 14837.1 1181.974\n## demean_expect                         1679513 1679513     1 14954.2 2735.674\n## factor(param_task_name):demean_expect   86935   43467     2  5101.8   70.802\n##                                          Pr(>F)    \n## factor(param_task_name)               < 2.2e-16 ***\n## demean_expect                         < 2.2e-16 ***\n## factor(param_task_name):demean_expect < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(model_wotask1)## Type III Analysis of Variance Table with Satterthwaite's method\n##                Sum Sq Mean Sq NumDF DenDF F value    Pr(>F)    \n## demean_expect 4785248 4785248     1 15089  6564.5 < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nanova(model_wotask1, model_task1)## refitting model(s) with ML (instead of REML)## Data: pvc_sub\n## Models:\n## model_wotask1: demean_outcome ~ demean_expect + (1 | sub)\n## model_task1: demean_outcome ~ factor(param_task_name) * demean_expect + (1 | sub)\n##               npar    AIC    BIC logLik deviance  Chisq Df Pr(>Chisq)    \n## model_wotask1    4 142306 142337 -71149   142298                         \n## model_task1      8 139720 139781 -69852   139704 2594.7  4  < 2.2e-16 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\nlibrary(emmeans)\n# emm1 = emmeans(model_task, specs = pairwise ~ stimintensity:task)\n# emm1"},{"path":"demean-per-sub-n1.html","id":"alireza-congruent-incongruent-pe","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.10 Alireza congruent incongruent (PE)","text":"categorize based congruent, incongruentsplit dataframe","code":"\n# %% -------------------------------------------------------------------------\n#  load pain data\n# ----------------------------------------------------------------------------\n\nmain_dir = dirname(dirname(getwd()))\ndatadir = file.path(main_dir, 'data', 'beh', 'beh02_preproc')\nsubject_varkey <- \"src_subject_id\"\niv <- \"param_cue_type\"\nxlab <- \"\"\ntaskname <- \"pain\"\nylab <- \"ratings (degree)\"\nsubject <- \"subject\"\nexclude <- \"sub-0001|sub-0003|sub-0004|sub-0005|sub-0025|sub-0999\"\ndata = data.frame()\ndata <- df_load_beh(datadir, taskname = taskname, subject_varkey = subject_varkey, iv = iv, exclude = exclude)\ndata$event03_RT <- data$event03_stimulusC_reseponseonset - data$event03_stimulus_displayonset\n\ndir.create(analysis_dir, showWarnings = FALSE, recursive = TRUE)\n\nmaindata <- data %>%\ngroup_by(src_subject_id) %>%\nmutate(event04_actual_angle = as.numeric(event04_actual_angle)) %>%\nmutate(event02_expect_angle = as.numeric(event02_expect_angle)) %>%\nmutate(avg_outcome = mean(event04_actual_angle, na.rm = TRUE)) %>%\nmutate(demean_outcome = event04_actual_angle - avg_outcome) %>%\nmutate(avg_expect = mean(event02_expect_angle, na.rm = TRUE)) %>%\nmutate(demean_expect = event02_expect_angle - avg_expect)\n\n# %% -------------------------------------------------------------------------\n#  0. argparse\n# ----------------------------------------------------------------------------\n\ndata_p2= maindata %>%\n  arrange(src_subject_id ) %>%\n  group_by(src_subject_id) %>%\n  mutate(trial_index = row_number())\ndata_a3 <- data_p2 %>%\n  group_by(src_subject_id, session_id, param_run_num) %>%\n  mutate(trial_index = row_number(param_run_num))\n\ndata_a3lag <-\n    data_a3 %>%\n    group_by(src_subject_id, session_id, param_run_num) %>%\n    mutate(lag.demean_outcome = dplyr::lag(demean_outcome, n = 1, default = NA))\ndata_a3lag <- data_a3lag %>%\n  mutate(EXPECT_cmc = avg_expect - mean(avg_expect))\ndata_a3lag_omit <- data_a3lag[complete.cases(data_a3lag$lag.demean_outcome),]\n\ndf <- data_a3lag_omit\npvc <- simple_contrasts_beh(df)## Warning: Unknown or uninitialised column: `stim_con_linear`.## Warning: Unknown or uninitialised column: `stim_con_quad`.## Warning: Unknown or uninitialised column: `CUE_high_gt_low`.## Warning: Unknown or uninitialised column: `cue_name`."},{"path":"demean-per-sub-n1.html","id":"archive-this-cell","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.10.1 archive this cell","text":"","code":"\n# previous_congruency <- is_congruent(param_cue_type[previous_index], param_stimulus_type[previous_index])\n\nis_congruent <- function(cue, stim) {\n  if (cue == \"low_cue\" && stim == \"low_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"low_cue\" && stim == \"high_stim\") {\n    return(\"incongruent\")\n  } else if (cue == \"high_cue\" && stim == \"low_stim\") {\n    return(\"incongruent\")\n  } else if (cue == \"high_cue\" && stim == \"high_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"high_cue\" && stim == \"med_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"low_cue\" && stim == \"med_stim\") {\n    return(\"incongruent\")\n  } else {\n    return(NA)  # Handle other cases\n  }\n}\npvc.pain <- pvc[pvc$param_task_name == \"pain\",]\npvc.pain$pe <- pvc.pain$demean_outcome - pvc.pain$demean_expect\n\n# define congruency patterns\npvc.pain$congruency[(pvc.pain$param_cue_type == \"low_cue\") & (pvc.pain$pe < 0)] <- \"congruent\"## Warning: Unknown or uninitialised column: `congruency`.\npvc.pain$congruency[(pvc.pain$param_cue_type == \"high_cue\") & (pvc.pain$pe > 0)] <- \"congruent\"\n\npvc.pain$congruency[(pvc.pain$param_cue_type == \"low_cue\") & (pvc.pain$pe > 0)] <- \"incongruent\"\npvc.pain$congruency[(pvc.pain$param_cue_type == \"high_cue\") & (pvc.pain$pe < 0)] <- \"incongruent\"\n\n\nlibrary(dplyr)\n\n# definition: current cue level (high, low).\n# Find N-1 trial where cue level matches current trial\n# populate that as \"congruency_vector\"\npvc.pain <- pvc.pain %>%\n  # group by subject, session, run\n  group_by(src_subject_id, session_id, param_run_num) %>%\n  mutate(\n    congruency_status = {\n      congruency_vector <- vector(\"character\", n())\n\n      for (i in 1:n()) {\n        # get the current cue. find the trial indices with the same cue level as current trial `matching_indices`\n        current_cue <- param_cue_type[i]\n        # identifying all existing trials that matches the current cue level\n        matching_indices <- which(param_cue_type[1:(i - 1)] == current_cue)\n        if (length(matching_indices) > 0) {\n          # from matching_indices, grab the largest number.\n          # this maximum number would be the most recent N-1 cue trial, based on matching_indices\n          previous_index <- max(matching_indices)\n          # populate congruency_vector with previous N-1 trial's congruency value. (NOTE: must match current cue level)\n          congruency_vector[i] <- congruency[previous_index]\n        } else {\n          congruency_vector[i] <- NA\n        }\n      }\n      congruency_vector\n    }\n  )\n  # ungroup() %>%\n  # mutate(\n  #   congruency_status = ifelse(is.na(congruency_status), pvc$congruency, congruency_status)\n  # )"},{"path":"demean-per-sub-n1.html","id":"alireza-congruent-incongruent-incorrect","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.11 Alireza congruent incongruent (incorrect)","text":"categorize based congruent, incongruentsplit dataframe","code":""},{"path":"demean-per-sub-n1.html","id":"archive-this-cell-1","chapter":"10 beh :: outcome_demean ~ cue * stim * expect * n-1outcome","heading":"10.11.1 archive this cell","text":"","code":"\n# previous_congruency <- is_congruent(param_cue_type[previous_index], param_stimulus_type[previous_index])\n\nis_congruent <- function(cue, stim) {\n  if (cue == \"low_cue\" && stim == \"low_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"low_cue\" && stim == \"high_stim\") {\n    return(\"incongruent\")\n  } else if (cue == \"high_cue\" && stim == \"low_stim\") {\n    return(\"incongruent\")\n  } else if (cue == \"high_cue\" && stim == \"high_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"high_cue\" && stim == \"med_stim\") {\n    return(\"congruent\")\n  } else if (cue == \"low_cue\" && stim == \"med_stim\") {\n    return(\"incongruent\")\n  } else {\n    return(NA)  # Handle other cases\n  }\n}\npvc <- pvc[pvc$param_task_name == \"pain\",]\n\n# define congruency patterns\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"low_cue\") & (pvc.pain$param_stimulus_type == \"low_stim\")] <- \"congruent\"## Warning: Unknown or uninitialised column: `congruency2`.\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"high_cue\") & (pvc.pain$param_stimulus_type == \"low_stim\")] <- \"incongruent\"\n\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"low_cue\") & (pvc.pain$param_stimulus_type == \"med_stim\")] <- \"incongruent\"\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"high_cue\") & (pvc.pain$param_stimulus_type == \"med_stim\")] <- \"congruent\"\n\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"low_cue\") & (pvc.pain$param_stimulus_type == \"high_stim\")] <- \"incongruent\"\npvc.pain$congruency2[(pvc.pain$param_cue_type == \"high_cue\") & (pvc.pain$param_stimulus_type == \"high_stim\")] <- \"congruent\"\n\n\nlibrary(dplyr)\n\n# definition: current cue level (high, low).\n# Find N-1 trial where cue level matches current trial\n# populate that as \"congruency_vector\"\npvc.pain <- pvc.pain %>%\n  # group by subject, session, run\n  group_by(src_subject_id, session_id, param_run_num) %>%\n  mutate(\n    congruency_status2 = {\n      congruency_vector <- vector(\"character\", n())\n\n      for (i in 1:n()) {\n        # get the current cue. find the trial indices with the same cue level as current trial `matching_indices`\n        current_cue <- param_cue_type[i]\n        # identifying all existing trials that matches the current cue level\n        matching_indices <- which(param_cue_type[1:(i - 1)] == current_cue)\n        if (length(matching_indices) > 0) {\n          # from matching_indices, grab the largest number.\n          # this maximum number would be the most recent N-1 cue trial, based on matching_indices\n          previous_index <- max(matching_indices)\n          # populate congruency_vector with previous N-1 trial's congruency value. (NOTE: must match current cue level)\n          congruency_vector[i] <- congruency2[previous_index]\n        } else {\n          congruency_vector[i] <- NA\n        }\n      }\n      congruency_vector\n    }\n  )\n  # ungroup() %>%\n  # mutate(\n  #   congruency_status2 = ifelse(is.na(congruency_status2), pvc$congruency2, congruency_status2)\n  # )"},{"path":"mediation.html","id":"mediation","chapter":"11 beh :: Mediation","heading":"11 beh :: Mediation","text":"","code":""},{"path":"mediation.html","id":"what-is-the-purpose-of-this-notebook-7","chapter":"11 beh :: Mediation","heading":"What is the purpose of this notebook?","text":", model outcome ratings function cue, stimulus intensity, expectation ratings, N-1 outcome rating.opposed notebook 15, want check demeaning process runs opposed subjects.opposed notebook 15, want check demeaning process runs opposed subjects.words, calculate average within run subtract ratingsIn words, calculate average within run subtract ratingsMain model: lmer(outcome_rating ~ cue * stim * expectation rating + N-1 outcomerating)Main model: lmer(outcome_rating ~ cue * stim * expectation rating + N-1 outcomerating)Main question: constitutes reported outcome rating?Main question: constitutes reported outcome rating?Sub questions:\nlinear relationship expectation rating outcome rating, differ function cue?\nN-1 outcome rating affect current expectation ratings?\nLater, effect different across tasks similar?\nSub questions:linear relationship expectation rating outcome rating, differ function cue?N-1 outcome rating affect current expectation ratings?Later, effect different across tasks similar?IV:\nstim (high / med / low)\ncue (high / low)\nexpectation rating (continuous)\nN-1 outcome rating (continuous)IV:\nstim (high / med / low)\ncue (high / low)\nexpectation rating (continuous)\nN-1 outcome rating (continuous)DV: outcome ratingDV: outcome rating","code":""},{"path":"mediation.html","id":"some-thoughts-todos-1","chapter":"11 beh :: Mediation","heading":"Some thoughts, TODOs","text":"Standardized coefficientsSlope difference? Intercept difference? ( cue expectantion rating)Correct range (within participant)\nhypothesis:Larger expectation leads prediction errorIndividual differences ratingsOutcome experience, based behavioral experience\nbrain maps associated component.load data combine participant data","code":"##  event02_expect_RT event04_actual_RT event02_expect_angle event04_actual_angle\n##  Min.   :0.6504    Min.   :0.0171    Min.   :  0.00       Min.   :  0.00      \n##  1st Qu.:1.6200    1st Qu.:1.9188    1st Qu.: 29.55       1st Qu.: 37.83      \n##  Median :2.0511    Median :2.3511    Median : 57.58       Median : 60.49      \n##  Mean   :2.1337    Mean   :2.4011    Mean   : 61.88       Mean   : 65.47      \n##  3rd Qu.:2.5589    3rd Qu.:2.8514    3rd Qu.: 88.61       3rd Qu.: 87.70      \n##  Max.   :3.9912    Max.   :3.9930    Max.   :180.00       Max.   :180.00      \n##  NA's   :651       NA's   :638       NA's   :651          NA's   :641"},{"path":"mediation.html","id":"covariance-matrix-ratings-and-rt","chapter":"11 beh :: Mediation","heading":"Covariance matrix: ratings and RT","text":"","code":""},{"path":"mediation.html","id":"covariance-matrix-fixation-durations-e.g.-isis","chapter":"11 beh :: Mediation","heading":"Covariance matrix: fixation durations (e.g. ISIs)","text":"","code":""},{"path":"mediation.html","id":"mediation-1","chapter":"11 beh :: Mediation","heading":"11.1 mediation","text":"","code":"\npsych::mediate(event04_actual_angle ~ CUE_high_gt_low*stim_con_linear+ event02_expect_angle + lag.04outcomeangle, data = pvc, n.iter = 1000) %>% print(short = FALSE)## \n## Mediation/Moderation Analysis \n## Call: psych::mediate(y = event04_actual_angle ~ CUE_high_gt_low * stim_con_linear + \n##     event02_expect_angle + lag.04outcomeangle, data = pvc, n.iter = 1000)\n## \n## The DV (Y) was  event04_actual_angle . The IV (X) was  CUE_high_gt_low stim_con_linear event02_expect_angle lag.04outcomeangle CUE_high_gt_low*stim_con_linear . The mediating variable(s) =  .Call: psych::mediate(y = event04_actual_angle ~ CUE_high_gt_low * stim_con_linear + \n##     event02_expect_angle + lag.04outcomeangle, data = pvc, n.iter = 1000)\n## \n## No mediator specified leads to traditional regression \n##                                 event04_actual_angle   se     t   df      Prob\n## Intercept                                       0.00 0.30 -0.01 5023  9.89e-01\n## CUE_high_gt_low                                -5.37 0.71 -7.54 5023  5.62e-14\n## stim_con_linear                                34.42 0.75 46.13 5023  0.00e+00\n## event02_expect_angle                            0.36 0.01 33.69 5023 1.84e-224\n## lag.04outcomeangle                              0.48 0.01 46.08 5023  0.00e+00\n## CUE_high_gt_low*stim_con_linear                 1.71 1.49  1.14 5023  2.53e-01\n## \n## R = 0.83 R2 = 0.68   F = 2177.74 on 5 and 5023 DF   p-value:  0"},{"path":"mediation.html","id":"mediation-2","chapter":"11 beh :: Mediation","heading":"11.2 mediation 2","text":"","code":"\nmod1 <- \"# a path\n         #thirst ~ a * room_temp\n         event02_expect_angle ~ a * CUE_high_gt_low\n\n         # b path\n         #consume ~ b * thirst\n         event04_actual_angle ~ b* event02_expect_angle\n\n         # c prime path\n         #consume ~ cp * room_temp\n         event04_actual_angle ~ cp * CUE_high_gt_low\n\n         # indirect and total effects\n         ab := a * b\n         total := cp + ab\"\nlibrary(lavaan)## This is lavaan 0.6-17\n## lavaan is FREE software! Please report any bugs.## \n## Attaching package: 'lavaan'## The following object is masked from 'package:psych':\n## \n##     cor2cov\nfsem1 <- sem(mod1, data = pvc, se = \"bootstrap\", bootstrap = 1000)## Warning in lav_model_nvcov_bootstrap(lavmodel = lavmodel, lavsamplestats =\n## lavsamplestats, : lavaan WARNING: 236 bootstrap runs failed or did not\n## converge.\nsummary(fsem1, standardized = TRUE)## lavaan 0.6.17 ended normally after 1 iteration\n## \n##   Estimator                                         ML\n##   Optimization method                           NLMINB\n##   Number of model parameters                         5\n## \n##                                                   Used       Total\n##   Number of observations                          4621        5029\n## \n## Model Test User Model:\n##                                                       \n##   Test statistic                                 0.000\n##   Degrees of freedom                                 0\n## \n## Parameter Estimates:\n## \n##   Standard errors                            Bootstrap\n##   Number of requested bootstrap draws             1000\n##   Number of successful bootstrap draws             764\n## \n## Regressions:\n##                          Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##   event02_expect_angle ~                                                      \n##     CUE_hgh__  (a)         34.622    1.053   32.883    0.000   34.622    0.429\n##   event04_actual_angle ~                                                      \n##     evnt02_x_  (b)          0.674    0.013   51.439    0.000    0.674    0.715\n##     CUE_hgh__ (cp)        -15.034    0.978  -15.379    0.000  -15.034   -0.198\n## \n## Variances:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##    .evnt02_xpct_ng 1328.872   32.023   41.497    0.000 1328.872    0.816\n##    .evnt04_ctl_ngl  825.688   20.426   40.423    0.000  825.688    0.571\n## \n## Defined Parameters:\n##                    Estimate  Std.Err  z-value  P(>|z|)   Std.lv  Std.all\n##     ab               23.321    0.855   27.266    0.000   23.321    0.307\n##     total             8.287    1.092    7.592    0.000    8.287    0.109\nparameterestimates(fsem1, boot.ci.type = \"bca.simple\", standardized = TRUE) %>%\n  kable()"},{"path":"mediation.html","id":"mediation-3-test-same-model-using-mediation-from-mbess","chapter":"11 beh :: Mediation","heading":"11.3 mediation 3: Test same model using mediation() from MBESS","text":"","code":"## Warning in resid.Y.on.X + resid.Y.on.M: longer object length is not a multiple\n## of shorter object length## Warning in resid.Y.on.X + resid.Y.on.M - resid.Y.on.X.and.M: longer object\n## length is not a multiple of shorter object length## Warning in standardized.resid.Y.on.X + standardized.resid.Y.on.M: longer object\n## length is not a multiple of shorter object length## Warning in standardized.resid.Y.on.X + standardized.resid.Y.on.M -\n## standardized.resid.Y.on.X.and.M: longer object length is not a multiple of\n## shorter object length## Warning in abs(e.1M) + abs(e.1Y): longer object length is not a multiple of\n## shorter object length## Warning in abs(standardized.e.1M) + abs(standardized.e.1Y): longer object\n## length is not a multiple of shorter object length## [1] \"Bootstrap resampling has begun. This process may take a considerable amount of time if the number of replications is large, which is optimal for the bootstrap procedure.\"##                                           Estimate CI.Lower_BCa CI.Upper_BCa\n## Indirect.Effect                        23.32106331           NA           NA\n## Indirect.Effect.Partially.Standardized  0.61326642           NA           NA\n## Index.of.Mediation                      0.30663221           NA           NA\n## R2_4.5                                 -0.02001083           NA           NA\n## R2_4.6                                  0.07764679           NA           NA\n## R2_4.7                                  0.18103664           NA           NA\n## Ratio.of.Indirect.to.Total.Effect       2.81406275           NA           NA\n## Ratio.of.Indirect.to.Direct.Effect     -1.55124885           NA           NA\n## Success.of.Surrogate.Endpoint           0.23936430           NA           NA\n## Residual.Based_Gamma                            NA           NA           NA\n## Residual.Based.Standardized_gamma               NA           NA           NA\n## SOS                                    -1.68537707           NA           NA"},{"path":"mediation.html","id":"mediation-4-test-library-mediation","chapter":"11 beh :: Mediation","heading":"11.4 mediation 4: Test library mediation","text":":::: {.refbox}https://nmmichalak.github.io/nicholas_michalak/blog_entries/2018/nrg01/nrg01.html\n::::","code":""},{"path":"simulation.html","id":"simulation","chapter":"12 RL :: simulation","heading":"12 RL :: simulation","text":"title: “Document Title”\noutput: html_notebook","code":""},{"path":"simulation.html","id":"what-is-the-purpose-of-this-notebook-8","chapter":"12 RL :: simulation","heading":"What is the purpose of this notebook?","text":", Aryan simulated behavioral outcome ratings using reinforcement learning model.","code":""},{"path":"simulation.html","id":"load-data","chapter":"12 RL :: simulation","heading":"load data","text":"","code":""},{"path":"simulation.html","id":"function","chapter":"12 RL :: simulation","heading":"12.1 function","text":"","code":"\n# summarize dataframe __________________________________________________________\nplot_twovariable <- function(df, iv1, iv2, group, subject, xmin, xmax, ymin,ymax,\nxlab, ylab, ggtitle, color_scheme, alpha, fit_lm, lm_method = NULL, identity_line=TRUE, size=NULL) {\n    # x: iv1 e.g. expect rating\n    # y: iv2 e.g. outcome rating\n    # group: param_cue_type\n    # subject: src_subject_id\n    # xlab(\"expect rating\") +\n    # ylab(\"outcome rating\") +\n    # color_scheme = c(\"high_cue\" = \"#000000\",low_cue\" = \"#BBBBBB\"        )\n    library(ggplot2)\n\n    df_dropna <- df[!is.na(df[, iv1]) & !is.na(df[, iv2]), ]\n    subjectwise_naomit_2dv <- meanSummary_2continuous(\n        df_dropna,\n        c(subject, group),\n        iv1, iv2\n    )\n    # subjectwise_naomit_2dv <- na.omit(subjectwise_2dv)\n    subjectwise_naomit_2dv[ , group] <- as.factor(subjectwise_naomit_2dv[, group])\n    # plot _________________________________________________________________________ #nolint\n\n    g <- ggplot(\n        data = subjectwise_naomit_2dv,\n        aes(\n            x = .data[[\"DV1_mean_per_sub\"]],\n            y = .data[[\"DV2_mean_per_sub\"]],\n            color = .data[[group]],\n            size = size\n        )\n    ) +\n        geom_point(\n            aes(shape = .data[[group]],\n            color = .data[[group]]),\n            size = 2,\n            alpha = alpha) +\n\n        theme(aspect.ratio = 1) +\n        scale_color_manual(values = color_scheme) +\n        scale_shape_manual(values = c(16, 3)) +\n        xlab(xlab) +\n        ylab(ylab) +\n        ylim(ymin,ymax) +\n        xlim(xmin,xmax) +\n        ggtitle(ggtitle) +\n        theme(\n            axis.line = element_line(colour = \"grey50\"),\n            panel.background = element_blank(),\n            plot.subtitle = ggtext::element_textbox_simple(size = 11)\n        )\n\n    if (isTRUE(fit_lm)) {\n        g <- g +\n        # geom_ribbon(stat = \"smooth\", method = lm_method, se = FALSE, alpha = 0.1,\n        #       aes(color = NULL, group = factor(group))) +\n        geom_line(stat = \"smooth\", method = lm_method, se = FALSE, alpha = 0.8, linewidth = 1.5)\n    } else {\n        g\n    }\n\n    if (isTRUE(identity_line)) {\n        g <- g + geom_abline(\n            intercept = 0, slope = 1, color = \"#373737\", # color = \"green\"\n            linetype = \"dashed\",\n            linewidth = .5\n        )\n    } else {\n        g\n    }\n    return(g)\n}"},{"path":"simulation.html","id":"plot-expectation-and-outcome-ratings-per-cue-x-stim","chapter":"12 RL :: simulation","heading":"plot expectation and outcome ratings per cue X stim","text":"curvature resembles demeaned ratings observed.","code":"\ngroup <- \"cue\"\n\niv1 <- \"demean_expect\"\niv2 <- \"demean_outcome\"\n\nsubject <- \"sub\"\nxmin <- 48;xmax <- 50\nymin <- 48;ymax <- 50\nxlab <- \"expectation rating\"\nylab <- \"outcome rating\"\nggtitle <- \"all stimulus intensity\"\ncolor_scheme <- c(\"high_cue\" = \"#941100\", \"low_cue\" =  \"#5D5C5C\")\nalpha <- .8\nfit_lm <- TRUE\nlm_method <- \"lm\"\nidentity_line <- TRUE\nsize <- NULL\ng <- ggplot(data = merged_df,\n            aes(\n              x = .data[[\"expectation\"]],\n              y = .data[[\"outcome\"]],\n              color = .data[[group]],\n              size = size\n            )) +\n  geom_point(aes(shape = .data[[group]],\n                 color = .data[[group]]),\n             size = 2,\n             alpha = alpha) +\n  theme(aspect.ratio = 1) +\n  scale_color_manual(values = color_scheme) +\n  scale_shape_manual(values = c(16, 3)) +\n  xlab(xlab) +\n  ylab(ylab) +\n  ylim(ymin, ymax) +\n  xlim(xmin, xmax) +\n  ggtitle(ggtitle) +\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 11)\n  )\n\n\nif (isTRUE(fit_lm)) {\n  g <- g +\n    geom_line(\n      stat = \"smooth\",\n      method = lm_method,\n      se = FALSE,\n      alpha = 0.8,\n      linewidth = 1.5\n    )\n} else {\n  g\n}\n\nif (isTRUE(identity_line)) {\n  g <- g + geom_abline(\n    intercept = 0,\n    slope = 1,\n    color = \"#373737\",\n    # color = \"green\"\n    linetype = \"dashed\",\n    linewidth = .5\n  )\n} else {\n  g\n}\ng## Warning: Using `size` aesthetic for lines was deprecated in ggplot2 3.4.0.\n## ℹ Please use `linewidth` instead.\n## This warning is displayed once every 8 hours.\n## Call `lifecycle::last_lifecycle_warnings()` to see where this warning was\n## generated.## `geom_smooth()` using formula = 'y ~ x'"},{"path":"simulation.html","id":"plot-expectation-and-outcome-collapsing-across-all-stimulus-intesnity","chapter":"12 RL :: simulation","heading":"12.2 plot expectation and outcome, collapsing across all stimulus intesnity","text":"Given ratings demeaned, intercept mean intensity ratings (49 C).","code":""},{"path":"simulation.html","id":"plot-outcome-as-a-function-of-stim-x-cue-x-expectation-rating","chapter":"12 RL :: simulation","heading":"12.3 Plot Outcome as a function of stim X cue X Expectation rating","text":"","code":""},{"path":"simulation.html","id":"plot-cue-and","chapter":"12 RL :: simulation","heading":"12.3.1 plot cue and","text":"cue stim effects signficiant, mid range different. behaviorla data shows medium intensity smaller cue effects compared high low cues, whereas current simulations show opposite trend. sure read much .","code":""},{"path":"simulation_aryan.html","id":"simulation_aryan","chapter":"13 RL :: simulation Aryan","heading":"13 RL :: simulation Aryan","text":"","code":""},{"path":"simulation_aryan.html","id":"output-rmdformatsdowncute","chapter":"13 RL :: simulation Aryan","heading":"13.1 output: rmdformats::downcute","text":"","code":""},{"path":"simulation_aryan.html","id":"what-is-the-purpose-of-this-notebook-9","chapter":"13 RL :: simulation Aryan","heading":"What is the purpose of this notebook?","text":", model Aryans model fitted results, using scheme behavioral analysis (15*.Rmd)","code":""},{"path":"simulation_aryan.html","id":"load-data-1","chapter":"13 RL :: simulation Aryan","heading":"load data","text":"","code":""},{"path":"simulation_aryan.html","id":"plot-the-relationship-between-expectation-and-outcome-rating-using-model-4-simulations-jepma","chapter":"13 RL :: simulation Aryan","heading":"13.2 Plot the relationship between expectation and outcome rating using model 4 simulations (Jepma)","text":"","code":""},{"path":"simulation_aryan.html","id":"plot-the-relationship-between-expectation-and-outcome-rating-using-model-2-simulations-jepma","chapter":"13 RL :: simulation Aryan","heading":"13.3 Plot the relationship between expectation and outcome rating using model 2 simulations (Jepma)","text":"","code":""},{"path":"simulation_aryan.html","id":"model-fits-from-model-2.-expectation-ratings-jepma-model","chapter":"13 RL :: simulation Aryan","heading":"13.3.1 model fits from model 2. expectation ratings (Jepma model)","text":"","code":"\nmain_dir = dirname(dirname(getwd()))\ndata <- read.csv(file.path(main_dir, 'data/simulated/model_ver04_0508/table_pain_new.csv'))\nsubjectwise_2dv <- meanSummary_2continuous(data, c(\"src_subject_id\"),\n                                   \"event02_expect_angle\", \"Exp_mdl2\" )\nggplot(data = subjectwise_2dv,\n       aes(x = .data[[\"DV1_mean_per_sub\"]],\n           y = .data[[\"DV2_mean_per_sub\"]],\n           size = .5\n           )) +\n  geom_point(size = 2, alpha = .5  ) +\n  ylim(0,180) +\n  xlim(0,180) +\n  coord_fixed() +\n  geom_abline(intercept = 0, slope = 1, color = \"#373737\", linetype = \"dashed\", linewidth = .5) +\n  xlab(\"Observed\\nexpectation rating\") +\n  ylab(\"Model-fitted \\nexpectation rating\")+\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 1),\n    axis.text.x = element_text(size = 10),\n    axis.text.y = element_text(size = 10),\n    axis.title.x = element_text(size = 15),\n    axis.title.y = element_text(size = 15)\n\n  )"},{"path":"simulation_aryan.html","id":"model-fits-from-model-2.-outcome-ratings-jepma-model","chapter":"13 RL :: simulation Aryan","heading":"13.3.2 model fits from model 2. outcome ratings (Jepma model)","text":"","code":"\nsubjectwise_2dv <- meanSummary_2continuous(data, c(\"src_subject_id\"),\n                                   \"event04_actual_angle\", \"Pain_mdl2\" )\nggplot(data = subjectwise_2dv,\n       aes(x = .data[[\"DV1_mean_per_sub\"]],\n           y = .data[[\"DV2_mean_per_sub\"]],\n           size = .5\n           )) +\n  geom_point(size = 2, alpha = .5  ) +\n  ylim(0,180) +\n  xlim(0,180) +\n  coord_fixed() +\n  geom_abline(intercept = 0, slope = 1, color = \"#373737\", linetype = \"dashed\", linewidth = .5) +\n  xlab(\"Observed\\noutcome rating\") +\n  ylab(\"Model-fitted \\noutcome rating\")+\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 1),\n    axis.text.x = element_text(size = 15),\n    axis.text.y = element_text(size = 15),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20)\n\n  )"},{"path":"simulation_aryan.html","id":"correlation-betweeen-alpha_incongruent-and-cue-trial-slope-randome-effects-of-cue","chapter":"13 RL :: simulation Aryan","heading":"13.4 correlation betweeen alpha_incongruent and cue trial slope (randome effects of cue)","text":"","code":"## Warning: Removed 3 rows containing missing values (`geom_point()`).## Warning: Removed 2 rows containing missing values (`geom_point()`)."},{"path":"simulation_aryan.html","id":"correlation-betweeen-alpha_incongruent-and-nps","chapter":"13 RL :: simulation Aryan","heading":"13.5 correlation betweeen alpha_incongruent and NPS","text":"","code":"\n# load dataframe\nNPS <- data.frame(read.csv(file.path(main_dir, 'data/NPS_curated.csv')))\nNPS <- NPS %>%\n  mutate(congruency = case_when(\n    cuetype == \"cuetype-low\" & stimintensity == \"low\" ~ \"congruent\",\n    cuetype == \"cuetype-high\" & stimintensity == \"high\" ~ \"congruent\",\n    cuetype == \"cuetype-low\" & stimintensity == \"high\" ~ \"incongruent\",\n    cuetype == \"cuetype-high\" & stimintensity == \"low\" ~ \"incongruent\",\n    TRUE ~ \"other\"\n  ))\nNPS_congru <- NPS %>%\n  group_by(sub) %>%\n  summarise(avg_diff = mean(NPSpos[congruency == \"congruent\"]) - mean(NPSpos[congruency == \"incongruent\"]))\n\n# grab alpha_incongruent\nmodel_param <- data.frame(read.csv(file.path(main_dir, \"data/RL/modelfit_jepma_0525/par_mdl2_pain.csv\")))\n\nmodel_param <- model_param %>%\n  mutate(sub = sprintf(\"sub-%04d\", subj_num_new_pain))\n\n# Merge the two dataframes based on the \"sub\" column\nmerged_NPS <- merge(NPS_congru, model_param, by = \"sub\")\nmerged_NPS$alpha_c_gt_i <- merged_NPS$alpha_c - merged_NPS$alpha_i\n# grab cue slope\n# grab intersection of subject ids\n# plot ggplot\nggplot(data = merged_NPS,\n       aes(x = .data[[\"avg_diff\"]],\n           y = .data[[\"alpha_c_gt_i\"]],\n           size = .5\n           )) +\n  geom_point(size = 2, alpha = .5  ) +\n  ylim(-10,10) +\n  xlim(-10,10) +\n  coord_fixed() +\n  geom_abline(intercept = 0, slope = 1, color = \"#373737\", linetype = \"dashed\", linewidth = .5) +\n  xlab(\"NPS \\n(congruent > incongruent)\") +\n  ylab(\"Alpha \\n(congruent > incongruent)\")+\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 1),\n    axis.text.x = element_text(size = 15),\n    axis.text.y = element_text(size = 15),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20)\n\n  )\n# run lmer"},{"path":"simulation_aryan.html","id":"correlation-bettween-nps-and-pe","chapter":"13 RL :: simulation Aryan","heading":"13.6 correlation bettween NPS and PE","text":"","code":""},{"path":"simulation_aryan.html","id":"test-similarity-between-nps-positive-values-and-pe-11062023","chapter":"13 RL :: simulation Aryan","heading":"13.6.1 test similarity between NPS positive values and PE (11/06/2023)","text":"","code":"\nPEdf <- read.csv(file.path(main_dir, 'data/RL/modelfit_jepma_0525/table_pain.csv'))\nNPS <- data.frame(read.csv(file.path(main_dir, 'data/NPS_curated.csv')))\n\nPEdf <- PEdf %>%\n  mutate(sub = sprintf(\"sub-%04d\", src_subject_id),\n         ses = sprintf(\"ses-%02d\", session_id),\n         run = sprintf(\"run-%02d\", param_run_num),\n         trial = sprintf(\"trial-%03d\", trial_index_runwise-1)\n         )\nmerged_NPSpe <- merge(NPS, PEdf, by = c(\"sub\", \"ses\", \"run\", \"trial\"))\n\n\nsubjectwise_2dv <- meanSummary_2continuous(merged_NPSpe, c(\"src_subject_id\",\"stimintensity\", \"cuetype\"),\n                                   \"PE_mdl2\", \"NPSpos\" )\nggplot(data = subjectwise_2dv,\n       aes(x = .data[[\"DV1_mean_per_sub\"]],\n           y = .data[[\"DV2_mean_per_sub\"]],\n           color = .data[[\"cuetype\"]],\n           # shape = .data[[\"stimintensity\"]],\n           # size = .5\n           )) +\n  geom_point(size = 2, alpha = .5  ) +\n  ylim(-50,50) +\n  xlim(-50,50) +\n  coord_fixed() +\n  scale_color_manual(values = c(\"cuetype-high\" =\"red\",\"cuetype-low\" =  \"#5D5C5C\"))+\n  geom_abline(intercept = 0, slope = 1, color = \"#373737\", linetype = \"dashed\", linewidth = .5) +\n  xlab(\"PE\") +\n  ylab(\"NPSpos\")+\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 1),\n    axis.text.x = element_text(size = 15),\n    axis.text.y = element_text(size = 15),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20)\n\n  )## Warning: Removed 13 rows containing missing values (`geom_point()`).\nmodel.25 <- lmer(merged_NPSpe$NPSpos ~ merged_NPSpe$PE_mdl2 + (1|sub), data = merged_NPSpe)\nsummary(model.25)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: merged_NPSpe$NPSpos ~ merged_NPSpe$PE_mdl2 + (1 | sub)\n##    Data: merged_NPSpe\n## \n## REML criterion at convergence: 20826.7\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.4290 -0.5073 -0.0168  0.5202  5.5313 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept) 28.52    5.340   \n##  Residual             68.76    8.292   \n## Number of obs: 2922, groups:  sub, 54\n## \n## Fixed effects:\n##                       Estimate Std. Error        df t value Pr(>|t|)    \n## (Intercept)          6.501e+00  7.457e-01 5.305e+01   8.718 8.06e-12 ***\n## merged_NPSpe$PE_mdl2 3.876e-02  6.866e-03 2.896e+03   5.645 1.81e-08 ***\n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##             (Intr)\n## mr_NPS$PE_2 -0.052"},{"path":"simulation_aryan.html","id":"test-relationship-between-pe-and-cue-type-and-stimintensity-06162023","chapter":"13 RL :: simulation Aryan","heading":"13.6.2 test relationship between PE and cue type and stimintensity (06/16/2023)","text":"","code":"\nmodel.PENPS <- lmer(NPSpos ~ PE_mdl2*cuetype*stimintensity + (1|sub), data = merged_NPSpe)\nsummary(model.PENPS)## Linear mixed model fit by REML. t-tests use Satterthwaite's method [\n## lmerModLmerTest]\n## Formula: NPSpos ~ PE_mdl2 * cuetype * stimintensity + (1 | sub)\n##    Data: merged_NPSpe\n## \n## REML criterion at convergence: 20816\n## \n## Scaled residuals: \n##     Min      1Q  Median      3Q     Max \n## -5.5455 -0.5260 -0.0153  0.5196  5.6086 \n## \n## Random effects:\n##  Groups   Name        Variance Std.Dev.\n##  sub      (Intercept) 28.32    5.321   \n##  Residual             68.21    8.259   \n## Number of obs: 2922, groups:  sub, 54\n## \n## Fixed effects:\n##                                               Estimate Std. Error         df\n## (Intercept)                                  7.590e+00  8.362e-01  8.488e+01\n## PE_mdl2                                     -1.962e-02  3.555e-02  2.887e+03\n## cuetypecuetype-low                           1.515e+00  9.025e-01  2.890e+03\n## stimintensitylow                            -1.753e+00  8.436e-01  2.883e+03\n## stimintensitymed                            -2.107e+00  6.415e-01  2.873e+03\n## PE_mdl2:cuetypecuetype-low                   2.818e-03  4.109e-02  2.887e+03\n## PE_mdl2:stimintensitylow                     4.253e-02  4.452e-02  2.883e+03\n## PE_mdl2:stimintensitymed                     1.800e-03  4.896e-02  2.870e+03\n## cuetypecuetype-low:stimintensitylow         -1.618e+00  1.252e+00  2.893e+03\n## cuetypecuetype-low:stimintensitymed          4.626e-01  1.160e+00  2.868e+03\n## PE_mdl2:cuetypecuetype-low:stimintensitylow -2.715e-02  5.295e-02  2.867e+03\n## PE_mdl2:cuetypecuetype-low:stimintensitymed  2.309e-02  5.654e-02  2.863e+03\n##                                             t value Pr(>|t|)    \n## (Intercept)                                   9.077 3.81e-14 ***\n## PE_mdl2                                      -0.552  0.58111    \n## cuetypecuetype-low                            1.678  0.09337 .  \n## stimintensitylow                             -2.077  0.03786 *  \n## stimintensitymed                             -3.284  0.00104 ** \n## PE_mdl2:cuetypecuetype-low                    0.069  0.94533    \n## PE_mdl2:stimintensitylow                      0.955  0.33953    \n## PE_mdl2:stimintensitymed                      0.037  0.97068    \n## cuetypecuetype-low:stimintensitylow          -1.293  0.19626    \n## cuetypecuetype-low:stimintensitymed           0.399  0.69017    \n## PE_mdl2:cuetypecuetype-low:stimintensitylow  -0.513  0.60816    \n## PE_mdl2:cuetypecuetype-low:stimintensitymed   0.408  0.68304    \n## ---\n## Signif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n## \n## Correlation of Fixed Effects:\n##                                (Intr) PE_md2 ctypc- stmntnstyl stmntnstym\n## PE_mdl2                        -0.215                                    \n## ctypctyp-lw                    -0.224  0.174                             \n## stmntnstylw                    -0.252  0.234  0.273                      \n## stmntnstymd                    -0.329  0.314  0.308  0.365               \n## PE_mdl2:ct-                     0.184 -0.850 -0.565 -0.232     -0.276    \n## PE_mdl2:stmntnstyl              0.164 -0.780 -0.096  0.285     -0.217    \n## PE_mdl2:stmntnstym              0.141 -0.668 -0.096 -0.102      0.138    \n## ctypctyp-lw:stmntnstyl          0.168 -0.138 -0.747 -0.704     -0.249    \n## ctypctyp-lw:stmntnstym          0.180 -0.159 -0.741 -0.221     -0.557    \n## PE_mdl2:ctypctyp-lw:stmntnstyl -0.136  0.636  0.359 -0.222      0.181    \n## PE_mdl2:ctypctyp-lw:stmntnstym -0.121  0.572  0.337  0.095     -0.117    \n##                                PE_m2:- PE_mdl2:stmntnstyl PE_mdl2:stmntnstym\n## PE_mdl2                                                                     \n## ctypctyp-lw                                                                 \n## stmntnstylw                                                                 \n## stmntnstymd                                                                 \n## PE_mdl2:ct-                                                                 \n## PE_mdl2:stmntnstyl              0.635                                       \n## PE_mdl2:stmntnstym              0.554   0.566                               \n## ctypctyp-lw:stmntnstyl          0.434  -0.235              0.042            \n## ctypctyp-lw:stmntnstym          0.431   0.090             -0.099            \n## PE_mdl2:ctypctyp-lw:stmntnstyl -0.705  -0.807             -0.454            \n## PE_mdl2:ctypctyp-lw:stmntnstym -0.643  -0.478             -0.855            \n##                                ctypctyp-lw:stmntnstyl ctypctyp-lw:stmntnstym\n## PE_mdl2                                                                     \n## ctypctyp-lw                                                                 \n## stmntnstylw                                                                 \n## stmntnstymd                                                                 \n## PE_mdl2:ct-                                                                 \n## PE_mdl2:stmntnstyl                                                          \n## PE_mdl2:stmntnstym                                                          \n## ctypctyp-lw:stmntnstyl                                                      \n## ctypctyp-lw:stmntnstym          0.562                                       \n## PE_mdl2:ctypctyp-lw:stmntnstyl -0.068                 -0.295                \n## PE_mdl2:ctypctyp-lw:stmntnstym -0.226                 -0.264                \n##                                PE_mdl2:ctypctyp-lw:stmntnstyl\n## PE_mdl2                                                      \n## ctypctyp-lw                                                  \n## stmntnstylw                                                  \n## stmntnstymd                                                  \n## PE_mdl2:ct-                                                  \n## PE_mdl2:stmntnstyl                                           \n## PE_mdl2:stmntnstym                                           \n## ctypctyp-lw:stmntnstyl                                       \n## ctypctyp-lw:stmntnstym                                       \n## PE_mdl2:ctypctyp-lw:stmntnstyl                               \n## PE_mdl2:ctypctyp-lw:stmntnstym  0.520"},{"path":"simulation_aryan.html","id":"plot-the-relationship-between-pe-and-nps-as-a-function-of-cue","chapter":"13 RL :: simulation Aryan","heading":"13.6.3 plot the relationship between PE and NPS as a function of cue","text":"","code":"\nggplot(data = merged_NPSpe,\n       aes(x = .data[[\"PE_mdl2\"]],\n           y = .data[[\"NPSpos\"]],\n           color = .data[[\"cuetype\"]],\n           size = .5\n           )) +\n  geom_point(size = 2, alpha = .5  ) +\n  ylim(-150,150) +\n  xlim(-150,150) +\n  coord_fixed() +\n  scale_color_manual(values = c(\"cuetype-high\" =\"red\",\"cuetype-low\" =  \"#5D5C5C\"))+\n  geom_abline(intercept = 0, slope = 1, color = \"#373737\", linetype = \"dashed\", linewidth = .5) +\n  xlab(\"PE\") +\n  ylab(\"NPSpos\")+\n  theme(\n    axis.line = element_line(colour = \"grey50\"),\n    panel.background = element_blank(),\n    plot.subtitle = ggtext::element_textbox_simple(size = 1),\n    axis.text.x = element_text(size = 15),\n    axis.text.y = element_text(size = 15),\n    axis.title.x = element_text(size = 20),\n    axis.title.y = element_text(size = 20)\n\n  )"},{"path":"simulation_aryan.html","id":"plot-the-relationship-between-pe-and-nps-as-a-function-of-cue-and-stimulus-intensity","chapter":"13 RL :: simulation Aryan","heading":"13.6.4 plot the relationship between PE and NPS as a function of cue and stimulus intensity","text":"","code":""},{"path":"ch20_npssimulation.html","id":"ch20_npssimulation","chapter":"14 [model] NPSsimulation","heading":"14 [model] NPSsimulation","text":"","code":""},{"path":"ch20_npssimulation.html","id":"function-1","chapter":"14 [model] NPSsimulation","heading":"14.0.1 Function","text":"","code":""},{"path":"ch20_npssimulation.html","id":"nps-data","chapter":"14 [model] NPSsimulation","heading":"14.0.2 NPS data","text":"","code":""},{"path":"ch20_npssimulation.html","id":"behavioral-data","chapter":"14 [model] NPSsimulation","heading":"14.0.3 behavioral data","text":"","code":""},{"path":"ch20_npssimulation.html","id":"q.-within-pain-task-does-stimulus-intenisty-level-and-cue-level-significantly-predict-nps-dotproducts","chapter":"14 [model] NPSsimulation","heading":"Q. Within pain task, Does stimulus intenisty level and cue level significantly predict NPS dotproducts?","text":"","code":""},{"path":"ch20_npssimulation.html","id":"get-pain-relationship-controlling-for-cue-cuetype-expect","chapter":"14 [model] NPSsimulation","heading":"14.0.4 get pain relationship, controlling for cue, cuetype, expect","text":"\nMultilevel-modeling:\nlmer(NPSpos ~ CUE + STIM + EXPECT_demean + SES + (1| sub), data = pvc)\n","code":"\nmodel.stim <- lmer(event04_actual_angle ~\n                          STIM_linear +\n                          CUE_high_gt_low + STIM_quadratic+ EXPECT_demean +\n                          EXPECT_cmc +\n                          ses +\n                          (1|sub), data = df\n                    )\n# CUE_high_gt_low+STIM+EXPECT_demean\nsjPlot::tab_model(model.stim,\n                  title = \"Multilevel-modeling: \\nlmer(NPSpos ~ CUE + STIM + EXPECT_demean + SES + (1| sub), data = pvc)\",\n                  CSS = list(css.table = '+font-size: 12;'))\n# re.beta <- coef(model.stim)$unit[,\"x\"]\nfixEffect_expect <-as.data.frame(fixef(model.stim))\nrandEffect_expect <-as.data.frame(ranef(model.stim))\nntrials = 12\nlowintens = 48;\nmedintens = 49;\nhighintens = 50;\nstim <- 48:50\npainmean = 30      # average pain; arbitrary, on a 0 - 100 scale\npainslope = fixEffect_expect['STIM_linear',1]     # rise in pain per unit change in stim (per degree)\npainslope_stan = 0.33621048\nstdCoef.merMod <- function(object) {\n  sdy <- sd(getME(object,\"y\"))\n  sdx <- apply(getME(object,\"X\"), 2, sd)\n  sc <- fixef(object)*sdx/sdy\n  se.fixef <- coef(summary(object))[,\"Std. Error\"]\n  se <- se.fixef*sdx/sdy\n  return(data.frame(stdcoef=sc, stdse=se))\n}\nstdCoef.merMod(model.stim)##                     stdcoef       stdse\n## (Intercept)      0.00000000 0.000000000\n## STIM_linear      0.31648413 0.007848709\n## CUE_high_gt_low -0.02640086 0.009953683\n## STIM_quadratic   0.01621649 0.007849931\n## EXPECT_demean    0.22157672 0.009947333\n## EXPECT_cmc       0.69471095 0.034434185\n## sesses-03       -0.08777975 0.010153298\n## sesses-04       -0.09126342 0.010120143\n# # library(limma)\n\n# S <- rep(stim,times=ntrials) # stim\n# C <- rep(rep(c(1,-1), each = 3), times = 6) #cue\n# E <- painslope * (C + rnorm(length(C))) + painmean # pseudo nociception\n# Szscore <- (S - mean(S)) / sd(S)\n\ndf$S <- as.numeric(mapvalues(df$stimintensity,\n                                        from = c(\"low\", \"med\", \"high\"), c(48, 49, 50)))\ndf$C <- as.numeric(mapvalues(df$cuetype,\n                                        from = c(\"cuetype-low\", \"cuetype-high\"), c(-1, 1)))\ndf$E <- painslope * (df$C + rnorm(length(df$C))) + painmean\n\ndf$Szscore <- (df$S - mean(df$S, na.rm = TRUE)) / sd(df$S)\n\ndf$Pcalib = df$Szscore * painslope + painmean + rnorm(length(df$C))\n\nmodel.stim2pain <- lmer(Pcalib ~ S  + (1|sub), df)\n\nb_stim2pain = fixef(model.stim2pain)[2] #0.4126089 #36.5757\n\ndf$Sprime = df$Szscore * b_stim2pain + painmean # subjective pain experience, converted to a scale of 0-180, in order to match expectation ratings\n# df$Sprime = df$S * b_stim2pain\n\ndf <- df %>%\n  group_by(sub) %>%\n  mutate(E = as.numeric(E)) %>%\n  mutate(avg_E = mean(E, na.rm = TRUE)) %>%\n  mutate(E_demean = E - avg_E) %>%\n  mutate(E_cmc = avg_E - mean(avg_E))"},{"path":"ch20_npssimulation.html","id":"simulation-1","chapter":"14 [model] NPSsimulation","heading":"14.1 simulation **","text":"","code":"\nw = 0.7\n\nerror = rnorm(length(df$C))\n\ndf$P.assim <-  w * df$Sprime + (1 - w) * df$E + error\n\ndf$P.pe = df$Sprime - df$E + error\n\ndf$P.adapt <- 1\n\n  minimal.diff <- (df$Sprime - df$E)/std(df$Sprime) < b_stim2pain\n  large.diff <- (df$Sprime - df$E)/std(df$Sprime) > b_stim2pain\n  df$P.adapt[minimal.diff] <- w * df$Sprime[minimal.diff] + (1 - w) * df$E[minimal.diff] + error[minimal.diff]\n  df$P.adapt[large.diff] <- w * df$Sprime[large.diff]  + error[large.diff]"},{"path":"ch20_npssimulation.html","id":"lineplots-original","chapter":"14 [model] NPSsimulation","heading":"Lineplots Original","text":"","code":"## Automatically converting the following non-factors to factors: cue_name"},{"path":"ch20_npssimulation.html","id":"lineplots-p.assim","chapter":"14 [model] NPSsimulation","heading":"Lineplots P.assim","text":"","code":"## Automatically converting the following non-factors to factors: cue_name"},{"path":"ch20_npssimulation.html","id":"p.assim-demeaned_expect-_-cue-_-stim","chapter":"14 [model] NPSsimulation","heading":"14.1.1 P.assim ~ demeaned_expect _ cue _ stim","text":"","code":""},{"path":"ch20_npssimulation.html","id":"lineplots-p.pe","chapter":"14 [model] NPSsimulation","heading":"Lineplots P.pe","text":"","code":"## Automatically converting the following non-factors to factors: cue_name"},{"path":"ch20_npssimulation.html","id":"p.pe-demeaned_expect-_-cue-_-stim","chapter":"14 [model] NPSsimulation","heading":"14.1.2 P.pe ~ demeaned_expect _ cue _ stim","text":"","code":""},{"path":"ch20_npssimulation.html","id":"lineplots-p.adapt","chapter":"14 [model] NPSsimulation","heading":"Lineplots P.adapt","text":"","code":"## Automatically converting the following non-factors to factors: cue_name"},{"path":"ch20_npssimulation.html","id":"p.adapt-demeaned_expect-_-cue-_-stim","chapter":"14 [model] NPSsimulation","heading":"14.1.3 P.adapt ~ demeaned_expect _ cue _ stim","text":"","code":""},{"path":"fmri_time.html","id":"fmri_time","chapter":"fMRI timeseries","heading":"fMRI timeseries","text":"chapters, extract BOLD signal stimulus epoch, ROI course 42 TRs. cover 20s onset stimulus delivery. TTL2 TTL1 signals onset.TTL1 refers start rampup temperature, .e. baseline 32 starts rise intended temperatureTTL1 refers start rampup temperature, .e. baseline 32 starts rise intended temperatureTTL2 refers start plateau epoch, .e. onset intended temperature.TTL2 refers start plateau epoch, .e. onset intended temperature.Chapter @ref(ch51_fir_glasserTPJttl2) plots time series pain stimulus onset, using TTL2 referenceChapter @ref(ch51_fir_glasserTPJttl2) plots time series pain stimulus onset, using TTL2 referenceChapter @ref(fmritimeseries_tt1) plots time series pain stimulus onset, using TTL1 referenceChapter @ref(fmritimeseries_tt1) plots time series pain stimulus onset, using TTL1 reference","code":""},{"path":"fir_ttl2.html","id":"fir_ttl2","chapter":"15 fMRI :: FIR ~ task","heading":"15 fMRI :: FIR ~ task","text":"TODOload tsvconcatenateper time column, calculate mean varianceplot","code":"\nplot_timeseries_onefactor <-  function(df, iv1,  mean, error, xlab, ylab, ggtitle, color) {\n\nn_points <- 100  # Number of points for interpolation\n    g <- ggplot(\n      data = df,\n      aes(\n        x = .data[[iv1]],\n        y = .data[[mean]],\n        group = 1,\n        color = color\n      ),\n      cex.lab = 1.5,\n      cex.axis = 2,\n      cex.main = 1.5,\n      cex.sub = 1.5\n    ) +\n\n      geom_errorbar(aes(\n        ymin = (.data[[mean]] - .data[[error]]),\n        ymax = (.data[[mean]] + .data[[error]]),\n        color = color\n      ), width = .1, alpha=0.8) +\n\n      geom_line() +\n      geom_point(color=color) +\n      ggtitle(ggtitle) +\n      xlab(xlab) +\n      ylab(ylab) +\n\n      theme_classic() +\n\n      theme(aspect.ratio = .6) +\n      expand_limits(x = 3.25) +\n\n      scale_color_manual(\"\",\n                         values =  color) +\n            # scale_fill_manual(\"\",\n                         # values =  color) +\n      theme(\n        legend.position = c(.99, .99),\n        legend.justification = c(\"right\", \"top\"),\n        legend.box.just = \"right\",\n        legend.margin = margin(6, 6, 6, 6)\n      ) +\n      theme(legend.key = element_rect(fill = \"white\", colour = \"white\")) +\n      theme_bw()\n\n    return(g)\n  }"},{"path":"fir_ttl2.html","id":"parameters-todo-ignore","chapter":"15 fMRI :: FIR ~ task","heading":"15.1 parameters {TODO: ignore}","text":"","code":"\n# parameters\nmain_dir <- dirname(dirname(getwd()))\n\ndatadir <- file.path(main_dir, 'analysis/fmri/nilearn/glm/fir')\nanalysis_folder  = paste0(\"model52_iv-6cond_dv-firglasserSPM_ttl2\")\nanalysis_dir <-\n  file.path(main_dir,\n            \"analysis\",\n            \"mixedeffect\",\n            analysis_folder,\n            as.character(Sys.Date())) # nolint\ndir.create(analysis_dir,\n           showWarnings = FALSE,\n           recursive = TRUE)\nsave_dir <- analysis_dir"},{"path":"taskwise-stim-effect.html","id":"taskwise-stim-effect","chapter":"16 taskwise stim effect","heading":"16 taskwise stim effect","text":"","code":"\nroi_list <- c('rINS', 'TPJ', 'dACC', 'PHG', 'V1', 'SM', 'MT', 'RSC', 'LOC', 'FFC', 'PIT', 'pSTS', 'AIP', 'premotor')\nrun_types <- c(\"pain\", \"vicarious\", \"cognitive\")\n  plot_list <- list()\n  TR_length <- 42\nfor (ROI in roi_list) {\n\n    datadir = file.path(main_dir, \"analysis/fmri/spm/fir/ttl2par\")\n taskname = 'pain'\nexclude <- \"sub-0001\"\nfilename <- paste0(\"sub-*\",  \"*roi-\", ROI, \"_tr-42.csv\")\n  common_path <- Sys.glob(file.path(datadir, \"sub-*\",  filename\n  ))\n  filter_path <- common_path[!str_detect(common_path, pattern = exclude)]\n\ndf <- do.call(\"rbind.fill\", lapply(filter_path, FUN = function(files) {\n    read.table(files, header = TRUE, sep = \",\")\n    }))\n\nfor (run_type in run_types) {\n  print(run_type)\n  filtered_df <- df[!(df$condition == \"rating\" | df$condition == \"cue\" | df$runtype != run_type), ]\n\n  parsed_df <- filtered_df %>%\n    separate(condition, into = c(\"cue\", \"stim\"), sep = \"_\", remove = FALSE)\n  # --------------------- subset regions based on ROI ----------------------------\n  df_long <- pivot_longer(parsed_df, cols = starts_with(\"tr\"), names_to = \"tr_num\", values_to = \"tr_value\")\n\n  # ----------------------------- clean factor -----------------------------------\n  df_long$tr_ordered <- factor(\n          df_long$tr_num,\n          levels = c(paste0(\"tr\", 1:TR_length))\n      )\n  df_long$stim_ordered <- factor(\n          df_long$stim,\n          levels = c(\"stimH\", \"stimM\", \"stimL\")\n      )\n\n  # --------------------------- summary statistics -------------------------------\n  subjectwise <- meanSummary(df_long,\n                                        c(\"sub\",\"tr_ordered\", \"stim_ordered\"), \"tr_value\")\n  groupwise <- summarySEwithin(\n    data = subjectwise,\n    measurevar = \"mean_per_sub\",\n    withinvars = c( \"stim_ordered\", \"tr_ordered\"),\n    idvar = \"sub\"\n  )\n  groupwise$task <- run_type\n  # https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n  # ... Rest of your data processing code ...\n\n  # subset <- groupwise[groupwise$runtype == run_type, ]\n  LINEIV1 = \"tr_ordered\"\n  LINEIV2 = \"stim_ordered\"\n  MEAN = \"mean_per_sub_norm_mean\"\n  ERROR = \"se\"\n  dv_keyword = \"actual\"\n  sorted_indices <- order(groupwise$tr_ordered)\n  groupwise_sorted <- groupwise[sorted_indices, ]\n  p1 <- plot_timeseries_bar(groupwise_sorted,\n                            LINEIV1, LINEIV2, MEAN, ERROR,\n                            xlab = \"TRs\",\n                            ylab = paste0(ROI, \" activation (A.U.)\"),\n                            ggtitle = paste0(ROI, \": \",run_type, \" (N = \", length(unique(subjectwise$sub)),\") time series, Epoch - stimulus\"),\n                            color = c(\"#5f0f40\",\"#ae2012\", \"#fcbf49\"))\n  time_points <- seq(1, 0.46 * TR_length, 0.46)\n  #p1 <- p1 + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:(7 + TR_length)])) + theme_classic()\n\n  plot_list[[run_type]] <- p1 + theme_classic()\n}\n\n  # --------------------------- plot three tasks -------------------------------\nlibrary(gridExtra)\nplot_list <- lapply(plot_list, function(plot) {\n  plot + theme(plot.margin = margin(5, 5, 5, 5))  # Adjust plot margins if needed\n})\ncombined_plot <- ggpubr::ggarrange(plot_list[[\"pain\"]],plot_list[[\"vicarious\"]],plot_list[[\"cognitive\"]],\n                  common.legend = TRUE,legend = \"bottom\", ncol = 3, nrow = 1,\n                  widths = c(3, 3, 3), heights = c(.5,.5,.5), align = \"v\")\ncombined_plot\nggsave(file.path(save_dir, paste0(\"roi-\", ROI,\"_epoch-stim_desc-highstimGTlowstim.png\")), combined_plot, width = 12, height = 4)\n\n}## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## \n## Attaching package: 'gridExtra'## The following object is masked from 'package:dplyr':\n## \n##     combine## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\"## [1] \"pain\"\n## [1] \"vicarious\"\n## [1] \"cognitive\""},{"path":"taskwise-stim-effect.html","id":"pca-subjectwise","chapter":"16 taskwise stim effect","heading":"16.0.1 PCA subjectwise","text":"","code":"\n# install.packages(\"ggplot2\")    # Install ggplot2 if you haven't already\n# install.packages(\"FactoMineR\") # Install FactoMineR if you haven't already\nlibrary(ggplot2)\nlibrary(FactoMineR)\nrun_types = c(\"pain\")\nfor (run_type in run_types) {\n  print(run_type)\n  filtered_df <- df[!(df$condition == \"rating\" | df$condition == \"cue\" | df$runtype != run_type), ]\n\n  parsed_df <- filtered_df %>%\n    separate(condition, into = c(\"cue\", \"stim\"), sep = \"_\", remove = FALSE)\n  # --------------------- subset regions based on ROI ----------------------------\n  df_long <- pivot_longer(parsed_df, cols = starts_with(\"tr\"), names_to = \"tr_num\", values_to = \"tr_value\")\n\n  # ----------------------------- clean factor -----------------------------------\n  df_long$tr_ordered <- factor(\n          df_long$tr_num,\n          levels = c(paste0(\"tr\", 1:TR_length))\n      )\n  df_long$stim_ordered <- factor(\n          df_long$stim,\n          levels = c(\"stimH\", \"stimM\", \"stimL\")\n      )\n\n  # --------------------------- summary statistics -------------------------------\n  subjectwise <- meanSummary(df_long,\n                                        c(\"sub\",\"tr_ordered\", \"stim_ordered\"), \"tr_value\")\n\n# Assuming your original dataframe is named 'df'\n\n# Convert the dataframe to wide format\ndf_wide <- pivot_wider(subjectwise,\n                       id_cols = c(\"tr_ordered\", \"stim_ordered\"),\n                       names_from = c(\"sub\"),\n                       values_from = \"mean_per_sub\")\n\n# df_wide <- pivot_wider(subjectwise,\n#                        id_cols = c(\"sub\", \"ROIindex\",\"stim_ordered\"),\n#                        names_from = \"tr_ordered\",\n#                        values_from = \"mean_per_sub\")\nstim_high.df <- df_wide[df_wide$stim_ordered == \"stimH\",]\nstim_med.df <- df_wide[df_wide$stim_ordered == \"stimM\",]\nstim_low.df <- df_wide[df_wide$stim_ordered == \"stimL\",]\n# selected_columns <- subset(stim_high.df, select = 2:(ncol(stim_high.df) - 1))\nmeanhighdf <- data.frame(subset(stim_high.df, select = 3:(ncol(stim_high.df) - 1)))\nhigh.pca_result <- prcomp(meanhighdf)\nhigh.pca_scores <- as.data.frame(high.pca_result$x)\n# Access the proportion of variance explained by each principal component\nhigh.variance_explained <- high.pca_result$sdev^2 / sum(high.pca_result$sdev^2)\nplot(high.variance_explained)\n# Access the standard deviations of each principal component\nhigh.stdev <- high.pca_result$sdev\n\nmeanmeddf <- data.frame(subset(stim_med.df, select = 3:(ncol(stim_med.df) - 1)))\nmed.pca <- prcomp(meanmeddf)\nmed.pca_scores <- as.data.frame(med.pca$x)\n\nmeanlowdf <- data.frame(subset(stim_low.df, select = 3:(ncol(stim_low.df) - 1)))\nlow.pca <- prcomp(meanlowdf)\nlow.pca_scores <- as.data.frame(low.pca$x)\nlibrary(plotly)  # You can use plotly to create an interactive 3D plot\n# plot_ly(high.pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\")\n# plot_ly(low.pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\")\ncombined_pca_scores <- rbind(high.pca_scores, med.pca_scores, low.pca_scores)\n\n# Add a new column to indicate the stim_ordered category (high_stim or low_stim)\ncombined_pca_scores$stim_ordered <- c(rep(\"high_stim\", nrow(high.pca_scores)),\n                                      rep(\"med_stim\", nrow(med.pca_scores)),\n                                      rep(\"low_stim\", nrow(low.pca_scores)))\n\n# Create the 3D PCA plot\nplot_ly(combined_pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\",\n        color = ~stim_ordered)\n# data_matrix <- groupwise[groupwise$stim_ordered == \"high_stim\",c(\"tr_ordered\", \"mean_per_sub_norm_mean\")]\n# sorted_indices <- order(data_matrix$tr_ordered)\n# df_ordered <- data_matrix[sorted_indices, ]\n# pca_result <- PCA(data_matrix$mean_per_sub_norm_mean)\n# datapoints <- df$datapoints\n}## [1] \"pain\"## \n## Attaching package: 'plotly'## The following object is masked from 'package:ggplot2':\n## \n##     last_plot## The following objects are masked from 'package:plyr':\n## \n##     arrange, mutate, rename, summarise## The following object is masked from 'package:reshape':\n## \n##     rename## The following object is masked from 'package:stats':\n## \n##     filter## The following object is masked from 'package:graphics':\n## \n##     layout\nplot_ly(combined_pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\",\n        color = ~stim_ordered)"},{"path":"taskwise-stim-effect.html","id":"pca-groupwise","chapter":"16 taskwise stim effect","heading":"16.0.2 PCA groupwise","text":"","code":"\n# install.packages(\"ggplot2\")    # Install ggplot2 if you haven't already\n# install.packages(\"FactoMineR\") # Install FactoMineR if you haven't already\nlibrary(ggplot2)\nlibrary(FactoMineR)\n\n\n\n# Assuming your original dataframe is named 'df'\n\n# Convert the dataframe to wide format\ndf_wide.group <- pivot_wider(subjectwise,\n                       id_cols = c(\"tr_ordered\", \"stim_ordered\"),\n                       names_from = \"sub\",\n                       values_from = \"mean_per_sub\")\n# ------\n# data_matrix <- groupwise[groupwise$stim_ordered == \"high_stim\",c(\"tr_ordered\", \"mean_per_sub_norm_mean\")]\n# sorted_indices <- order(data_matrix$tr_ordered)\n# df_ordered <- data_matrix[sorted_indices, ]\n# datapoints <- df_ordered$mean_per_sub_norm_mean\n# data_df <- data.frame(Dim1 = datapoints, Dim2 = datapoints, Dim3 = datapoints)\n# pca <- prcomp(data_df)\n# pca_scores <- as.data.frame(pca$x)\n# plot_ly(pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\")\n# -------\nstim_high.df <- df_wide[df_wide$stim_ordered == \"stimH\",]\nstim_low.df <- df_wide[df_wide$stim_ordered == \"stimL\",]\n# selected_columns <- subset(stim_high.df, select = 2:(ncol(stim_high.df) - 1))\nmeanhighdf <- data.frame(subset(stim_high.df, select = 3:(ncol(stim_high.df) - 1)))\nhigh.pca <- prcomp(meanhighdf)\nhigh.pca_scores <- as.data.frame(high.pca$x)\n\nmeanlowdf <- data.frame(subset(stim_low.df, select = 3:(ncol(stim_low.df) - 1)))\nlow.pca <- prcomp(meanlowdf)\nlow.pca_scores <- as.data.frame(low.pca$x)\nlibrary(plotly)  # You can use plotly to create an interactive 3D plot\n# plot_ly(high.pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\")\n# plot_ly(low.pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\")\ncombined_pca_scores <- rbind(high.pca_scores, low.pca_scores)\n\n# Add a new column to indicate the stim_ordered category (high_stim or low_stim)\ncombined_pca_scores$stim_ordered <- c(rep(\"high_stim\", nrow(high.pca_scores)), rep(\"low_stim\", nrow(low.pca_scores)))\n\n# Create the 3D PCA plot\nplot_ly(combined_pca_scores, x = ~PC1, y = ~PC2, z = ~PC3, type = \"scatter3d\", mode = \"markers\",\n        color = ~stim_ordered)## Warning in RColorBrewer::brewer.pal(N, \"Set2\"): minimal value for n is 3, returning requested palette with 3 different levels\n\n## Warning in RColorBrewer::brewer.pal(N, \"Set2\"): minimal value for n is 3, returning requested palette with 3 different levels\n# data_matrix <- groupwise[groupwise$stim_ordered == \"high_stim\",c(\"tr_ordered\", \"mean_per_sub_norm_mean\")]\n# sorted_indices <- order(data_matrix$tr_ordered)\n# df_ordered <- data_matrix[sorted_indices, ]\n# pca_result <- PCA(data_matrix$mean_per_sub_norm_mean)\n# datapoints <- df$datapoints\n\n# Assuming you have a dataframe named 'data' containing the 20 data points, 'x' and 'y' values, and corresponding standard deviations 'sd'\n\n# Load the ggplot2 library\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# Create the plot\n# y = \"mean_per_sub_mean\"z\n# combined_pca <- combined_pca_scores %>%\n  # mutate(group_index = group_indices(., stim_ordered))\n\ncombined_pca <- combined_pca_scores %>%\n  group_by(stim_ordered) %>%\n  mutate(group_index = row_number())\nggplot(combined_pca, aes(x=group_index,y=PC1, group = stim_ordered, colour=stim_ordered)) +\n  stat_smooth(method=\"loess\", span=0.25, se=TRUE, aes(color=stim_ordered), alpha=0.3) +\n  theme_bw()## `geom_smooth()` using formula = 'y ~ x'\n# Assuming you have a dataframe named 'data' containing the 20 data points, 'x' and 'y' values, and corresponding standard deviations 'sd'\n\n# Load the ggplot2 library\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n\n# Create the plot\n# y = \"mean_per_sub_mean\"z\nggplot(groupwise, aes(x=tr_ordered,y=mean_per_sub_mean, group = stim_ordered, colour=stim_ordered)) +\n  stat_smooth(method=\"loess\", span=0.25, se=TRUE, aes(color=stim_ordered), alpha=0.3) +\n  theme_bw()## `geom_smooth()` using formula = 'y ~ x'\n# ggplot(data=groupwise, aes(x=tr_ordered, y=mean_per_sub_mean, ymin=se, ymax=se, fill=stim_ordered, linetype=stim_ordered)) +\n#  geom_line() +\n#  geom_ribbon(alpha=0.5)\n# Assuming you have a dataframe named 'data' containing the 20 mean data points and corresponding standard errors\n# 'x' represents the x-values (e.g., time points)\n# 'mean_y' represents the mean y-values\n# 'se_y' represents the standard errors of the mean y-values\n\n# Load the ggplot2 library\n# install.packages(\"ggplot2\")\nlibrary(ggplot2)\n# groupwise$x <- as.numeric(groupwise$x)\n#\n# # Sort the dataframe by the 'x' variable (if it's not already sorted)\n# data <- data[order(data$x), ]\n\n# Create the plot\n# Create the plot with custom span and smoothing method\nggplot(groupwise, aes(x=tr_ordered,y=mean_per_sub_mean)) +\n  geom_line() +                                   # Plot the smooth line for the mean\n  geom_ribbon(aes(ymin = mean_per_sub_mean - se, ymax = mean_per_sub_mean + se), alpha = 0.3) + # Add the ribbon for standard error\n  geom_smooth(method = \"loess\", span = 0.1, se = FALSE) +       # Add the loess smoothing curve\n  labs(x = \"X-axis Label\", y = \"Y-axis Label\", title = \"Smooth Line with Standard Error Ribbon\") +\n  theme_minimal()## `geom_smooth()` using formula = 'y ~ x'"},{"path":"taskwise-stim-effect.html","id":"dep-epoch-stim-high-cue-vs-low-cue","chapter":"16 taskwise stim effect","heading":"16.1 DEP: epoch: stim, high cue vs low cue","text":"","code":"\n# filtered_df <- subset(df, condition != \"rating\")\nfiltered_df <- df[!(df$condition == \"rating\" | df$condition == \"cue\"), ]\n\nparsed_df <- filtered_df %>%\n  separate(condition, into = c(\"cue\", \"stim\"), sep = \"_\", remove = FALSE)\n\nTR_length <- 42\n# --------------------- subset regions based on ROI ----------------------------\ndf_long <- pivot_longer(parsed_df, cols = starts_with(\"tr\"), names_to = \"tr_num\", values_to = \"tr_value\")\n\n# ----------------------------- clean factor -----------------------------------\ndf_long$tr_ordered <- factor(\n        df_long$tr_num,\n        levels = c(paste0(\"tr\", 1:TR_length))\n    )\ndf_long$cue_ordered <- factor(\n        df_long$cue,\n        levels = c(\"cueH\",\"cueL\")\n    )\n\n# --------------------------- summary statistics -------------------------------\nsubjectwise <- meanSummary(df_long,\n                                      c(\"sub\", \"tr_ordered\", \"cue_ordered\"), \"tr_value\")\ngroupwise <- summarySEwithin(\n  data = subjectwise,\n  measurevar = \"mean_per_sub\",\n  withinvars = c(\"cue_ordered\", \"tr_ordered\"),\n  idvar = \"sub\"\n)\ngroupwise$task <- taskname\n# https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n# --------------------------------- plot ---------------------------------------\nLINEIV1 = \"tr_ordered\"\nLINEIV2 = \"cue_ordered\"\nMEAN = \"mean_per_sub_norm_mean\"\nERROR = \"se\"\ndv_keyword = \"actual\"\nsorted_indices <- order(groupwise$tr_ordered)\ngroupwise_sorted <- groupwise[sorted_indices, ]\np1 = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=\"time_series\", color=c(\"red\", \"blue\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\np1 + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()"},{"path":"taskwise-stim-effect.html","id":"taskwise-cue-effect","chapter":"16 taskwise stim effect","heading":"16.2 taskwise cue effect","text":"","code":"\nroi_list <- c('rINS', 'TPJ', 'dACC', 'PHG', 'V1', 'SM', 'MT', 'RSC', 'LOC', 'FFC', 'PIT', 'pSTS', 'AIP', 'premotor')\nfor (ROI in roi_list) {\n\n    datadir = file.path(main_dir, \"analysis/fmri/spm/fir/ttl2par\")\n# taskname = 'pain'\nexclude <- \"sub-0001\"\nfilename <- paste0(\"sub-*\",  \"*roi-\", ROI, \"_tr-42.csv\")\n  common_path <- Sys.glob(file.path(datadir, \"sub-*\",  filename\n  ))\n  filter_path <- common_path[!str_detect(common_path, pattern = exclude)]\n\ndf <- do.call(\"rbind.fill\", lapply(filter_path, FUN = function(files) {\n    read.table(files, header = TRUE, sep = \",\")\n    }))\n\n\nrun_types <- c(\"pain\", \"vicarious\", \"cognitive\")\n  plot_list <- list()\n  TR_length <- 42\nfor (run_type in run_types) {\n  filtered_df <- df[!(df$condition == \"rating\" | df$condition == \"cue\" | df$runtype != run_type), ]\n\n  parsed_df <- filtered_df %>%\n    separate(condition, into = c(\"cue\", \"stim\"), sep = \"_\", remove = FALSE)\n  # --------------------- subset regions based on ROI ----------------------------\n  df_long <- pivot_longer(parsed_df, cols = starts_with(\"tr\"), names_to = \"tr_num\", values_to = \"tr_value\")\n\n  # ----------------------------- clean factor -----------------------------------\n  df_long$tr_ordered <- factor(\n          df_long$tr_num,\n          levels = c(paste0(\"tr\", 1:TR_length))\n      )\ndf_long$cue_ordered <- factor(\n        df_long$cue,\n        levels = c(\"cueH\",\"cueL\")\n    )\n\n  # --------------------------- summary statistics -------------------------------\n  subjectwise <- meanSummary(df_long,\n                                        c(\"sub\",\"tr_ordered\", \"cue_ordered\"), \"tr_value\")\n  groupwise <- summarySEwithin(\n    data = subjectwise,\n    measurevar = \"mean_per_sub\",\n    withinvars = c( \"cue_ordered\", \"tr_ordered\"),\n    idvar = \"sub\"\n  )\n  groupwise$task <- run_type\n  # https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n  # ... Rest of your data processing code ...\n\n  # subset <- groupwise[groupwise$runtype == run_type, ]\n  LINEIV1 = \"tr_ordered\"\n  LINEIV2 = \"cue_ordered\"\n  MEAN = \"mean_per_sub_norm_mean\"\n  ERROR = \"se\"\n  dv_keyword = \"actual\"\n  sorted_indices <- order(groupwise$tr_ordered)\n  groupwise_sorted <- groupwise[sorted_indices, ]\n  p1 <- plot_timeseries_bar(groupwise_sorted,\n                            LINEIV1, LINEIV2, MEAN, ERROR,\n                            xlab = \"TRs\",\n                            ylab = paste0(ROI, \" activation (A.U.)\"),\n                            ggtitle = paste0(run_type, \" time series, Epoch - stimulus\"),\n                            color =c(\"red\", \"blue\"))\n  time_points <- seq(1, 0.46 * TR_length, 0.46)\n  #p1 <- p1 + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:(7 + TR_length)])) + theme_classic()\n\n  plot_list[[run_type]] <- p1 + theme_classic()\n}\n\n  # --------------------------- plot three tasks -------------------------------\nlibrary(gridExtra)\nplot_list <- lapply(plot_list, function(plot) {\n  plot + theme(plot.margin = margin(5, 5, 5, 5))  # Adjust plot margins if needed\n})\ncombined_plot <- ggpubr::ggarrange(plot_list[[\"pain\"]],plot_list[[\"vicarious\"]],plot_list[[\"cognitive\"]],\n                  common.legend = TRUE,legend = \"bottom\", ncol = 3, nrow = 1,\n                  widths = c(3, 3, 3), heights = c(.5,.5,.5), align = \"v\")\ncombined_plot\nggsave(file.path(save_dir, paste0(\"roi-\", ROI, \"_epoch-stim_desc-highcueGTlowcue.png\")), combined_plot, width = 12, height = 4)\n}"},{"path":"taskwise-stim-effect.html","id":"epoch-stim-rating","chapter":"16 taskwise stim effect","heading":"16.3 epoch: stim, rating","text":"","code":""},{"path":"taskwise-stim-effect.html","id":"epoch-6-cond","chapter":"16 taskwise stim effect","heading":"16.4 epoch: 6 cond","text":"","code":"\n# ------------------------------------------------------------------------------\n#                       epoch stim, high cue vs low cue\n# ------------------------------------------------------------------------------\n# --------------------- subset regions based on ROI ----------------------------\n\n# ----------------------------- clean factor -----------------------------------\ndf_long$tr_ordered <- factor(\n        df_long$tr_num,\n        levels = c(paste0(\"tr\", 1:TR_length))\n    )\ndf_long$cue_ordered <- factor(\n        df_long$cue,\n        levels = c(\"cueH\", \"cueL\")\n    )\ndf_long$stim_ordered <- factor(\n        df_long$stim,\n        levels = c(\"stimH\", \"stimM\", \"stimL\")\n    )\n\ndf_long$sixcond <- factor(\n        df_long$condition,\n        levels = c(\"cueH_stimH\", \"cueL_stimH\",\n                   \"cueH_stimM\", \"cueL_stimM\",\n                   \"cueH_stimL\", \"cueL_stimL\")\n)\n# --------------------------- summary statistics -------------------------------\nsubjectwise <- meanSummary(df_long,\n                                      c(\"sub\", \"tr_ordered\", \"sixcond\"), \"tr_value\")\ngroupwise <- summarySEwithin(\n  data = subjectwise,\n  measurevar = \"mean_per_sub\",\n  withinvars = c(\"sixcond\", \"tr_ordered\"),\n  idvar = \"sub\"\n)\ngroupwise$task <- taskname\n# https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n# --------------------------------- plot ---------------------------------------\nLINEIV1 = \"tr_ordered\"\nLINEIV2 = \"sixcond\"\nMEAN = \"mean_per_sub_norm_mean\"\nERROR = \"se\"\ndv_keyword = \"actual\"\nsorted_indices <- order(groupwise$tr_ordered)\ngroupwise_sorted <- groupwise[sorted_indices, ]\np3H = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"High intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\" ), color=c(\"red\",\"#5f0f40\",\"gray\", \"gray\", \"gray\", \"gray\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\np3H + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\np3H + theme_classic()\np3M = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"Medium intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\"), color=c(\"#d6d6d6\",\"#d6d6d6\",\"#bc3908\", \"#f6aa1c\", \"gray\", \"gray\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\np3M + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\np3M + theme_classic()\np3L = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"Low intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\"), color=c(\"gray\",\"gray\",\"gray\", \"gray\", \"#2541b2\", \"#00a6fb\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\np3L + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\np3L + theme_classic()"},{"path":"taskwise-6-cond-effect.html","id":"taskwise-6-cond-effect","chapter":"17 taskwise 6 cond effect","heading":"17 taskwise 6 cond effect","text":"","code":"\n# ------------------------------------------------------------------------------\n#                       epoch stim, high cue vs low cue\n# ------------------------------------------------------------------------------\n# --------------------- subset regions based on ROI ----------------------------\nrun_types <- c(\"pain\", \"vicarious\", \"cognitive\")\n\n  TR_length <- 42\nfor (run_type in run_types) {\n  filtered_df <- df[!(df$condition == \"rating\" | df$condition == \"cue\" | df$runtype != run_type), ]\nplot_list <- list()\n\n  parsed_df <- filtered_df %>%\n    separate(condition, into = c(\"cue\", \"stim\"), sep = \"_\", remove = FALSE)\n  # --------------------- subset regions based on ROI ----------------------------\n  df_long <- pivot_longer(parsed_df, cols = starts_with(\"tr\"), names_to = \"tr_num\", values_to = \"tr_value\")\n\n# ----------------------------- clean factor -----------------------------------\ndf_long$tr_ordered <- factor(\n        df_long$tr_num,\n        levels = c(paste0(\"tr\", 1:TR_length))\n    )\ndf_long$cue_ordered <- factor(\n        df_long$cue,\n        levels = c(\"cueH\", \"cueL\")\n    )\ndf_long$stim_ordered <- factor(\n        df_long$stim,\n        levels = c(\"stimH\", \"stimM\", \"stimL\")\n    )\n\ndf_long$sixcond <- factor(\n        df_long$condition,\n        levels = c(\"cueH_stimH\", \"cueL_stimH\",\n                   \"cueH_stimM\", \"cueL_stimM\",\n                   \"cueH_stimL\", \"cueL_stimL\")\n)\n# --------------------------- summary statistics -------------------------------\nsubjectwise <- meanSummary(df_long,\n                                      c(\"sub\", \"tr_ordered\", \"sixcond\"), \"tr_value\")\ngroupwise <- summarySEwithin(\n  data = subjectwise,\n  measurevar = \"mean_per_sub\",\n  withinvars = c(\"sixcond\", \"tr_ordered\"),\n  idvar = \"sub\"\n)\ngroupwise$task <- taskname\n# https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n# --------------------------------- plot ---------------------------------------\nLINEIV1 = \"tr_ordered\"\nLINEIV2 = \"sixcond\"\nMEAN = \"mean_per_sub_norm_mean\"\nERROR = \"se\"\ndv_keyword = \"actual\"\nsorted_indices <- order(groupwise$tr_ordered)\ngroupwise_sorted <- groupwise[sorted_indices, ]\np3H = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"High intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\" ), color=c(\"red\",\"#5f0f40\",\"gray\", \"gray\", \"gray\", \"gray\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\n# p3H + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\np3H + theme_classic()\nplot_list[[\"H\"]] <- p3H + theme_classic()\n\np3M = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"Medium intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\"), color=c(\"#d6d6d6\",\"#d6d6d6\",\"#bc3908\", \"#f6aa1c\", \"gray\", \"gray\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\n# p3M + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\nplot_list[[\"M\"]] <- p3M + theme_classic()\n\np3L = plot_timeseries_bar(groupwise,\n               LINEIV1, LINEIV2, MEAN, ERROR,  xlab = \"Runs\" , ylab= \"Epoch: stimulus, High cue vs. Low cue\", ggtitle=paste0(\"Low intensity - Low cue vs. High cue (N = \", unique(groupwise$N), \")\"), color=c(\"gray\",\"gray\",\"gray\", \"gray\", \"#2541b2\", \"#00a6fb\"))\ntime_points <- seq(1, 0.46 * TR_length, 0.46)\n# p3L + scale_x_discrete(labels = setNames(time_points, colnames(df_long)[7:7+TR_length]))+ theme_classic()\nplot_list[[\"L\"]] <- p3L + theme_classic()\n\n\n  # --------------------------- plot three tasks -------------------------------\nlibrary(gridExtra)\nplot_list <- lapply(plot_list, function(plot) {\n  plot + theme(plot.margin = margin(5, 5, 5, 5))  # Adjust plot margins if needed\n})\ncombined_plot <- ggpubr::ggarrange(plot_list[[\"H\"]],plot_list[[\"M\"]],plot_list[[\"L\"]],\n                  common.legend = FALSE,legend = \"bottom\", ncol = 3, nrow = 1,\n                  widths = c(3, 3, 3), heights = c(.5,.5,.5), align = \"v\")\ncombined_plot\nggsave(file.path(save_dir, paste0(\"taskwise-\",run_type, \"_epoch-stim_desc-stimcuecomparison.png\")), combined_plot, width = 12, height = 4)\n}"},{"path":"fmritimeseries_tt1.html","id":"fmritimeseries_tt1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18 fMRI :: FIR ~ task TTL1","text":"purpose notebook plot BOLD timeseries SPM FIR model.\nTODOload tsvconcatenateper time column, calculate mean varianceplot","code":""},{"path":"fmritimeseries_tt1.html","id":"references","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.1 references","text":"https://stackoverflow.com/questions/29402528/append-data-frames-together----loop/29419402","code":"\nplot_timeseries_onefactor <-\n  function(df, iv1, mean, error, xlab, ylab, ggtitle, color) {\n    n_points <- 100 # Number of points for interpolation\n\n    g <- ggplot(\n      data = df,\n      aes(\n        x = .data[[iv1]],\n        y = .data[[mean]],\n        group = 1,\n        color = color\n      ),\n      cex.lab = 1.5,\n      cex.axis = 2,\n      cex.main = 1.5,\n      cex.sub = 1.5\n    ) +\n      geom_errorbar(aes(\n        ymin = (.data[[mean]] - .data[[error]]),\n        ymax = (.data[[mean]] + .data[[error]]),\n        color = color\n      ),\n      width = .1,\n      alpha = 0.8) +\n      geom_line() +\n      geom_point(color = color) +\n      ggtitle(ggtitle) +\n      xlab(xlab) +\n      ylab(ylab) +\n      theme_classic() +\n      theme(aspect.ratio = .6) +\n      expand_limits(x = 3.25) +\n      scale_color_manual(\"\",\n                         values = color) +\n      # theme(\n      #   legend.position = c(.99, .99),\n      #   legend.justification = c(\"right\", \"top\"),\n      #   legend.box.just = \"right\",\n      #   legend.margin = margin(6, 6, 6, 6)\n      # ) +\n      # theme(legend.key = element_rect(fill = \"white\", colour = \"white\")) +\n      theme_bw()\n\n    return(g)\n  }\nplot_timeseries_bar_SANDBOX <-\n  function(df, iv1, iv2, mean, error, xlab, ylab, ggtitle, color) {\n    n_points <- 100 # Number of points for interpolation\n\n    ## Removing \"tr\" from the column values\n    df[[iv1]] <- as.numeric(sub(\"tr\", \"\", df[[iv1]]))\n\n    g <- ggplot(\n      data = df,\n      aes(\n        x = .data[[iv1]],\n        y = .data[[mean]],\n        group = factor(.data[[iv2]]),\n        color = factor(.data[[iv2]])\n      ),\n      cex.lab = 1.5,\n      cex.axis = 2,\n      cex.main = 1.5,\n      cex.sub = 1.5\n    ) +\n      geom_errorbar(aes(\n        ymin = (.data[[mean]] - .data[[error]]),\n        ymax = (.data[[mean]] + .data[[error]]),\n        fill =  factor(.data[[iv2]])\n      ),\n      width = .1,\n      alpha = 0.8) +\n      geom_line() +\n      geom_point() +\n      ggtitle(ggtitle) +\n      xlab(xlab) +\n      ylab(ylab) +\n      theme_classic() +\n      expand_limits(x = 3.25) +\n      scale_color_manual(\"\",\n                         values = color) +\n      scale_fill_manual(\"\",\n                        values = color) +\n      theme(\n        aspect.ratio = .6,\n        text = element_text(size = 20),\n        axis.title.x = element_text(size = 24),\n        axis.title.y = element_text(size = 24),\n        legend.position = c(.99, .99),\n        legend.justification = c(\"right\", \"top\"),\n        legend.box.just = \"right\",\n        legend.margin = margin(6, 6, 6, 6)\n      ) +\n      theme(legend.key = element_rect(fill = \"white\", colour = \"white\")) +\n      theme_bw()\n\n    return(g)\n  }"},{"path":"fmritimeseries_tt1.html","id":"parameters","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"parameters","text":"","code":"\nmain_dir <- dirname(dirname(getwd()))\ndatadir <- file.path(main_dir, \"analysis/fmri/nilearn/glm/fir\")\nanalysis_folder <- paste0(\"model52_iv-6cond_dv-firglasserSPM_ttl1\")\nanalysis_dir <-\n  file.path(main_dir,\n            \"analysis\",\n            \"mixedeffect\",\n            analysis_folder,\n            as.character(Sys.Date()))\ndir.create(analysis_dir,\n           showWarnings = FALSE,\n           recursive = TRUE)\nsave_dir <- analysis_dir"},{"path":"fmritimeseries_tt1.html","id":"taskwise-stim-effect-1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.2 taskwise stim effect","text":", list ROIs. Per ROI, FIR values pain, vicarious, cognitive tasks.\n’ll aggregate data per ROI plot time series 3 tasks.","code":"\nroi_list <- c(\"dACC\", \"PHG\", \"V1\", \"SM\", \"MT\", \"RSC\", \"LOC\", \"FFC\", \"PIT\", \"pSTS\", \"AIP\", \"premotor\") # 'rINS', 'TPJ',\nrun_types <- c(\"pain\", \"vicarious\", \"cognitive\")\nplot_list <- list()\nTR_length <- 42\n\n\nfor (ROI in roi_list) {\n  main_dir <- dirname(dirname(getwd()))\n  datadir <- file.path(main_dir, \"analysis/fmri/spm/fir/ttl1par\")\n  taskname <- \"pain\"\n  exclude <- \"sub-0001\"\n  filename <- paste0(\"sub-*\", \"*roi-\", ROI, \"_tr-42.csv\")\n  common_path <- Sys.glob(file.path(datadir, \"sub-*\", filename))\n  filter_path <-\n    common_path[!str_detect(common_path, pattern = exclude)]\n\n  df <-\n    do.call(\"rbind.fill\", lapply(\n      filter_path,\n      FUN = function(files) {\n        read.table(files, header = TRUE, sep = \",\")\n      }\n    ))\n\n  for (run_type in run_types) {\n    print(run_type)\n    filtered_df <-\n      df[!(df$condition == \"rating\" |\n             df$condition == \"cue\" | df$runtype != run_type),]\n\n    parsed_df <- filtered_df %>%\n      separate(\n        condition,\n        into = c(\"cue\", \"stim\"),\n        sep = \"_\",\n        remove = FALSE\n      )\n    # --------------------------------------------------------------------------\n    #                           0) subset dataframe based on ROI\n    # --------------------------------------------------------------------------\n    df_long <-\n      pivot_longer(\n        parsed_df,\n        cols = starts_with(\"tr\"),\n        names_to = \"tr_num\",\n        values_to = \"tr_value\"\n      )\n\n    # --------------------------------------------------------------------------\n    #                           1) clean factor\n    # --------------------------------------------------------------------------\n    df_long$tr_ordered <- factor(df_long$tr_num,\n                                 levels = c(paste0(\"tr\", 1:TR_length)))\n    df_long$stim_ordered <- factor(df_long$stim,\n                                   levels = c(\"stimH\", \"stimM\", \"stimL\"))\n    # --------------------------------------------------------------------------\n    #                             2) summary statistics\n    # --------------------------------------------------------------------------\n    subjectwise <- meanSummary(df_long,\n                               c(\"sub\", \"tr_ordered\", \"stim_ordered\"),\n                               \"tr_value\")\n    groupwise <- summarySEwithin(\n      data = subjectwise,\n      measurevar = \"mean_per_sub\",\n      withinvars = c(\"stim_ordered\", \"tr_ordered\"),\n      idvar = \"sub\"\n    )\n    groupwise$task <- run_type\n    # https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n    LINEIV1 <- \"tr_ordered\"\n    LINEIV2 <- \"stim_ordered\"\n    MEAN <- \"mean_per_sub_norm_mean\"\n    ERROR <- \"se\"\n    dv_keyword <- \"actual\"\n    sorted_indices <- order(groupwise$tr_ordered)\n    groupwise_sorted <- groupwise[sorted_indices,]\n\n    # --------------------------------------------------------------------------\n    #                             3) plot per run\n    # --------------------------------------------------------------------------\n    p1 <- plot_timeseries_bar_SANDBOX(\n      groupwise_sorted,\n      LINEIV1,\n      LINEIV2,\n      MEAN,\n      ERROR,\n      xlab = \"TRs\",\n      ylab = paste0(ROI, \" activation (A.U.)\"),\n      ggtitle = paste0(\n        ROI,\n        \": \",\n        run_type,\n        \" (N = \",\n        length(unique(subjectwise$sub)),\n        \") time series, Epoch - stimulus\"\n      ),\n      color = c(\"#5f0f40\", \"#ae2012\", \"#fcbf49\")\n    )\n    time_points <- seq(1, 0.46 * TR_length, 0.46)\n    p1 <- p1 +\n      annotate(\n        \"rect\",\n        xmin = 0,\n        xmax = 20,\n        ymin = min(df[[MEAN]], na.rm = TRUE) - 5,\n        ymax = max(df[[MEAN]], na.rm = TRUE) + 5,\n        fill = \"grey\",\n        alpha = 0.2\n      )\n    plot_list[[run_type]] <- p1 + theme_classic()\n\n  }\n\n  # --------------------------------------------------------------------------\n  #                             4) plot three tasks per ROI\n  # --------------------------------------------------------------------------\n  library(gridExtra)\n  plot_list <- lapply(plot_list, function(plot) {\n    plot + theme(plot.margin = margin(5, 5, 5, 5)) # Adjust plot margins if needed\n  })\n  combined_plot <- ggpubr::ggarrange(\n    plot_list[[\"pain\"]],\n    plot_list[[\"vicarious\"]],\n    plot_list[[\"cognitive\"]],\n    common.legend = TRUE,\n    legend = \"bottom\",\n    ncol = 3,\n    nrow = 1,\n    widths = c(3, 3, 3),\n    heights = c(.5, .5, .5),\n    align = \"v\"\n  )\n  print(combined_plot)\n  ggsave(file.path(\n    save_dir,\n    paste0(\"roi-\", ROI, \"_epoch-stim_desc-highstimGTlowstim.png\")\n  ),\n  combined_plot,\n  width = 12,\n  height = 4)\n}## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## \n## Attaching package: 'gridExtra'## The following object is masked from 'package:dplyr':\n## \n##     combine## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"pain\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"vicarious\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf## [1] \"cognitive\"## Warning in geom_errorbar(aes(ymin = (.data[[mean]] - .data[[error]]), ymax =\n## (.data[[mean]] + : Ignoring unknown aesthetics: fill## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf\np1 + annotate(\"rect\", xmin = 0, xmax = 10, ymin = min(df[[MEAN]], na.rm = TRUE) - 5, ymax = max(df[[MEAN]], na.rm = TRUE) + 5, fill = \"grey\", alpha = 0.2)## Warning in min(df[[MEAN]], na.rm = TRUE): no non-missing arguments to min;\n## returning Inf## Warning in max(df[[MEAN]], na.rm = TRUE): no non-missing arguments to max;\n## returning -Inf"},{"path":"fmritimeseries_tt1.html","id":"pca-subjectwise-1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.2.1 PCA subjectwise","text":"","code":"\nrun_types <- c(\"pain\")\nfor (run_type in run_types) {\n  print(run_type)\n  filtered_df <-\n    df[!(df$condition == \"rating\" |\n           df$condition == \"cue\" | df$runtype != run_type),]\n\n  parsed_df <- filtered_df %>%\n    separate(\n      condition,\n      into = c(\"cue\", \"stim\"),\n      sep = \"_\",\n      remove = FALSE\n    )\n  # ------------------------------------------------------------------------------\n  #                       subset regions based on ROI\n  # ------------------------------------------------------------------------------\n  df_long <-\n    pivot_longer(\n      parsed_df,\n      cols = starts_with(\"tr\"),\n      names_to = \"tr_num\",\n      values_to = \"tr_value\"\n    )\n\n  # ------------------------------------------------------------------------------\n  #                             clean factor\n  # ------------------------------------------------------------------------------\n  df_long$tr_ordered <- factor(df_long$tr_num,\n                               levels = c(paste0(\"tr\", 1:TR_length)))\n  df_long$stim_ordered <- factor(df_long$stim,\n                                 levels = c(\"stimH\", \"stimM\", \"stimL\"))\n\n  # ------------------------------------------------------------------------------\n  #                            summary stats\n  # ------------------------------------------------------------------------------\n  subjectwise <- meanSummary(df_long,\n                             c(\"sub\", \"tr_ordered\", \"stim_ordered\"), \"tr_value\")\n\n\n  # ------------------------------------------------------------------------------\n  #                             convert dataframe long to wide\n  # ------------------------------------------------------------------------------\n\n  df_wide <- pivot_wider(\n    subjectwise,\n    id_cols = c(\"tr_ordered\", \"stim_ordered\"),\n    names_from = c(\"sub\"),\n    values_from = \"mean_per_sub\"\n  )\n\n  stim_high.df <- df_wide[df_wide$stim_ordered == \"stimH\",]\n  stim_med.df <- df_wide[df_wide$stim_ordered == \"stimM\",]\n  stim_low.df <- df_wide[df_wide$stim_ordered == \"stimL\",]\n\n  meanhighdf <-\n    data.frame(subset(stim_high.df, select = 3:(ncol(stim_high.df) - 1)))\n  high.pca_result <- prcomp(meanhighdf)\n  high.pca_scores <- as.data.frame(high.pca_result$x)\n  # Access the proportion of variance explained by each principal component\n  high.variance_explained <-\n    high.pca_result$sdev ^ 2 / sum(high.pca_result$sdev ^ 2)\n  plot(high.variance_explained)\n  # Access the standard deviations of each principal component\n  high.stdev <- high.pca_result$sdev\n\n  meanmeddf <-\n    data.frame(subset(stim_med.df, select = 3:(ncol(stim_med.df) - 1)))\n  med.pca <- prcomp(meanmeddf)\n  med.pca_scores <- as.data.frame(med.pca$x)\n\n  meanlowdf <-\n    data.frame(subset(stim_low.df, select = 3:(ncol(stim_low.df) - 1)))\n  low.pca <- prcomp(meanlowdf)\n  low.pca_scores <- as.data.frame(low.pca$x)\n\n  combined_pca_scores <-\n    rbind(high.pca_scores, med.pca_scores, low.pca_scores)\n\n  # Add a new column to indicate the stim_ordered category (high_stim or low_stim)\n  combined_pca_scores$stim_ordered <- c(rep(\"high_stim\", nrow(high.pca_scores)),\n                                        rep(\"med_stim\", nrow(med.pca_scores)),\n                                        rep(\"low_stim\", nrow(low.pca_scores)))\n\n  # ------------------------------------------------------------------------------\n  #                             3d PCA plot\n  # ------------------------------------------------------------------------------\n  plot_ly(\n    combined_pca_scores,\n    x = ~ PC1,\n    y = ~ PC2,\n    z = ~ PC3,\n    type = \"scatter3d\",\n    mode = \"markers\",\n    color = ~ stim_ordered\n  )\n}## [1] \"pain\"\nplot_ly(\n  combined_pca_scores,\n  x = ~ PC1,\n  y = ~ PC2,\n  z = ~ PC3,\n  type = \"scatter3d\",\n  mode = \"markers\",\n  color = ~ stim_ordered\n)"},{"path":"fmritimeseries_tt1.html","id":"pca-groupwise-1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.2.2 PCA groupwise","text":"","code":"\n# ------------------------------------------------------------------------------\n#                       data formatting\n# ------------------------------------------------------------------------------\n\n# Convert the dataframe to wide format\ndf_wide.group <- pivot_wider(\n  subjectwise,\n  id_cols = c(\"tr_ordered\", \"stim_ordered\"),\n  names_from = \"sub\",\n  values_from = \"mean_per_sub\"\n)\n\n# Split the data into two subsets based on the 'stim_ordered' value\n# One for 'stimH' and another for 'stimL'\nstim_high.df <- df_wide[df_wide$stim_ordered == \"stimH\",]\nstim_low.df <- df_wide[df_wide$stim_ordered == \"stimL\",]\n\n# Prepare data for PCA analysis by selecting relevant columns\n# Exclude the first two columns and the last column\nmeanhighdf <-\n  data.frame(subset(stim_high.df, select = 3:(ncol(stim_high.df) - 1)))\nmeanlowdf <-\n  data.frame(subset(stim_low.df, select = 3:(ncol(stim_low.df) - 1)))\n\n\n# ------------------------------------------------------------------------------\n#                      Principal Component Analysis (PCA)\n# ------------------------------------------------------------------------------\nhigh.pca <- prcomp(meanhighdf) # Perform Principal Component Analysis (PCA)\nhigh.pca_scores <- as.data.frame(high.pca$x) # Extract PCA scores\n\n# Repeat the process for the low stimulus data\nlow.pca <- prcomp(meanlowdf)\nlow.pca_scores <- as.data.frame(low.pca$x)\n\ncombined_pca_scores <- rbind(high.pca_scores, low.pca_scores)\n\n# Add a new column to indicate the 'stim_ordered' category (high_stim or low_stim)\n# This helps in distinguishing the groups in the plot\ncombined_pca_scores$stim_ordered <-\n  c(rep(\"high_stim\", nrow(high.pca_scores)), rep(\"low_stim\", nrow(low.pca_scores)))\n\n# ------------------------------------------------------------------------------\n#                      plot 3D scatter plot of the PCA scores\n# ------------------------------------------------------------------------------\n# The points are colored based on their stim_ordered category\nplot_ly(\n  combined_pca_scores,\n  x = ~ PC1,\n  y = ~ PC2,\n  z = ~ PC3,\n  type = \"scatter3d\",\n  mode = \"markers\",\n  color = ~ stim_ordered\n)## Warning in RColorBrewer::brewer.pal(N, \"Set2\"): minimal value for n is 3, returning requested palette with 3 different levels\n\n## Warning in RColorBrewer::brewer.pal(N, \"Set2\"): minimal value for n is 3, returning requested palette with 3 different levels\n# ------------------------------------------------------------------------------\n#                      plot 2D group plot\n# ------------------------------------------------------------------------------\n# Create a 2D plot with smoothed lines for each stim_ordered group\ncombined_pca <- combined_pca_scores %>%\n  group_by(stim_ordered) %>%\n  mutate(group_index = row_number())\nggplot(combined_pca,\n       aes(\n         x = group_index,\n         y = PC1,\n         group = stim_ordered,\n         colour = stim_ordered\n       )) +\n  stat_smooth(\n    method = \"loess\",\n    span = 0.25,\n    se = TRUE,\n    aes(color = stim_ordered),\n    alpha = 0.3\n  ) +\n  theme_bw()## `geom_smooth()` using formula = 'y ~ x'\n# Create the plot\n\nggplot(\n  groupwise,\n  aes(\n    x = tr_ordered,\n    y = mean_per_sub_mean,\n    group = stim_ordered,\n    colour = stim_ordered\n  )\n) +\n  stat_smooth(\n    method = \"loess\",\n    span = 0.25,\n    se = TRUE,\n    aes(color = stim_ordered),\n    alpha = 0.3\n  ) +\n  theme_bw()## `geom_smooth()` using formula = 'y ~ x'\n# Create the plot\n# Create the plot with custom span and smoothing method\nggplot(groupwise, aes(x = tr_ordered, y = mean_per_sub_mean)) +\n  geom_line() + # Plot the smooth line for the mean\n  geom_ribbon(aes(ymin = mean_per_sub_mean - se, ymax = mean_per_sub_mean + se),\n              alpha = 0.3) + # Add the ribbon for standard error\n  geom_smooth(method = \"loess\", span = 0.1, se = FALSE) + # Add the loess smoothing curve\n  labs(x = \"X-axis Label\", y = \"Y-axis Label\", title = \"Smooth Line with Standard Error Ribbon\") +\n  theme_minimal()## `geom_smooth()` using formula = 'y ~ x'"},{"path":"fmritimeseries_tt1.html","id":"taskwise-cue-effect-1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.3 taskwise cue effect","text":"","code":"\nroi_list <- c(\"dACC\", \"PHG\", \"V1\", \"SM\", \"MT\", \"RSC\", \"LOC\", \"FFC\", \"PIT\", \"pSTS\", \"AIP\", \"premotor\") # 'rINS', 'TPJ',\nfor (ROI in roi_list) {\n  datadir <- file.path(main_dir, \"analysis/fmri/spm/fir/ttl2par\")\n  # taskname = 'pain'\n  exclude <- \"sub-0001\"\n  filename <- paste0(\"sub-*\", \"*roi-\", ROI, \"_tr-42.csv\")\n  common_path <- Sys.glob(file.path(datadir, \"sub-*\", filename))\n  filter_path <-\n    common_path[!str_detect(common_path, pattern = exclude)]\n\n  df <-\n    do.call(\"rbind.fill\", lapply(\n      filter_path,\n      FUN = function(files) {\n        read.table(files, header = TRUE, sep = \",\")\n      }\n    ))\n\n\n  run_types <- c(\"pain\", \"vicarious\", \"cognitive\")\n  plot_list <- list()\n  TR_length <- 42\n  for (run_type in run_types) {\n    filtered_df <-\n      df[!(df$condition == \"rating\" |\n             df$condition == \"cue\" | df$runtype != run_type),]\n\n    parsed_df <- filtered_df %>%\n      separate(\n        condition,\n        into = c(\"cue\", \"stim\"),\n        sep = \"_\",\n        remove = FALSE\n      )\n\n    # --------------------------------------------------------------------------\n    #                        subset regions based on ROI\n    # --------------------------------------------------------------------------\n    df_long <-\n      pivot_longer(\n        parsed_df,\n        cols = starts_with(\"tr\"),\n        names_to = \"tr_num\",\n        values_to = \"tr_value\"\n      )\n\n    # --------------------------------------------------------------------------\n    #                             clean factor\n    # --------------------------------------------------------------------------\n    df_long$tr_ordered <- factor(df_long$tr_num,\n                                 levels = c(paste0(\"tr\", 1:TR_length)))\n    df_long$cue_ordered <- factor(df_long$cue,\n                                  levels = c(\"cueH\", \"cueL\"))\n\n    # --------------------------------------------------------------------------\n    #                             summary statistics\n    # --------------------------------------------------------------------------\n    subjectwise <- meanSummary(df_long,\n                               c(\"sub\", \"tr_ordered\", \"cue_ordered\"), \"tr_value\")\n    groupwise <- summarySEwithin(\n      data = subjectwise,\n      measurevar = \"mean_per_sub\",\n      withinvars = c(\"cue_ordered\", \"tr_ordered\"),\n      idvar = \"sub\"\n    )\n    groupwise$task <- run_type\n    # https://stackoverflow.com/questions/29402528/append-data-frames-together-in-a-for-loop/29419402\n\n    LINEIV1 <- \"tr_ordered\"\n    LINEIV2 <- \"cue_ordered\"\n    MEAN <- \"mean_per_sub_norm_mean\"\n    ERROR <- \"se\"\n    dv_keyword <- \"actual\"\n    sorted_indices <- order(groupwise$tr_ordered)\n    groupwise_sorted <- groupwise[sorted_indices,]\n    p1 <- plot_timeseries_bar(\n      groupwise_sorted,\n      LINEIV1,\n      LINEIV2,\n      MEAN,\n      ERROR,\n      xlab = \"TRs\",\n      ylab = paste0(ROI, \" activation (A.U.)\"),\n      ggtitle = paste0(run_type, \" time series, Epoch - stimulus\"),\n      color = c(\"red\", \"blue\")\n    )\n    time_points <- seq(1, 0.46 * TR_length, 0.46)\n\n    plot_list[[run_type]] <- p1 + theme_classic()\n  }\n\n  # ----------------------------------------------------------------------------\n  #                             plot three tasks\n  # ----------------------------------------------------------------------------\n  library(gridExtra)\n  plot_list <- lapply(plot_list, function(plot) {\n    plot + theme(plot.margin = margin(5, 5, 5, 5)) # Adjust plot margins if needed\n  })\n  combined_plot <-\n    ggpubr::ggarrange(\n      plot_list[[\"pain\"]],\n      plot_list[[\"vicarious\"]],\n      plot_list[[\"cognitive\"]],\n      common.legend = TRUE,\n      legend = \"bottom\",\n      ncol = 3,\n      nrow = 1,\n      widths = c(3, 3, 3),\n      heights = c(.5, .5, .5),\n      align = \"v\"\n    )\n\n  print(combined_plot)\n  ggsave(file.path(\n    save_dir,\n    paste0(\"roi-\", ROI, \"_epoch-cue_desc-highcueGTlowcue.png\")\n  ),\n  combined_plot,\n  width = 12,\n  height = 4)\n}"},{"path":"fmritimeseries_tt1.html","id":"epoch-stim-rating-1","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.3.1 epoch: stim, rating","text":"","code":""},{"path":"fmritimeseries_tt1.html","id":"main-sandbox-6-condition-in-three-panels.-per-task.-per-roi","chapter":"18 fMRI :: FIR ~ task TTL1","heading":"18.4 MAIN SANDBOX: 6 condition in three panels. per task. per ROI","text":"","code":"\n# A function to plot data\nplot_data <- function(groupwise, iv1, iv2, mean, error, xlab, ylab, ggtitle, run_type, colors) {\n  p <- plot_timeseries_bar(\n    groupwise,\n    \"tr_ordered\",\n    \"sixcond\",\n    \"mean_per_sub_norm_mean\",\n    \"se\",\n    xlab = \"TRs\",\n    ylab = \"Epoch: stimulus, High cue vs. Low cue\",\n    ggtitle = paste0(run_type, \" intensity (N = \", unique(groupwise$N), \")\"),\n    color_mapping = colors,\n    show_legend = FALSE\n  )\n  p + theme_classic()\n}\n#' Calculate Point Size Proportionally\n#'\n#' This function calculates point size proportionally based on a base point size and figure dimensions\n#' (width and height). It can be used to adjust the point size in plots to maintain proportionality\n#' with varying figure sizes.\n#'\n#' @param point_size_base The base point size for `geom_points`.\n#' @param figure_width The width of the figure in which the point size needs to be adjusted.\n#' @param figure_height The height of the figure in which the point size needs to be adjusted.\n#'\n#' @return The calculated point size.\n#'\n#' @examples\n#' # Define your point size base\n#' point_size_base <- 3\n#'\n#' # Define your figure dimensions (width and height)\n#' figure_width <- 12\n#' figure_height <- 8\n#'\n#' # Calculate the point size using the function\n#' POINT_SIZE <- calculate_point_size(point_size_base, figure_width, figure_height)\n#'\n#' # Apply the point size to your plot elements\n#' plot + geom_point(size = POINT_SIZE)\n#'\n#' @export\ncalculate_point_size <- function(figure_width, figure_height, point_size_base = 5) {\n  scaling_factor <- min(figure_width, figure_height) / point_size_base\n  return(scaling_factor)\n}\n# ------------------------------------------------------------------------------\n#                       epoch stim, high cue vs low cue\n# ------------------------------------------------------------------------------\n\nrun_types <- c(\"pain\", \"vicarious\", \"cognitive\")\nall_plots <- list()\nTR_length <- 42\nfor (roi in c(\"dACC\", \"PHG\")) {\n  plot_list_per_roi <- list()\n  for (run_type in run_types) {\n    filtered_df <-\n      df[!(\n        df$condition == \"rating\" |\n          df$condition == \"cue\" |\n          df$runtype != run_type | df$ROI == roi\n      ),]\n    plot_list <- list()\n\n    parsed_df <- filtered_df %>%\n      separate(\n        condition,\n        into = c(\"cue\", \"stim\"),\n        sep = \"_\",\n        remove = FALSE\n      )\n    # --------------------- subset regions based on ROI ----------------------------\n    df_long <-\n      pivot_longer(\n        parsed_df,\n        cols = starts_with(\"tr\"),\n        names_to = \"tr_num\",\n        values_to = \"tr_value\"\n      )\n\n    # ----------------------------------------------------------------------------\n    #                             clean factor\n    # ----------------------------------------------------------------------------\n    df_long$tr_ordered <- factor(df_long$tr_num,\n                                 levels = c(paste0(\"tr\", 1:TR_length)))\n    df_long$cue_ordered <- factor(df_long$cue,\n                                  levels = c(\"cueH\", \"cueL\"))\n    df_long$stim_ordered <- factor(df_long$stim,\n                                   levels = c(\"stimH\", \"stimM\", \"stimL\"))\n\n    df_long$sixcond <- factor(\n      df_long$condition,\n      levels = c(\n        \"cueH_stimH\",\n        \"cueL_stimH\",\n        \"cueH_stimM\",\n        \"cueL_stimM\",\n        \"cueH_stimL\",\n        \"cueL_stimL\"\n      )\n    )\n\n    # ------------------------------------------------------------------------------\n    #                             summary statistics\n    # ------------------------------------------------------------------------------\n    subjectwise <- meanSummary(df_long,\n                               c(\"sub\", \"tr_ordered\", \"sixcond\"), \"tr_value\")\n    groupwise <- summarySEwithin(\n      data = subjectwise,\n      measurevar = \"mean_per_sub\",\n      withinvars = c(\"sixcond\", \"tr_ordered\"),\n      idvar = \"sub\"\n    )\n    groupwise$task <- taskname\n\n    # ----------------------------------------------------------------------------\n    #                             plot parameters\n    # ----------------------------------------------------------------------------\n    # convert TR orders to numeric values\n    tr_numbers <-\n      as.numeric(sub(\"tr\", \"\", as.character(groupwise$tr_ordered)))\n    tr_sequence <- (tr_numbers - 1) * 0.46\n    groupwise$tr_sequence <- tr_sequence\n\n    LINEIV1 <- \"tr_sequence\"\n    LINEIV2 <- \"sixcond\"\n    MEAN <- \"mean_per_sub_norm_mean\"\n    ERROR <- \"se\"\n    dv_keyword <- \"actual\"\n    sorted_indices <- order(groupwise$tr_ordered)\n    groupwise_sorted <- groupwise[sorted_indices,]\n    XLAB <- \"TRs\"\n    YLAB <- \"Stimulus Epoch High vs. Low cue\"\n    HIGHSTIM_COLOR <- c(\n      \"cueH_stimH\" = \"red\",\n      \"cueL_stimH\" = \"#5f0f40\",\n      \"cueH_stimM\" = \"gray\",\n      \"cueL_stimM\" = \"gray\",\n      \"cueH_stimL\" = \"gray\",\n      \"cueL_stimL\" = \"gray\"\n    )\n    MEDSTIM_COLOR <- c(\n      \"cueH_stimH\" = \"gray\",\n      \"cueL_stimH\" = \"gray\",\n      \"cueH_stimM\" = \"#bc3908\",\n      \"cueL_stimM\" = \"#f6aa1c\",\n      \"cueH_stimL\" = \"gray\",\n      \"cueL_stimL\" = \"gray\"\n    )\n    LOWSTIM_COLOR <- c(\n      \"cueH_stimH\" = \"gray\",\n      \"cueL_stimH\" = \"gray\",\n      \"cueH_stimM\" = \"gray\",\n      \"cueL_stimM\" = \"gray\",\n      \"cueH_stimL\" = \"#2541b2\",\n      \"cueL_stimL\" = \"#00a6fb\"\n    )\n\n    AXIS_FONTSIZE <- 10\n    COMMONAXIS_FONTSIZE <- 15\n    TITLE_FONTSIZE <- 20\n    figure_width <- 10  # Adjust this to your actual figure width\n    figure_height <- 10  # Adjust this to your actual figure height\n    GEOMPOINT_SIZE <- calculate_point_size(figure_width, figure_height)\n\n    # ----------------------------------------------------------------------------\n    #                             plot intensity per task\n    # ----------------------------------------------------------------------------\n    p3H <- plot_timeseries_bar(\n      groupwise,\n      LINEIV1,\n      LINEIV2,\n      MEAN,\n      ERROR,\n      XLAB,\n      YLAB,\n      ggtitle = paste0(tools::toTitleCase(run_type), \"\\n High intensity (N = \", unique(groupwise$N), \")\"),\n      color_mapping = HIGHSTIM_COLOR,\n      show_legend = FALSE,\n      geompoint_size = GEOMPOINT_SIZE\n    )\n\n    # Assuming tr_sequence is correct and has been added to groupwise\n    # Calculate breaks to show every 10th TR\n    breaks_to_show <-\n      seq(0, max(groupwise$tr_sequence), by = 0.46 * 5)\n    labels_to_show <-\n      seq(0, max(groupwise$tr_sequence), by = 0.46 * 5)\n    # It's important to ensure that both 'breaks_to_show' and 'labels_to_show' have the same length\n    # If the lengths differ, we need to adjust them so they match\n    if (length(breaks_to_show) != length(labels_to_show)) {\n      # Assuming you want to keep all the breaks and just adjust the labels\n      labels_to_show <- labels_to_show[seq_along(breaks_to_show)]\n    }\n\n    # High intensity\n    plot_list[[\"H\"]] <- p3H +\n      scale_x_continuous(\n        breaks = breaks_to_show,\n        # Set breaks at every 10th point\n        labels = labels_to_show,\n        # Use the calculated labels\n        limits = range(groupwise$tr_sequence)  # Set the limits based on the sequence\n      ) +\n      theme_classic()\n\n    # Medium intensity\n    p3M <- plot_timeseries_bar(\n      groupwise,\n      LINEIV1,\n      LINEIV2,\n      MEAN,\n      ERROR,\n      XLAB,\n      YLAB,\n      ggtitle = paste0(\n        tools::toTitleCase(run_type),\n        \"\\n Medium intensity (N = \",\n        unique(groupwise$N),\n        \")\"\n      ),\n      color_mapping = MEDSTIM_COLOR,\n      show_legend = FALSE,\n      geompoint_size = GEOMPOINT_SIZE\n    )\n    plot_list[[\"M\"]] <- p3M +\n      scale_x_continuous(\n        breaks = breaks_to_show,        # Set breaks at every 10th point\n        labels = labels_to_show,        # Use the calculated labels\n        limits = range(groupwise$tr_sequence)  # Set the limits based on the sequence\n      ) +\n      theme_classic()\n\n    # Low intensity\n    p3L <- plot_timeseries_bar(\n      groupwise,\n      LINEIV1,\n      LINEIV2,\n      MEAN,\n      ERROR,\n      XLAB,\n      YLAB,\n      ggtitle = paste0(tools::toTitleCase(run_type), \"\\n Low intensity (N = \", unique(groupwise$N), \")\"),\n      color_mapping = LOWSTIM_COLOR,\n      show_legend = FALSE,\n      geompoint_size = GEOMPOINT_SIZE\n    )\n    plot_list[[\"L\"]] <- p3L +\n      scale_x_continuous(\n        breaks = breaks_to_show,\n        # Set breaks at every 10th point\n        labels = labels_to_show,\n        # Use the calculated labels\n        limits = range(groupwise$tr_sequence)  # Set the limits based on the sequence\n      ) +\n      theme_classic()\n\n    # ----------------------------------------------------------------------------\n    #                   combine three tasks in one panel per ROI\n    # ----------------------------------------------------------------------------\n\n    library(gridExtra)\n    plot_list <- lapply(plot_list, function(plot) {\n      plot +\n        theme(\n          plot.margin = margin(5, 5, 5, 5),          # Adjust plot margins if needed\n          axis.title.y = element_blank(),          # Remove y-axis title\n          axis.title.x = element_blank(),\n          axis.text.y = element_text(size = AXIS_FONTSIZE),          # Increase y-axis text size\n          axis.text.x = element_text(size = AXIS_FONTSIZE, angle = 30)\n        )\n    })\n    combined_plot_per_run <-\n      ggpubr::ggarrange(\n        plot_list[[\"H\"]],\n        plot_list[[\"M\"]],\n        plot_list[[\"L\"]],\n        common.legend = FALSE,\n        legend = \"none\",\n        ncol = 3,\n        nrow = 1,\n        widths = c(3, 3, 3),\n        heights = c(.5, .5, .5),\n        align = \"v\"\n      )\n\n    # Add the combined plot for this run type to the list for the current ROI\n    plot_list_per_roi[[run_type]] <- combined_plot_per_run\n\n\n  } # end of run loop\n\n  # ----------------------------------------------------------------------------\n  #                  add commom legend\n  # ----------------------------------------------------------------------------\n  legend_data <- data.frame(\n    sixcond = factor(\n      c(\n        \"cueH_stimH\",\n        \"cueL_stimH\",\n        \"cueH_stimM\",\n        \"cueL_stimM\",\n        \"cueH_stimL\",\n        \"cueL_stimL\"\n      )\n    ),\n    color = c(\"red\", \"#5f0f40\", \"#bc3908\", \"#f6aa1c\", \"#2541b2\", \"#00a6fb\"),\n    stringsAsFactors = FALSE\n  )\n\n  legend_plot <-\n    ggplot(legend_data, aes(x = sixcond, y = 1, color = sixcond)) +\n    geom_point() +\n    scale_color_manual(values = legend_data$color) +\n    theme_void() +\n    theme(legend.position = \"bottom\") +\n    guides(color = guide_legend(title = \"Condition\"))\n\n  legend_grob <-\n    ggplotGrob(legend_plot)$grobs[[which(sapply(ggplotGrob(legend_plot)$grobs, function(x)\n      x$name) == \"guide-box\")]]\n  heights <- c(rep(1, length(run_types)), 2)\n  # ----------------------------------------------------------------------------\n  #                  common axes for the 9 panels\n  # ----------------------------------------------------------------------------\n  y_axis_label <-\n    textGrob(\n      \"FIR BOLD \\n(high > low cue; stimulus epoch)\",\n      rot = 90,\n      gp = gpar(fontsize = COMMONAXIS_FONTSIZE)\n    )\n    x_axis_label <-\n    textGrob(\n      \"TR (0.46s per TR)\",\n      rot = 0,\n      gp = gpar(fontsize = COMMONAXIS_FONTSIZE)\n    )\n  num_rows <- length(plot_list_per_roi) + 1  # +1 for the legend\n  # ----------------------------------------------------------------------------\n  #                  combined plots across 3 tasks\n  # ----------------------------------------------------------------------------\n  roi_combined_plot <-\n    do.call(grid.arrange, c(plot_list_per_roi, ncol = 1))\n\n  final_plot <- grid.arrange(\n    y_axis_label,\n    arrangeGrob(\n      roi_combined_plot,\n     x_axis_label,\n      legend_grob,\n\n      ncol = 1,\n      heights = c(11,.5, 1)\n    ),\n    ncol = 2,\n    widths = c(1, 10),    # Relative widths for the label, plots, and legend,\n    top = textGrob(sprintf(\"%s Time series per task\", roi), gp = gpar(\n      fontsize = TITLE_FONTSIZE, fontface = \"bold\"\n    ))  # title parameter\n  )\n  grid.draw(final_plot)\n\n\n  # ----------------------------------------------------------------------------\n  #                 save all plots\n  # ----------------------------------------------------------------------------\n  ggsave(file.path(\n    save_dir,\n    paste0(\"roi-\",\n           roi ,\n           \"_epoch-stim_desc-stimcuecomparison.png\")\n  ),\n  all_plots[[roi]],\n  width = 12,\n  height = 20)\n}"}]
